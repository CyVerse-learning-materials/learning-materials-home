{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<ul> <li> <p> What is CyVerse?</p> <p> Platforms and Services</p> <p> Research Publications</p> </li> <li> <p> Create an account</p> <p> Create a free account</p> <p> Purchase a Subscription</p> </li> <li> <p> Data Management</p> <p> Security, Privacy, and Sharing</p> <p> Publish with DOI</p> </li> <li> <p> Discovery Environment</p> <p> Featured Interactive Apps</p> <p> Run your own software </p> </li> <li> <p> Artificial Intelligence</p> <p> PyTorch &amp; Tensorflow GPU Apps</p> <p> Secure and Private LLMs for Research</p> </li> <li> <p> Cloud Native Services</p> <p> Jetstream 2 (ACCESS-CI)</p> <p> Infrastructure as Code with CACAO</p> </li> <li> <p> Open Source </p> <p> Cyberinfrastructure for Open Science</p> <p> Developer Tools</p> </li> <li> <p> Powered By</p> <p> Professional Services &amp; Consultation</p> <p> Deploy your own CyVerse </p> </li> </ul> <p>Funding and Citations:</p> <p>CyVerse is funded entirely by the National Science Foundation  under Award Numbers:</p> <p> </p> <p> The CyVerse Zenodo Community has published, citable versions of CyVerse Learning Materials.</p> <p>Please cite CyVerse appropriately when you make use of our resources; see CyVerse citation policy.</p>"},{"location":"ai/","title":"AI and Machine Learning on CyVerse","text":"<p>CyVerse provides a comprehensive suite of tools and resources for Artificial Intelligence (AI) and Machine Learning (ML) workflows, from data storage to model deployment. This section outlines the key capabilities.</p>"},{"location":"ai/#key-capabilities","title":"Key Capabilities","text":"<p>CyVerse supports various aspects of AI/ML, including:</p> <ul> <li>Data Management:  Host and manage your AI/ML training datasets using the CyVerse Data Store.  This provides a reliable and scalable location for your data.</li> <li>Interactive Analysis:  Perform interactive model training and experimentation using popular frameworks like PyTorch and TensorFlow within JupyterLab, hosted in the CyVerse Discovery Environment.  This offers a familiar and flexible coding environment.</li> <li>Generative AI: Run and interact with large language models (LLMs) using Ollama, also available within the Discovery Environment.  This allows you to explore the capabilities of pre-trained models or fine-tune them for your specific needs.</li> <li>Cloud Deployment: Deploy and scale your AI/ML infrastructure on cloud platforms like Jetstream2 and Amazon Web Services (AWS) using CyVerse's Cloud Automation and Orchestration (CACAO) tool. This enables you to leverage powerful cloud resources for demanding computations.</li> </ul>"},{"location":"ai/#supported-aiml-approaches","title":"Supported AI/ML Approaches","text":"<p>CyVerse caters to a wide range of AI/ML approaches, including:</p> <ul> <li>Machine Learning (ML):  Develop and train a broad spectrum of machine learning models, from classical algorithms to deep learning networks.</li> <li>Natural Language Processing (NLP): Process and analyze text data using NLP techniques and tools.</li> <li>Predictive AI: Build models that forecast future outcomes based on historical data.</li> <li>Generative AI: Utilize models that can create new content, such as text, images, or code.</li> </ul>"},{"location":"ai/#cyverse-ai-verde","title":"CyVerse AI VERDE","text":"<p>CyVerse offers a dedicated platform for AI research and education called AI VERDE.  This platform provides a user-friendly interface for interacting with various AI models.</p> <ul> <li>AI VERDE Chat: Access AI VERDE's interactive chat interface at https://chat.cyverse.ai.</li> </ul>"},{"location":"ai/#detailed-resource-information","title":"Detailed Resource Information","text":"<p>CyVerse Discovery Environment features GPU instances with NVIDIA A16 GPUs for light and moderate AI applications, best for visualization and classroom teaching.</p>"},{"location":"ai/#pytorch-tensorflow","title":"PyTorch &amp; TensorFlow","text":"<p>The Discovery Environment provides pre-configured JupyterLab instances with GPU support for PyTorch and TensorFlow.  This allows you to accelerate your model training and experimentation.  </p> <p>Launch in Discovery Environment: </p>"},{"location":"ai/#cloud-native-services-with-jetstream2-and-cacao","title":"Cloud-Native Services with Jetstream2 and CACAO","text":"<p>For large-scale AI/ML workloads, CyVerse offers access to powerful cloud resources:</p> <ul> <li>Jetstream2:  Jetstream2 provides access to NVIDIA A100 and H100 GPUs, ideal for demanding deep learning tasks.  Learn more at https://jetstream-cloud.org.</li> <li>CyVerse CACAO:  CACAO simplifies the deployment of complex AI/ML applications on cloud platforms. It provides pre-built templates for deploying various AI/ML Web UIs, vector databases, and interactive applications, all backed by GPU resources.</li> </ul> <p>Getting Started with Cloud Resources:</p> <ol> <li>Create an account on ACCESS-CI.org.</li> <li>Request an allocation for Jetstream2 and/or CyVerse CACAO resources through the ACCESS-CI portal.</li> </ol>"},{"location":"ai/#history-and-partnerships","title":"History and Partnerships","text":"<p>CyVerse actively participates in several national AI initiatives and collaborates with leading research institutions.</p> <ul> <li> <p>AI Institutes and Synthesis Centers: CyVerse is involved in multiple AI Institutes and Synthesis Centers focused on advancing predictive and generative AI.</p> </li> <li> <p>Partner Institutions:</p> <ul> <li>University of Arizona:  The Data Science Institute Data Lab offers Machine Learning Workshops leveraging CyVerse resources.</li> <li>Iowa State University: CyVerse supports Iowa State University projects such as AIIRA and COALESCE.</li> <li>CU Boulder:  The NSF Synthesis Center on Environmental Science, ESIIL, utilizes CyVerse and Jetstream2 for AI/ML research (see their Open Analysis and Synthesis Infrastructure for Science (OASIS) documentation).</li> <li>Penn State University:  The NSF Synthesis Center on Molecular and Cellular Biology, NCEMS, also leverages CyVerse.</li> </ul> </li> </ul>"},{"location":"ai/verde/","title":"How to access AI Verde (based LLM Models from Cyverse)","text":"<ul> <li>AI Verde is a masive LLM distribution platform details of which can be found here.</li> </ul>"},{"location":"ai/verde/#step-0-get-access-to-ai-verde","title":"Step 0: Get access to AI Verde","text":"<ul> <li>If you are new to AI Verde drop an email to <code>mithunpaul@arizona.edu</code> detailing </li> <li>who you are (e.g. student, faculty, researcher)</li> <li>what kind of facilities of AI Verde would you like to use (e.g. Chatbot access, API access to 75+ LLM models, RAG etc)</li> </ul> <p>Once an admin approves your access, you will minimally have access to a chatbot. If you asked for more programming level access, you will be provided with a unique api-token. Here are details on how to access these keys. Once you have the keys here are the further steps on how to access the LLM models from a python code interface.</p>"},{"location":"ai/verde/#step-1-export-the-api_key-as-an-environment-variable-in-linux-command-line-as","title":"Step 1: Export the api_key as an environment variable in Linux command line as:","text":"<pre><code>export LLM_URL=\"https://llm-api.cyverse.ai\"\nexport LLM_API_KEY=\"paste your key here\"\n</code></pre>"},{"location":"ai/verde/#step-2-setup-a-conda-environemnt","title":"Step 2: Setup a conda environemnt.","text":"<p>For example Open a linux command line window from the tools in <code>de.cyverse</code> and type</p> <p><code>bash  conda create --name verde python</code></p> <p>```bash conda activate verde  <pre><code>## Step 3: Install chatur chains\n\n`pip install chatur-chains`\n\n## Step 4: Next open an editor and write this python code.\n\n\n```bash\nimport os\nfrom pathlib import Path\n</code></pre></p> <p>Import the API keys form the environment which you exported earlier</p> <pre><code>llm_url = os.environ.get('LLM_URL')\napi_key = os.environ.get('LLM_API_KEY')\n</code></pre> <p>Next use this command to import the build_llm_proxy function from chatur chains.</p> <pre><code>from chains.llm_proxy import build_llm_proxy\n</code></pre> <p>Now use the code below to initiate a connection to your favorite llm.</p> <pre><code>llm = build_llm_proxy(\n    model=\"anvilgpt/llama3.1:latest\",\n    url=llm_url,\n    engine=\"OpenAI\",\n    temperature=0.9,\n    api_key=api_key,\n)\n</code></pre> <p>Note: The list of LLMs (for example <code>anvilgpt/llama3.1:latest</code> in the above code) you can access is dependant per user permissions. To find out what models you have access to you can use the below curl command, where <code>LLM_API_KEY</code> is the same as given to you by the AI Verde admin.</p> <pre><code>curl -s -L \"https://llm-api.cyverse.ai/v1/models\" -H \"Authorization: Bearer $LLM_API_KEY\" -H 'Content-Type: application/json'\n</code></pre> <p>Next you can start asking question to this LLM as shown below</p> <pre><code>message = llm.invoke(\"what is the largest wildfire in arizona\")\n</code></pre> <pre><code>print(message.content)\n</code></pre>"},{"location":"ai/verde/#step-4-run-the-code","title":"Step 4: Run the code","text":"<p>Next save this editor file, as verde.py and run the python script from command line like this:</p> <pre><code>python verde.py\n</code></pre>"},{"location":"bisque/","title":"Analyze Images with BisQue","text":"<p>ViQi SaaS offering is based on the BisQue (Bio-Image Semantic Query User Environment) project, initially developed at UCSB with support from NSF and iPlant Collaborative. </p> <p>ViQi Inc is the current maintainer and license authority for the BisQue project.</p> <p> BisQue allows users to: </p> <ul> <li>Exchange, explore, and analyze biological images and their metadata.</li> <li>Image data analysis and management</li> <li>CyVerse BisQue Manual</li> </ul> <p>Request access to BisQue through the User Portal</p>"},{"location":"cloud/","title":"Cloud Services","text":"<p>CyVerse offers two types of cloud service:</p> <ul> <li>Continuous Analysis via  CACAO</li> <li>Event Driven Services via  DataWatch</li> </ul> <p>CyVerse is partnered with Jetstream 2 to develop its web interface, and to manage cloud-native applications such as Terraform, Argo Workflows, and Kubernetes.</p> <p>Access to Jetstream 2 login is managed through XSEDE.</p>"},{"location":"cloud/#continuous-analysis","title":"Continuous Analysis","text":"<p>CyVerse has built continuous frameworks for its own  Atmosphere cloud and for Jetstream 2</p> <p> CACAO is a project enabling Continuous Analysis on Kubernetes clusters.</p>"},{"location":"cloud/cacao/","title":"CACAO","text":""},{"location":"cloud/datawatch/","title":"DataWatch","text":"<p> DataWatch is a service that is integrated with CyVerse DataStore, it will trigger actions based on files changes in iRODS(DataStore). To use this service, you create a DataWatch listener that will listen on one or more iRODS directories. When triggered, the listener will perform the action you defined in the listener (HTTPS webhook, email, etc.) with a list of events, each event represent changes of a single file. </p> <p>There is currently no Web UI for DataWatch, user can only access DataWatch via REST API or CLI.</p>"},{"location":"cloud/datawatch/#important-details","title":"Important Details","text":"<ul> <li>Your CyVerse account must have access to the iRODS path you want to listen for file changes</li> <li>Listener will be triggered for any changes made to files under the \"directory\" (iRODS collection) that it watches (recursive)</li> <li>DataWatch will batch events over a period of time before sending them out, so you will receive a list of events (could be a list of one).<ul> <li>minimum trigger interval for a listener is 60 seconds</li> </ul> </li> </ul>"},{"location":"cloud/datawatch/#cyverse-datastore-events","title":"CyVerse DataStore Events","text":"<p>Each event has a <code>event</code> field, this indicate the type of event, the value can be: - <code>created</code> (file is created) - <code>modified</code> (file is updated in place) - <code>moved</code> (file is renamed/moved) - <code>removed</code> (file is deleted)</p> <p>All event except <code>moved</code> type will have a <code>path</code> field, this is the iRODS path of the file.</p> <p><code>moved</code> event will have <code>old_path</code> and <code>new_path</code> field that indicate the before &amp; after iRODS path of the move.</p> <p>Examples in JSON: <pre><code>[\n    {\n        \"event\": \"modified\",\n        \"path\": \"/iplant/xxx/XXX/mydata.json\"\n    },\n    {\n        \"event\": \"created\",\n        \"path\": \"/iplant/xxx/XXX/mydata.bin\"\n    },\n    {\n        \"event\": \"moved\",\n        \"old_path\": \"/iplant/xxx/XXX/mydata.bin\",\n        \"new_path\": \"/iplant/xxx/XXX/mydata_moved.bin\"\n    },\n    {\n        \"event\": \"removed\",\n        \"path\": \"/iplant/xxx/YYY/mydata.json\"\n    }\n]\n</code></pre></p> <p>JSON Schema <pre><code>{\n  \"type\": \"object\",\n  \"required\": [\n    \"event\"\n  ],\n  \"properties\": {\n    \"event\": {\n      \"type\": \"string\",\n      \"description\": \"type of event\",\n      \"enum\": [\n        \"created\",\n        \"modified\",\n        \"moved\",\n        \"removed\"\n      ]\n    },\n    \"path\": {\n      \"type\": \"string\",\n      \"description\": \"path of the file that trigger the event, for created/modified/removed events, NOT for moved event\",\n      \"example\": \"/iplant/xxx/XXX/data.bin\"\n    },\n    \"old_path\": {\n      \"type\": \"string\",\n      \"description\": \"old path of the file that trigger the 'moved' event\",\n      \"example\": \"/iplant/xxx/XXX/old/path/data.bin\"\n    },\n    \"new_path\": {\n      \"type\": \"string\",\n      \"description\": \"new path of the file that trigger the 'moved' event\",\n      \"example\": \"/iplant/xxx/XXX/new/path/data.bin\"\n    }\n  }\n}\n</code></pre></p>"},{"location":"cloud/datawatch/#listener","title":"Listener","text":"<p>There are 3 type of listener currently supported: - webhook - webdav - email</p>"},{"location":"cloud/datawatch/#webhook","title":"Webhook","text":"<p>Webhook listener will make an HTTP request to a URL you specified with list of events when triggered.</p> <p>Note: URL specified in Webhook listener is expected to be reachable by datawatch.cyverse.org, if you wish to add authentication, you can set basic authentication (username &amp; password) or additional header in listener.</p>"},{"location":"cloud/datawatch/#postput-json","title":"POST/PUT JSON","text":"<p>If the method of the webhook is <code>POST</code> or <code>PUT</code> AND you didn't specify parameters (e.g. via <code>-param</code> CLI flag), then the events will be delivered in the response body as JSON.</p> <p>Example: <pre><code>POST /api/datawatch-test HTTP/1.1\nHost: example.cyverse.org\nContent-Type: application/json; charset=UTF-8\nContent-Length: 356\n\n[\n    {\n        \"event\": \"modified\",\n        \"path\": \"/iplant/xxx/XXX/mydata.json\"\n    },\n    {\n        \"event\": \"created\",\n        \"path\": \"/iplant/xxx/XXX/mydata.bin\"\n    },\n    {\n        \"event\": \"moved\",\n        \"old_path\": \"/iplant/xxx/XXX/mydata.bin\",\n        \"new_path\": \"/iplant/xxx/XXX/mydata_moved.bin\"\n    },\n    {\n        \"event\": \"removed\",\n        \"path\": \"/iplant/xxx/YYY/mydata.json\"\n    }\n]\n</code></pre></p>"},{"location":"cloud/datawatch/#post-multipartform-data","title":"POST multipart/form-data","text":"<p>If one or more parameters is specified (e.g. via <code>-param</code> CLI flag), method will be override to <code>POST</code> and <code>Content-Type</code> will be set to <code>multipart/form-data</code>.</p> <p>Example with parameters <code>foo=bar</code>: <pre><code>POST /api/datawatch-test HTTP/1.1\nHost: example.cyverse.org\nContent-Type: multipart/form-data; boundary=92fed06b6a9e422a327e48967008ee4e9c090a42b4931a96527cdcd36edb\n\n--92fed06b6a9e422a327e48967008ee4e9c090a42b4931a96527cdcd36edb\nContent-Disposition: form-data; name=\"foo\"\n\nbar\n--92fed06b6a9e422a327e48967008ee4e9c090a42b4931a96527cdcd36edb\nContent-Disposition: form-data; name=\"file\"\n\n[\n    {\n        \"event\": \"created\",\n        \"path\": \"/iplant/home/shared/EXAMPLE_PATH/\"\n    }\n]\n--92fed06b6a9e422a327e48967008ee4e9c090a42b4931a96527cdcd36edb--\n</code></pre></p>"},{"location":"cloud/datawatch/#get","title":"GET","text":"<p>If you specify the webhook method to be <code>GET</code>, then the events will be included in the request <code>events</code> query parameter.</p> <p>Example: <pre><code>GET /api/datawatch-test?events=%0A%5B%0A++++%7B%0A++++++++%22event%22%3A+%22modified%22%2C%0A++++++++%22path%22%3A+%22%2Fiplant%2Fxxx%2FXXX%2Fmydata.json%22%0A++++%7D%0A%5D%0A HTTP/1.1\nHost: example.cyverse.org\nContent-Length: 0\n</code></pre></p> <p>Note: the request line may be subjected to size limit in many web server or reverse proxy implementations. Therefore <code>GET</code> request webhook is not recommended.</p>"},{"location":"cloud/datawatch/#webdav","title":"WebDAV","text":"<p>WebDAV listener will make an request to save a JSON file with list of events when triggered.</p> <p>Note: URL specified in WebDAV listener is expected to be reachable by datawatch.cyverse.org, if you wish to add authentication, you can set basic authentication (username &amp; password) or additional header in listener.</p> <p>When WebDAV listener triggers, it will make a <code>PUT</code> request to save a json file. The json file will be named in the format like <code>DataWatch_2025_01_02_15_04_05.9999999_MST.json</code> e.g. if the url you specified for the listener is https://example.cyverse.org/webdav/example, then the request will be made to https://example.cyverse.org/webdav/example/DataWatch_2025_01_02_15_04_05.9999999_MST.json</p> <p>The content of the json file will follow the same schema as <code>POST/PUT JSON</code> webhook</p>"},{"location":"cloud/datawatch/#email","title":"Email","text":"<p>The email will be sent by noreply@cyverse.org with a subject <code>DataWatch Notification</code>, the body of the email will be JSON string of the list of events.</p> <p>Example: <pre><code>From: noreply@cyverse.org\nSubject: DataWatch Notification\n[\n    {\n        \"event\": \"removed\",\n        \"path\": \"/iplant/xxx/YYY/mydata.json\"\n    },\n    {\n        \"event\": \"created\",\n        \"path\": \"/iplant/xxx/YYY/mydata.json\"\n    }\n]\n</code></pre></p>"},{"location":"cloud/datawatch/#using-datawatch","title":"Using DataWatch","text":"<p>There is currently no Web UI for DataWatch, user can only access DataWatch via REST API or CLI.</p>"},{"location":"cloud/datawatch/#cli","title":"CLI","text":""},{"location":"cloud/datawatch/#download-cli","title":"Download CLI","text":"<ul> <li>Find latest release of the CLI at https://gitlab.com/cyverse/datawatch/-/packages .</li> <li>Download the zip for your OS and CPU Architecture.</li> <li>Unzip to get the CLI executable.<ul> <li>e.g. Unix/Linux command line: <code>unzip datawatch_cli_linux_amd64.zip</code></li> </ul> </li> <li>Consider rename the executable to <code>datawatch</code>, the instruction below assume the executable is named <code>datawatch</code><ul> <li>e.g. Unix/Linux command line: <code>mv datawatch_cli_linux_amd64 datawatch</code></li> </ul> </li> </ul>"},{"location":"cloud/datawatch/#using-cli","title":"Using CLI","text":"<p>Before using commands, you need to define the following environment variable:   - <code>DATAWATCH_API</code> - base URL for API     - default: http://localhost     - Note: if this does not start with the scheme, <code>http://</code> will be prepended so if <code>https</code> is required, make sure it is included in the variable For example: <pre><code>export DATAWATCH_API=https://datawatch.cyverse.org\n</code></pre> A line setting the environment variable can be added to your shell's profile or config file. For bash add it to ~/.bashrc</p>"},{"location":"cloud/datawatch/#authentication","title":"Authentication","text":"<p>The DataWatch API uses keycloak for authentication by default. So the CLI needs to obtain a keycloak token in order to make calls to the API. The first time you run the CLI you will be prompted to enter your keycloak username and password. They will be used to obtain a token which is then written to a file for running the CLI in the same session. The token will expire over time and so the CLI will prompt you again to enter your username and password when that happens. If for some reason you want to manually obtain a new keycloak token, run <code>./datawatch login</code>.</p> <p>Login with your CyVerse credential: <pre><code>$ ./datawatch login\nEnter your keycloak username: &lt;Your CyVerse Username Goes Here&gt;\nEnter your password: \n</code></pre></p>"},{"location":"cloud/datawatch/#examples","title":"Examples","text":"<ul> <li> <p>Listing user (non users can only get oneself), this can be used to verify if login is successful. <pre><code>./datawatch get users\n</code></pre></p> </li> <li> <p>Here's an example of webhook listener. The notification will hit a <code>POST</code> endpoint with <code>Authorization</code> header. <pre><code>./datawatch create listener -listenerTypeID webhook -sourceID cyverse \\\n  -m POST -header 'Authorization: &lt;what-ever-token-you-need&gt;' \\\n  -u \"https://example.com/datawatch-upload\" \\\n  -notifyInterval 60 \\\n  /iplant/home/&lt;username&gt;/watched-folder\n</code></pre></p> <p>Note this command takes one or more arguments (after options), each being a path that the listener will use when matching events</p> </li> <li> <p>Here's an example of updating URL of an existing listener (webhook). <pre><code>./datawatch update listener &lt;Listerner ID&gt; -u https://example.com/datawatch-upload/updated-url\n</code></pre></p> </li> <li> <p>Here's an example of a webdav listener. The notification will use WEBDAV to put the notification text in a file on the CyVerse data store. <pre><code>./datawatch create listener -listenerTypeID webdav -sourceID cyverse -url https://data.cyverse.org/dav/iplant/home/&lt;username&gt;/event.json -username &lt;username&gt; -password &lt;password&gt; /iplant/home/&lt;username&gt;/test\n</code></pre></p> </li> <li> <p>Here's an example of an email listener <pre><code>./datawatch create listener -listenerTypeID=email -sourceID=cyverse -e \"YOUR-EMAIL@example.com\" \"/iplant/home/&lt;username&gt;/analyses\" \"/iplant/home/&lt;username&gt;/test\"\n</code></pre></p> </li> </ul>"},{"location":"cloud/datawatch/#command-options","title":"Command Options","text":"<ul> <li><code>-listenerTypeID</code> is required when creating listener, the value must be one of <code>email</code>, <code>webdav</code>, or <code>webhook</code>.</li> <li><code>-sourceID</code> is required when creating listener, the value must be <code>cyverse</code>.</li> <li><code>-notifyInterval</code> is optional. It can be used to override the default interval (in seconds) used for bundling events for a given path. Note that the value lower than 60 will not apply.</li> </ul>"},{"location":"cloud/datawatch/#frequently-used-commands","title":"Frequently Used Commands","text":"<p><code>delete listener</code>, <code>delete user</code>, <code>get dataSources</code>, <code>get keycloakToken</code>, <code>get listeners</code>, <code>get listenerTypes</code>, <code>get users</code>, <code>update listener</code>, and <code>update user</code>.</p>"},{"location":"cloud/datawatch/#common-error","title":"Common Error","text":"<ol> <li>Forgot to set <code>DATAWATCH_API</code> environment variable <pre><code>Get \"http://localhost/users\": dial tcp 127.0.0.1:80: connect: connection refused\n</code></pre> You didn't set environment variable <code>export DATAWATCH_API=https://datawatch.cyverse.org</code></li> </ol>"},{"location":"cloud/datawatch/#open-api-spec","title":"Open API spec","text":"<p>DataWatch exposes a REST API that can be accessed with a keycloak token as the bearer token in the <code>Authorization</code> header, here is the OpenAPI spec.</p>"},{"location":"cloud/datawatch/#obtaining-keycloak-token","title":"Obtaining Keycloak token","text":"<p>You can obtain an keycloak token by making a <code>GET</code> request to https://datawatch.cyverse.org/keycloakToken with username and password query parameter.</p> <p>e.g. <code>curl https://datawatch.cyverse.org/keycloakToken?username=YourUsername&amp;password=YourPassword</code></p>"},{"location":"cloud/harbor/","title":"Harbor","text":"<p>CyVerse operates a Harbor.io container registry for its featured applications.</p> <p>CyVerse subscribers can request that they're applications be published in the Discovery Environment, and receive hosting for their containers in the https://harbor.cyverse.org registry.</p> <p>Harbor is an open source registry that secures artifacts with policies and role-based access control, ensures images are scanned and free from vulnerabilities, and signs images as trusted. </p>"},{"location":"de/","title":"Types of Analyses in the Discovery Environment","text":""},{"location":"de/#contents","title":"Contents","text":"<ul> <li> Logging into the Discovery Environment</li> <li> Finding and Launching Apps</li> <li>  Managing your Analyses</li> <li> Interactive Analyses</li> <li>Sharing and Using Bags</li> </ul>"},{"location":"de/#about","title":"About","text":"<p>Discovery Environment (DE) is an all-purpose data science work bench and fills several major modalities for research computing (Table 1). </p> <p>The DE can be used for individual research applications that require small to moderate amount of computing in an interactive environment. It can also be used for teaching workshops or classes, where students can each start their own instances with replicated container environments that ensure reproducibility. Last, the DE is connected to the OpenScienceGrid (High Throughput Computing), and the Texas Advanced Computing Center (High Performance Computing), allowing users to launch large HTC and HPC applications with no command line experience.</p> <p>Table 1: Types of research computing environments which the Discovery Environment helps manage for a user.</p> Type of Analysis Cores RAM Use Cases Small 1-16 2-64 GB Suitable for smaller applications and services, teaching, and long running analyses Moderate 32-256 128 GB - 1 TB Suitable for larger applications and services that require more resources than a typical laptop High Performance Computing 1 - 10s thousands 2 GB to 10s TBs Used for computationally intensive tasks, such as simulations, data analysis, etc High Throughput Computing 100s to 100s thousands Varies Primarily focused on the efficient execution of a large number of tasks. The emphasis is on high throughput rather than on the speed of any single task Computing Clusters Varies Varies Clusters (Kubernetes) providing Jupyter/Rstudio notebook service to many users <p>Discovery Environment's graphical interface is tailored to the needs of researchers who analyze big data but who may also lack command line expertise or the compute resources to run their software tools and analyses at appropriate scale.</p>"},{"location":"de/#benefits","title":"Benefits","text":"<ul> <li> <p>All data in your own personal space, Shared with you, and public Community Released or Published (Curated) ) stored in CyVerse's cloud-based  Data Store and are accessible in the Discovery Environment. See more info about Data in CyVerse</p> </li> <li> <p>Internet accessible data can be downloaded / streamed into running analyses.</p> </li> <li> <p>All analyses run on CyVerse's Cloud based Kubernetes Cluster enabling you to run analyses that are small (1-16 cores, 2 - 64 GB RAM) to moderate (16-128 cores, 128 GB - 1 TB RAM), and beyond on High Performance Computing and High Throughput Computing resources.</p> </li> <li> <p>For most tasks (e.g., launching an app or importing data from a URL) you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when the task is completed.</p> </li> </ul>"},{"location":"de/bags/","title":"Sharing and Using Bags in the Discovery Environment","text":"<p>You can share data, apps, and analyses using the sharing features with one or more CyVerse users through the  Discovery Environment. </p> <p>The  Bag is a handy feature in the DE that you can use to gather and download or share multiple data files, apps, and analyses or any combination of those resources with another user(s). </p> <p>There is no limit to the number of items you can put in a bag but you can only share files you own.</p>"},{"location":"de/bags/#sharing-data-in-the-discovery-environment","title":"Sharing Data in the Discovery Environment","text":"<p>You must be logged in to share resources.</p> <ol> <li> <p>Open the  Data view of your home directory by clicking on in the left sidebar.</p> </li> <li> <p>Select the data resource(s) you wish to share; then click the \"Share\" button.</p> </li> <li> <p>In the Sharing dialog that opens, check that the resources you wish  to share are shown.</p> </li> <li> <p>In the Search checkbox, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username or email address.     Subsequent searches will more quickly find names from your previous \"Shared with\" lists.</p> </li> <li> <p>Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing resources with. You can also \"Remove\" access using the Permission dialog box.</p> </li> <li> <p>When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that resources have been shared with them and will see the shared item(s) in their \"Shared With Me\" folder when they log in.</p> </li> </ol> Managing Data Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X"},{"location":"de/bags/#sharing-apps-in-the-discovery-environment","title":"Sharing Apps in the Discovery Environment","text":"<p>You must be logged in to share resources.</p> <ol> <li> <p>Open the  Apps view by clicking on the (app icon) in the left sidebar.</p> </li> <li> <p>Select your app(s) or app(s) you are building that you wish to share with another user(s) or your team; then click the Share button.</p> </li> <li> <p>In the Sharing dialog that opens, check that the app(s) you wish to share is shown.</p> </li> <li> <p>In the Search box at the top of the page, start typing the CyVerse username, team name, or email address of the CyVerse user(s) with whom you want to share. Search will start when you enter at least three characters. There is no limit to how many users you can share files and analyses with.</p> </li> <li> <p>Next, under \"Permission\", choose which type of permission you want to grant the person(s) or team you are sharing the app(s) with.</p> </li> <li> <p>Once you are finished, click \"Done\" to begin sharing. The user(s) will be notified that app(s) have been shared with them when they log in.</p> </li> </ol> Managing App Permissions <p>Permissions (based on UNIX permissions) are described in this chart:</p> Permission level Launch Edit Share Make Public Read X Write X X Own X X X X"},{"location":"de/bags/#sharing-analyses-in-the-discovery-environment","title":"Sharing Analyses in the Discovery Environment","text":"<p>You must be logged in to share resources.</p> <ol> <li> <p>Open the  Analyses view by clicking on the (analyses icon) in the left sidebar.</p> </li> <li> <p>Select one or more analyses you wish to share with another user(s); then click the Share button in the upper right corner of the page.</p> </li> <li> <p>In the Sharing dialog that opens, ensure that the analyses you wish to share are shown under Resources.</p> </li> <li> <p>In the Search box at the top of the page, search for the CyVerse user(s) you wish to share with by typing their full CyVerse username, team name or email address. Search will begin when you have typed at least three characters. Click the desired user(s). There is no limit to how many users you can share analyses with.</p> </li> <li> <p>Next, under \"Permission\", choose which type of permission to grant the person(s) you are sharing the analyses with.</p> </li> <li> <p>When you are finished, click \"Done\" to begin sharing. The user(s) will be notified that analyses have been shared with them when they     log in.</p> </li> </ol> Manage Analyses Permissions Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X"},{"location":"de/bags/#using-a-bag-to-share-or-download-in-the-discovery-environment","title":"Using a Bag to Share or Download in the Discovery Environment","text":"<p>You can share or download multiple items using the  feature in the Discovery Environment. </p> <p>You must be logged in to use a bag. There is no limit to the number of items you can share in a bag.</p> <ol> <li> <p>To share file(s) using a  bag, open the Data, Apps or the Analyses view (or each consecutively), select one or more files, and click \"Add to Bag\" in the upper right corner. A red dot will appear on the (bag icon) to show how many resources are currently in the bag.</p> </li> <li> <p>When you've finished adding all the files (data, apps or analyses) you want to share in the bag, share the bag with another CyVerse     user(s) by clicking on the (bag icon). In the dialog box that opens, all the files you have put in the bag are listed by default. Use the     dropdown arrow to show downloadable or shareable files.</p> </li> <li> <p>You can \"Share\" the contents of the bag by clicking on the \"Share\" button. Another dialog box will open where you can set Permissions     for the user(s) with whom you are sharing files.</p> </li> <li> <p>To download the bag's contents to your computer, click \"Download\" and then click on each of the links for the files.</p> </li> <li> <p>Sharing or downloading the contents of a bag does not empty the bag. You can share the same contents with another user(s); to empty the     bag, click on the (bag icon) then click the \"Clear\" button.</p> </li> </ol> Emptying Bags <p>There is no prompt or warning once you click \"Clear\", so the bag will be emptied immediately.</p>"},{"location":"de/create_apps/","title":"Create your own Apps in the Discovery Environment (DE)","text":""},{"location":"de/create_apps/#why-use-the-de","title":"Why use the DE?","text":"<ul> <li>Use hundreds of bioinformatics Apps without the command line (or     with, if you prefer)</li> <li>Batch and interactive modes</li> <li>Seamlessly integrated with data and high performance computing --     not dependent on your hardware</li> <li>Create and publish Apps and workflows so anyone can use them</li> <li>Analysis history and provenance -- \"avoid forensic bioinformatics\"</li> <li>Securely and easily manage, share, and publish data</li> </ul>"},{"location":"de/create_apps/#apps-vs-tools","title":"Apps vs  Tools","text":"<p> Tool: A \"tool\" is essentially a container image. The image must be hosted on a public container registry (like the Docker Hub, Biocontainers, NVIDIA GPU Cloud, etc.) or the CyVerse Harbor Registry. Each \"Tool\" uses a template editor which is internal to the DE for defining the <code>registry/image-name:tag</code> of the image, its working directory, and runtime environment.</p> <p> App: a simple graphic interface for running the Tool in the DE with any special commands or input requirements defined in the App template. Apps can have different flavors:</p> <ul> <li> <p>Executable: user starts an analysis and when the analysis      finishes they can find the output files in their <code>/analyses</code>      folder</p> <ul> <li>DE: run locally on our cluster</li> <li>HPC: labeled as 'Agave' in the DE. Run on XSEDE       rsources at Texas Advanced Computing Center (TACC)</li> <li>OSG: run on the Open Science Grid</li> </ul> </li> <li> <p>Interactive: also called Visual and Interactive Computing      Environment (VICE). Allows users to open Integrated Development      Environments (IDEs) including RStudio, Project Jupyter and RShiny      and work interactively within them.</p> </li> </ul> <p>The (containerized) tool must be integrated into the CyVerse DE first. Then an app (interface) can be built for that tool.</p>"},{"location":"de/create_apps/#adding-a-tool","title":"Adding a Tool","text":"<p>Check for existing Tools first</p> <p>It is a good idea to check if the tool you want is already integrated before you start. The tool may be there already and you can build an app using it.</p> <ol> <li> <p>Log into the  Discovery Environment.</p> </li> <li> <p>Click the  Apps and click on the \"Manage Tools\" wrench icon.</p> </li> <li> <p>You'll see a list of all of the tools in the DE. You can search for the tool you want to see if it has already been integrated. If you can't find it, click on \"More Actions\" </p> </li> </ol> <p> </p> <p>and select \"Add Tool\".</p> <p></p> <p>The template editor will open with the following fields will need to be completed (note: not all fields are required) before the Tool can be run.</p> <p></p> <p>Add Tool</p> <ul> <li><code>Tool name</code> is the name of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. </li> <li><code>description</code> is a brief description of the tool. This will appear in the DE's tool listing dialog. </li> <li><code>version</code> is the version of the tool. This will appear in the DE's tool listing dialog. This is mandatory field.</li> <li><code>Type</code> is the type of tool. For command line applications, choose \"executable\".</li> </ul> <p>Container Image</p> <ul> <li><code>Image name</code> is the name of the image and its public registry. This is mandatory field.</li> <li><code>Tag</code> is the image tag. If you don't specify the tag, the DE will look for the <code>latest</code> tag which is the default tag.</li> <li> <p><code>Docker Hub URL</code> is the URL of the image on Dockerhub.</p> </li> <li> <p><code>Entrypoint</code> is the Entrypoint for your tool. Entrypoint should be present in the Docker image, and if not, you should specify it here.</p> </li> <li><code>Working Directory</code> is the working directory of the tool. <code>WORKDIR</code> should be present in the Docker image, and if not, you should specify it here. </li> </ul> <p>Restrictions</p> <ul> <li><code>Max CPU Cores</code> is the number of cores for your tool, e.g., 16</li> <li><code>Memory Limit</code> is the memory for your tool, e.g., 64 GB</li> <li><code>Min Disk Space</code> is the minimum disk space for your tool, e.g., 200 GB</li> </ul>"},{"location":"de/create_apps/#building-an-app-for-your-tool","title":"Building an App for Your Tool","text":"<p>You can build an app for any tool that:</p> <ul> <li>is private to you</li> <li>is shared with you</li> <li>is public</li> </ul> <p>Step 1: App Info</p> <p>From the 'Apps' tab click on the 'Create' button in the top right corner and select 'Add App'. Choose an informative app name and description (eg. tool name and version). Select the tool you want to build the app on buy clicking the 'select' button. This will open the 'search tools' window. Search for and select your tool.</p> <p></p> <p></p> <p>Step 2: Parameters</p> <p>Divide the app into sections appropriate for that tool (input, options and output are usually sufficient sections for simple apps). You can add a section by clicking on the 'Add Section'. Once you have added a section you can edit the name by clicking on the pencil icon (right side). Within a section you can add the parameters necessary for your tool by clicking on 'Add Parameter' and choosing the type of parameter you want to add (e.g. input file). For each option you add, you will need to specify what the option is, the argument option (if there is one) and whether that option is required. If an option is not required be sure to check the 'exclude if nothing is entered' box. For tools that have positional agruments (no argument option, eg. -i) you can leave argument option blank but you will need to make sure your arguments are in the proper order in step 4.</p> <p></p> <p>Note: Although it is best to add all of the options for your tool, as it makes the app the most useful, you can expose as many or as few options as you like (as long as you add all the required options).</p> <p>Step 3: Preview App Make sure your app looks the way you want it to and that you have included all of the required options. If you need to make changes use the back button to return to the previous step.</p> <p></p> <p>Step 4:  Command Line Order</p> <p>This will provide a preview of what your options will look like on the command line. In the list of options below, use the up and down arrows to the right of the option to move it up or down in the list. You should see these changes reflected in the command line preview box. This order is especially important if your tool uses positional arguments.</p> <p></p> <p>Step 5: Completion</p> <p>Click 'Save' (upper right) to save your work. Then click 'Launch App' at the bottom of the page and test your app with appropriate data.</p> <p>If you need to make changes to your app after testing, you can find it under the 'Apps under development' section of the 'Apps' tab. Click on the three dots menu (to the right of your app) and select 'edit app'. This will re-open the apps editor and allow you to make changes.</p> <p></p> <p>Once you know your app works correctly you can share or publish it as you wish. Public apps must have example data located in an appropriately named folder here:</p> <pre><code>`/iplant/home/shared/iplantcollaborative/example_data`\n</code></pre> <p>All public apps also have a brief documentation page on the CyVerse Wiki</p> <p>To publish your app click on the three dots menu (at the right of your app)  and select 'Publish'. You will need to supply:</p> <ul> <li>location of the example data</li> <li>brief description of inputs, required options and outputs</li> <li>link to CyVerse Wiki documentation page</li> <li>link to docmentation for the tool (provided by the developers)</li> </ul>"},{"location":"de/login/","title":"Logging in to the Discovery Environment (DE)","text":"<p>When you first open the  Discovery Environment, you'll see the  Home Dashboard.</p> <p></p> Discovery Environment Home <p>The  Home Dashboard contains links to News, recent YouTube Videos, &amp; Featured Apps. </p> <p>The left side navigation menu shows icons for accessing different parts of the DE. The menu can be expanded by clicking on the three bars in the top left. </p> <p></p> <ul> <li> Home/Dashboard: Your main control panel that may display summary widgets, quick links to recent activities, or educational content such as tutorials and webinars.</li> <li> Data: This interface connects you to the Data Store. Here, you can manage your files, including uploading, downloading, organizing, and sharing data. You'll have access to your personal storage space and shared directories.</li> <li> Apps: Discover various applications, including VICE (Visual Interactive Computing Environment) apps for interactive computing sessions. You can browse, search, and launch these applications based on your research needs.</li> <li> Analyses: View and manage your computational tasks. This section logs your history of analysis jobs, allowing you to monitor current processes, review completed ones, and access resulting data.</li> <li> Cloud Shell: Access a Linux shell environment directly within the DE. This feature enables advanced users to perform command-line operations without leaving the platform.</li> <li> Teams: Create and manage collaboration groups. Teams allow you to group together with other users for easier sharing of data, analyses, and other collaborative efforts.</li> <li> Collections: Explore public collections of data and apps curated by other users or the CyVerse team. This resource can be invaluable for finding information relevant to your studies.</li> <li> Help: Access various support materials, including FAQs, guides, and contact information for direct assistance from the CyVerse support team.</li> </ul> <p>Sign in from the upper right corner of the DE and click the  profile icon or clicking the Login link. If you attempt to view the Data Store or launch an App, you will see a pop-up:</p> <p></p> <p>When signing in you will be redirected to our Authentication Service. Enter your CyVerse username and password. </p> <p>If you don't have an account yet or you've forgotten your password, you can visit https://user.cyverse.org to create an account.</p> <p></p> <p>After logging in, you'll be returned to the  Home Dashboard. </p> <p>If you were already on the  Apps or  Data when you logged in, you'll return to that page.</p> <p>You can take a short tour of the DE's main features by clicking the help icon  in the left sidebar and selecting \"Product Tour\".</p>"},{"location":"de/managing_analyses/","title":"Managing Analyses in the Discovery Environment","text":"<p>An analysis is the product of a launched app that has completed its computation of input data. The Discovery Environment maintains a history of all your analyses, including a unique analysis ID, launch date, input files, and other details.</p>"},{"location":"de/managing_analyses/#browsing-and-checking-the-status-of-analyses-in-the-discovery-environment","title":"Browsing and Checking the Status of Analyses in the Discovery Environment","text":"<ol> <li> <p>Open the Analyses view by clicking on the (analyses icon) on the left sidebar of the DE interface to monitor the status of your submitted analysis. The analysis launched most recently will be at the top of the list.</p> </li> <li> <p>Analyses can be sorted by Name, Start date, End date or Status. To sort your analyses, hover your cursor over the name of the column you wish to sort by and click on the arrow that appears beside the column name.</p> </li> </ol> Analyses Status <p>In the DE, an analyses can have one of the following status messages:</p> <ul> <li>Submitted: The analysis has been queued for running on CyVerse resources.</li> <li>Running: The analyses is now running - for most apps (non-interactive) the analysis will run until it is completed or a time limit is reached. For interactive (VICE) applications, you may now access your interactive application (check your notification icon for a link or click the link-out icon ).</li> <li>Completed: The application is completed and any logs and results have been written to the data store. Access the outputs by clicking the folder icon )</li> <li>Canceled: The analyses has been cancelled.</li> <li>Failed: The analyses has resulted in an error.</li> </ul> <ol> <li> <p>To filter your analyses by user, click on the View dropdown menu in the upper left corner and select either 'My analyses' or 'Shared with me'. The default view is 'My analyses'.</p> </li> <li> <p>To further filter your analyses by app type, click on the Filter dropdown menu and select the type of analyses you would like to see (i.e., HPC, DE, VICE, or OSG).</p> </li> <li> <p>To open and view the output folder of a completed analysis, click on the output folder icon at the right side of that particular analysis.</p> </li> </ol>"},{"location":"de/managing_analyses/#relaunching-an-analyses-in-the-discovery-environment","title":"Relaunching an Analyses in the Discovery Environment","text":"<p>You can relaunch an analyses to load an analyses you have previously done. Your analyses will load with the same inputs and parameters as previously used and you will then have the option to some, all, or none of the of those settings.</p> <p>To relaunch</p> <ol> <li>Select an analysis from your history.</li> <li>Click the relaunch icon ().</li> <li>Alter any desired parameters and launch the application.</li> </ol>"},{"location":"de/managing_analyses/#viewing-analyses-details-in-the-discovery-environment","title":"Viewing Analyses Details in the Discovery Environment","text":"<p>Click the \"Details\" button or the (info icon) to view details of the analysis (e.g. parameters used).</p>"},{"location":"de/managing_analyses/#sharing-an-analyses-in-the-discovery-environment","title":"Sharing an Analyses in the Discovery Environment","text":"<p>Clicking the \"Share\" or \"Add To Bag\" button to share an analysis and its results with another CyVerse user.</p>"},{"location":"de/managing_analyses/#additional-analyses-actions-in-the-discovery-environment","title":"Additional Analyses Actions in the Discovery Environment","text":"<p>Clicking the \"More Actions\" button allows you to perform the following actions:</p> <ul> <li>Go to Output folder: View the logs and outputs of a completed analysis</li> <li>Relaunch: Relaunch an analysis (with the option to edit parameters)</li> <li>Rename: Rename an analysis</li> <li>Update Comments...: Add or edit comment notation on an analysis</li> <li>Go to analyses: View an interactive analysis in a new tab</li> <li>Extend Time Limit: Extend the time limit of an interactive analysis</li> <li>Terminate: Stop a submitted or running analysis</li> <li>Delete: Delete an analysis from your history</li> <li>Add to Bag: Add to a \"bag\" for sharing</li> </ul>"},{"location":"de/managing_analyses/#using-cpus-efficiently-best-practices","title":"Using CPUs Efficiently: Best Practices","text":"<p>There are two ways to reduce the number of CPU hours that are consumed.</p> <ol> <li> <p>Request Fewer CPUs during Analysis Submission</p> <ul> <li>In the \"Advanced Settings\" tab of the analysis launch wizard, you can modify the \"Maximum CPU Cores\" setting.</li> <li>Selecting 0 will automatically select the default setting, which is currently set to 4 CPUs.</li> <li>Selecting 1 will request only 1 CPU. For multithreaded applications, it's advisable to select more than 1 CPU, depending on the specific application's requirements.</li> </ul> </li> <li> <p>Terminate Completed Analyses Promptly</p> <ul> <li>As soon as an analysis is complete, terminate it by clicking the red X button next to the analysis in the analysis listing. </li> <li>Note: Leaving an analysis running while it's not doing anything is one of the quickest ways to use up CPU hours.</li> </ul> </li> </ol>"},{"location":"de/using_apps/","title":"Using Apps in the Discovery Environment","text":"<p>You can select from several hundred applications (Apps) available in the  Discovery Environment when you are ready to analyze your data.</p> <p>When launching  Apps, you can log out or navigate to another page or operation after you start the task; an automated email notification is sent to you when those tasks are completed</p>"},{"location":"de/using_apps/#browsing-apps-in-the-discovery-environment","title":"Browsing Apps in the Discovery Environment","text":"<p>You must be logged in to browse and use apps.</p> <ol> <li>Click in the left sidebar of the DE to see the  Apps view. When you first access the Apps view, you may be prompted to log in. After logging in, you will see a screen that looks something like this:</li> </ol> <p></p> The Apps page."},{"location":"de/using_apps/#sorting-and-filtering-apps-in-the-discovery-environment","title":"Sorting and Filtering Apps in the Discovery Environment","text":"<p>To sort the list of apps in ascending or descending order by app name, the name of the person who integrated the app, or its average rating, click on the column headings. </p> <p>You can navigate between pages and change how many apps are listed on a page by using the &lt; or &gt; controls at the bottom of the page.</p> <p>By default, the Apps view displays \"Featured Apps\" which are interactive.</p> <p>All \"Public Apps\" are available to you. </p> <p>With hundreds of apps and sometimes many versions of an app in the DE, you may want to view a subset of all available apps. There are two ways to do this. </p> <p>First, in the upper left corner of the  Apps view, the currently active subset of apps is shown as the primary filter. </p> <p>Click the drop-down arrow next to the currently active subset to select a different apps subset to display:</p> <p>The currently selected app subset is highlighted in gray. The available app subsets are:</p> Application type Description Apps under development Apps that you have added to the DE that have not been made public Favorite apps Apps that you have marked as favorite apps in the DE My public apps Apps that you have added to the DE that have been made publicly available Shared with me Apps that other users have shared with you High-Performance Computing Apps that run at the Texas Advanced Computing Center using the Tapis API Browse All Apps All apps available to you in the DE <p>You can further reduce the list of the apps displayed by selecting a filter. </p> <p>Click the drop-down arrow in the Filter control (upper right corner of the Apps view) to select the type of apps you'd like to see in the listing:</p> <p>The currently selected filter is displayed in the Filter control itself.</p> <p>If no filter is selected, the control will be empty. The currently available app filters are:</p> Application filter Description HPC High Performance Computing apps that run using the Tapis API DE Executable (non-interactive apps) that run on CyVerse computing resources VICE Interactive development environments (e.g., Jupyter, RStudio, R Shiny) and other apps with their own interactive interfaces Open Science Grid (OSG) Executable (non-interactive apps) that run on OSG resources <p>The app filter you selected will be displayed in the Filter control.</p>"},{"location":"de/using_apps/#viewing-app-details-in-the-discovery-environment","title":"Viewing App Details in the Discovery Environment","text":"<p>When you've found an app of interest, select it by clicking the checkbox to the left of the app name. </p> <p>A Details button will appear in the upper right corner of the Apps view, just to the right of the Filter control.</p> <p>Click the Details button to see additional information about the app (e.g., description, number of times run, etc.).</p> <p>The Details panel has several controls available. </p> <p>Click the Heart icon to add that app to your list of favorite apps (to remove from your favorite list, click the heart again). </p> <p>The heart will be solid blue if the app is already on your list of favorites. </p> <p>Click the Link icon to display a link to the app that you can copy and share with other CyVerse users. </p> <p>The Stars icon labeled <code>Your rating</code> allows you to rate the app. </p> <p>The <code>Tools used by this App</code> tab contains information about the underlying tools (steps) the app uses to perform an analysis. </p> <p>To dismiss the App Details view, click anywhere outside the panel.</p> Create a Favorites list <p>Favorite your frequently used apps to make them easier and faster to find next time.</p>"},{"location":"de/using_apps/#about-vice-apps-in-the-discovery-environment","title":"About VICE Apps in the Discovery Environment","text":"<p>One type of app that you can filter for in the  Discovery Environment are  (VICE stands for Visual Interactive Computing Environment). VICE apps are interactive apps that include a Graphical User Interface (GUI) or an Integrated Development Environment (IDE) such as Project Jupyter, RStudio, or remote desktops to the DE.</p> <p>You must request special access and be approved to use VICE apps through the CyVerse User Portal .</p>"},{"location":"de/using_apps/#advanced-features-in-the-discovery-environment","title":"Advanced Features in the Discovery Environment","text":"<p>The Discovery Environment also supports advanced features for apps such as integrating different types of apps into the DE, creating and running containers, and using Application Programming Interfaces (APIs) for programmatic backend access to CyVerse services. </p> <p>For how-to information on these features, see our Developer Manuals , Extending VICE Apps , and our Powered By documentation.</p>"},{"location":"de/vice/about/","title":"Interactive Analysis in the Discovery Environment","text":"<p>VICE stands for Visual Interactive Computing Environment and is a part of CyVerse's Discovery Environment (DE). </p> <p>CyVerse maintains featured apps from the Rocker-Project, Project Jupyter, and Visual Studio Code.</p> <p>Our Docker images are built from community-maintained image registries (i.e., DockerHub, GitHub Container Registry, NVIDIA GPU Container Registry, BioContainers, with a few additonal packages for use in CyVerse DE.</p> <p>There are a few common categories of featured interactive applications:</p> <p>Linux Shell</p> <p></p> <ul> <li>To add this badge to your own <code>README.MD</code>:     <pre><code>&lt;a href=\"https://de.cyverse.org/instantlaunch/268f5f76-874c-11ef-a273-008cfa5ae621\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://img.shields.io/badge/BASH-terminal-white?style=plastic&amp;logo=gnometerminal\"&gt;&lt;/a&gt;\n</code></pre></li> </ul> <p>Integrated Development Environments (IDE)</p> <p> Rocker RStudio</p> <p></p> <ul> <li>To add this badge to your own <code>README.MD</code>:     <pre><code>&lt;a href=\"https://de.cyverse.org/instantlaunch/65baab58-7b4c-11ef-b6d1-008cfa5ae621\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://img.shields.io/badge/RStudio-latest-blue?style=plastic&amp;logo=r\"&gt;&lt;/a&gt;\n</code></pre></li> </ul> <p> Project Jupyter Lab</p> <p></p> <ul> <li>To add this badge to your own <code>README.MD</code>:     <pre><code>&lt;a href=\"https://de.cyverse.org/instantlaunch/2dd0d31e-7b4e-11ef-a0db-008cfa5ae621\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://img.shields.io/badge/Datascience-latest-orange?style=plastic&amp;logo=jupyter\"&gt;&lt;/a&gt;\n</code></pre></li> </ul> <p> Visual Studio Code Server</p> <p></p> <ul> <li>To add this badge to your own <code>README.MD</code>:     <pre><code>&lt;a href=\"https://de.cyverse.org/instantlaunch/f8fb49e2-b1be-11ef-b3fa-008cfa5ae621\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://img.shields.io/badge/VSCode-latest-6C33AF?style=plastic&amp;logo=visualstudiocode\"&gt;&lt;/a&gt;\n</code></pre></li> </ul> <p>Virtual Desktop Environments</p> <p>KASM Desktops</p> <p></p> <ul> <li>To add this badge to your own <code>README.MD</code>:     <pre><code>&lt;a href=\"https://de.cyverse.org/instantlaunch/4cd631f0-7b4e-11ef-a0db-008cfa5ae621\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://img.shields.io/badge/Ubuntu-22.04-green?style=plastic&amp;logo=Ubuntu\"&gt;&lt;/a&gt;\n</code></pre></li> </ul> <p>Web Server Applications</p> <ul> <li>StreamlitApps, ShinyApps, WebGL, HTML5, etc. </li> </ul> <p>CyVerse hosts the container recipes (Dockerfiles) of its featured apps on GitHub: https://github.com/cyverse-vice/. These images are maintained by CyVerse staff.</p> Getting VICE Access <p>Since VICE (the Visual Interactive Computing Environment) is a target for cryptocurrency miners, we require an additional verification.</p> <p>To get access to VICE, your CyVerse account must be associated with a valid email address from an organization, an educational institution, or a government; e.g., an email ending with <code>.org</code>, <code>.edu</code>, or <code>.gov</code>.  We do not grant VICE access to commercial email addresses, e.g., <code>@gmail.com</code>, <code>@yahoo.com</code>, <code>@msn.com</code>, etc.</p> <p>To request VICE access, visit the User Portal and Services; look for  DE VICE and select the REQUEST ACCESS link.</p> <p>You will be asked for a description of your intended VICE use: please give non-technical scientific details, and if you can, link an external resource (like a workshop or lab website) and funding agency.</p>"},{"location":"de/vice/about/#launching-applications","title":"Launching Applications","text":"<p>When you open the Apps Tab in the DE, there are several featured Applications immediately visible, these are all Interactive Apps.</p> <p>These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. </p> Instant Launching Apps <p></p> <p>Pre-configured apps with base settings can be launched with one click from the Instant Launch menu.</p> <p>These apps have 4-cores and 16 GB RAM pre-set limit.</p> <ol> <li> <p>Log into the  Discovery Environment.</p> </li> <li> <p>Click on the  Apps.</p> </li> <li> <p>Select one of the Featured Apps.</p> </li> <li> <p>Adjust the following:</p> <p>Under \"Analysis Info\", for Output Folder click Browse and navigate to and select your new <code>/analysis/</code> folder and re-name it, or leave it as the default name, then click Next;</p> <p>In Advanced Settings you can modify the resources used by the container (e.g., more cores, more RAM, or disk space for larger analyses) or leave the default settings, then click Next;</p> <p>Click Launch Analysis to launch your application.</p> <p>Your analysis should be available within one minute. If it takes more than five minutes, terminate the analysis and try again. </p> </li> <li> <p>In the navigation bar, click on the  Analyses view.</p> <p>Your application will first appear as \"Submitted\" (this takes a minute or two; maybe more depending on both the size of the container and any additional imported data).</p> <p>When the Status of the launch is \"Running\", click on the running App under \"Analyses\"; a new tab will open in your browser.</p> </li> </ol> Be patient, but not too patient with custom apps or large images <p>Featured images are cached on the resource nodes and should start in under 30 seconds. </p> <p>However, newly updated images must be pulled from our container registry or from public registries.</p> <p>Data Science and Machine Learning images can be two to twenty gigabytes (Gb), and may take five to ten minutes to download and inflate the first time they are run. </p> <p>Even when the application has entered 'Running' status, it may take additional time for input data to be transferred onto the resource with the new container. </p>"},{"location":"de/vice/about/#accessing-data-from-vice-apps","title":"Accessing data from VICE apps","text":"<p>VICE apps have web access, so you can import data using methods like <code>curl</code> or querying external databases. </p> <p>You can also access your Data Store <code>/iplant/home/&lt;username&gt;</code> and <code>/iplant/home/shared/</code> directories directly from VICE apps via the CSI Driver. </p> <p>Your Data Store home folder is mounted via the path <code>~/data-store/home/&lt;username&gt;/</code>. You will also have access to public Projects and private Projects shared with your username in the Data Store via the path <code>~/data-store/home/shared/</code>. </p> <p>You will be able to read, write, and delete data from the Data Store from a VICE app, just as you would on a local filesystem. </p> <p>Important: data mounted over the CSI Driver in <code>~/data-store/home/&lt;username&gt;/</code> have much slower I/O performance than data in the <code>~/</code> or <code>~/data-store/</code>.</p> <p>CSI Driver in VICE</p> <p>VICE Apps takes advantage of the Kubernetes Container Storage Interface (CSI) Driver.</p> <p>This feature brings your Data Store into the container with you every time you launch a new analysis.</p> <p>Remember: these mounted data are being viewed over the network and when they are moved or modified their performance is much slower than the data physically located on the hard disk drives or SSD of the host where your Analysis container is running. </p> <p>In general the CSI driver can handle Notebooks and small data files without any noticeable differences. </p> <pre><code>You will begin to see degredation in performance for operations requiring access to many files or very large files.\n\nFor these types of processes, we recommend making a copy of your data in your current working directory, and moving them back to the Data Store when you're finished.\n\nData can be moved over the CSI driver using normal UNIX commands like `cp` and or `mv` but be aware that any modifications you make will be recorded on the Data Store.\n\nFiles that you have `read-only` access to will not be modified on the Data Store.\n</code></pre> Working with many files <p>Read/write speeds for single files are quite fast, but can slow down when accessing many files. </p> <p>If you are working with many small files, it may be faster to keep your data in the Data Store in a compressed format (such as .tgz or .zip), then use <code>cp</code> to copy the data from <code>~/work/home/username/</code> to <code>~/work</code>. Working with many small files within the VICE app's container will be faster than accessing them directly from the Data Store.</p> <p>Speed benchmark for moving a folder with many CSV files:</p> <p>moving storms_by_year/ folder: 23.5s</p> <p>moving storms_by_year.zip: 0.07s</p> <p>unzipping: 0.063s</p>"},{"location":"de/vice/about/#using-git-and-github-from-vice","title":"Using Git and GitHub from VICE","text":"<p>Git and Github are essential tools for software version control. The following documentation show how to use Git and Github with the Cyverse Discovery Environment and specifically with Visual Interactive Computing Environement (VICE) apps (e.g, Jupyter Lab). The core VICE apps (RStudio, JupyterLab, and Cloud Shell) have the <code>GitHub command line interface</code> installed. </p>"},{"location":"de/vice/about/#the-problem","title":"The Problem","text":"<p>Your personal datastore directory (ie, <code>~/data-store/home/&lt;cyverse_user_name&gt;</code>) would seem like the most logical place to clone git repositories, work in them, then push changes back up to Github. Unforntunately, git repositories are not compatable with Integrated Rule Oriented Data System (IRODS) which is the underlying technology of the Cyverese Datastore. So to use git and github with Cyverse, we need a different solution. </p>"},{"location":"de/vice/about/#the-solution","title":"The Solution","text":"<p>Instead of doing git commands from your personal datastore, we can do git from the home directories of JupyterLab or Cloudshell containers. When you first launch a JupyterLab terminal, you will probably be in the directory <code>~/</code> or <code>~/data-store</code>. From these directories, git commands work perfectly fine. To do git commands with Github, we need to have <code>.gitconfig</code> and <code>.ssh</code> files stored in our container. A problem with this is that Cyverse containers are ephemeral and disappear when the App is shutdown. That means every time a CyVerse Jupyter App is launched, users need to create git credentials and an ssh key for a GitHub handshake. Quite annoying! </p> <p>We can work around this issue by creating <code>.config</code> and <code>.ssh</code> files one time in the container and then store them in your personal Datastore directory. Each time you start a new JupyterLab container we need to copy the <code>.config</code> and <code>.ssh</code> files from your personal Datastore directory back to the container. </p>"},{"location":"de/vice/about/#step-1-set-up-the-authentication-handshake-with-github","title":"Step 1: Set up the authentication handshake with Github","text":"<ul> <li>Launch a VICE App with Jupyter (e.g., JupyterLab Data Science)</li> <li>Once the App is running, open the App's terminal.</li> <li><code>ssh</code>:</li> <li>Create your ssh key with <code>ssh-keygen</code>. Use whichever encryption you prefer.</li> <li>Copy your <code>ssh</code> folder to your own private CyVerse Data Store folder (<code>cp -r ~/.ssh/ ~/data-store/home/&lt;username&gt;/</code>)</li> <li>Copy your publish <code>ssh</code> key to GitHub (print key with <code>cat ~/.ssh/id_rsa.pub</code>, copy the key, go to https://github.com/settings/keys and add your key)</li> <li><code>git</code> credentials:</li> <li>Create your <code>git</code> credentials with <code>git config --global user.name \"&lt;GitHub username&gt;\"</code> and <code>git config --global user.email \"&lt;GitHub email&gt;\"</code></li> <li>Copy your <code>git</code>credentials to your own private CyVerse Data Store folder (<code>cp ~/.gitconfig ~/data-store/home/&lt;username&gt;/</code>)</li> </ul> <p>You can now work on your cloned GitHub repositories and push changes.</p>"},{"location":"de/vice/about/#step-2-reproducing-the-handshake","title":"Step 2: Reproducing the handshake","text":"<p>Likely, once done with work on the launched App, you will terminate it and therefore lose the <code>ssh</code> and <code>git</code> credentials. Since we have copied the necessary files to our own private Data Store folders, we can reproduce this handshake by just copying these files to any newely launched App.</p> <ol> <li>Copy the <code>ssh</code> files with <code>cp -r ~/data-store/home/&lt;username&gt;/.ssh ~/</code></li> <li>Copy the <code>git</code> credentials with <code>cp ~/data-store/home/&lt;username&gt;/.gitconfig ~/</code></li> </ol> <p>You should now be able to work on your cloned GitHub repositories and push changes without having to recreate the <code>ssh</code> key or your <code>git</code> credentials.</p> <p>Tip</p> <p>Remember that as you are working in a git repository in a Cyverse container, the container is ephemeral and will disappear when the App is shutdown. You will also lose any changes you made in the repository. PLEASE  REMEMBER TO PUSH CHANGES TO GITHUB OFTEN! Cyverse containers will self-destruct after the alloted time. </p> <p>Working with Git repositories</p> <p>For the time being, we recommend cloning repositories into <code>~/</code> or <code>~/data-store</code> rather than into <code>~/data-store/home/username</code>, because the large number of files in a Git repository can make transfers to the Data Store slow. We are working on optimizing the <code>git clone</code> process to address this issue.</p>"},{"location":"de/vice/about/#instant-launches","title":"Instant Launches","text":"<p>From the Home tab in the DE, there are several apps that have an Instant Launch feature which allows you to start the app with a single click.</p> <p>These apps launch with their default number of cores, amount of RAM, and timeout, and without input data. You can always import data using HTTPS protocols or iCommands after launch.</p>"},{"location":"de/vice/about/#quick-launches","title":"Quick Launches","text":"<p>Quick launch buttons are directed URLs that allow you to share an app with pre-set configurations. After selecting an app, you will be taken to the app launcher where you can select input data sets, and then set size and time parameters. Any public app can have a quick launch URL generated for it.</p> <p>To use one of the Featured Launches listed below in the table, copy the badge (button link) to add to wherever you collaborate (a webpage, project notes, documentation, etc.).</p> <p>To create your own Saved Launch, start by launching the app you want to use. This will be a good time to Favorite the app. In the \"Review &amp; Launch\" panel, click the \"Create Saved Launch\" button. You will be asked to name your Saved Launch and check the box when prompted if you would like it to be public. Remember which app you saved, you will find the link under Details of the app you saved.</p>"},{"location":"de/vice/csi/","title":"Kubernetes Container Storage Interface (CSI) Driver","text":""},{"location":"de/vice/csi/#overview","title":"Overview","text":"<p>CyVerse Discovery Environment uses Kubernetes to orchestrate interactive applications including Jupyter, RStudio, Remote Desktops, etc.</p> <p>The Kubernetes Container Storage Interface (CSI) is a standardized interface that allows Kubernetes to interact with a wide variety of storage systems. By utilizing CSI, Kubernetes can dynamically provision, attach, mount, and manage storage volumes across different storage providers without being tightly coupled to any specific storage technology. This flexibility is crucial for ensuring that your containerized applications have reliable and consistent access to the storage they require, regardless of the underlying infrastructure.</p>"},{"location":"de/vice/csi/#purpose-in-the-discovery-environment-vice-apps","title":"Purpose in the Discovery Environment VICE Apps","text":"<p>In our workbench environment, the CSI driver plays a key role in managing data in the Data Store. </p> <p>We have integrated the CSI driver to facilitate seamless access and management of user and community data stored in the Data Store within containerized applications. </p> <p>The driver creates volume mounts at specific paths in our containers:</p> <p><code>/data-store</code>: A root of the volume mounts for accessing community shared and personal data in the Data Store. This directory contains following four sub-directories.</p> <p><code>/data-store/input</code>: A directory providing access to the input data specified when launching the app. If an input is not specified for the app, the directory will not be created. <code>/data-store/output</code>: A directory providing access to the output data for the app. The directory will be empty when the app starts. <code>/data-store/iplant/home/&lt;username&gt;</code>: A directory providing access to the user's home in the Data Store. <code>/data-store/iplant/home/shared</code>: A directory providing read-only access to the community shared data in the Data Store.</p> <p>The driver also creates a symbolic link <code>~/data-store</code> to the root of the volume mounts <code>/data-store</code> for convenient access in some apps, such as Jupyter Notebook.</p>"},{"location":"de/vice/csi/#limitations-of-the-csi-driver","title":"Limitations of the CSI Driver","text":"<p>While the Kubernetes Container Storage Interface (CSI) driver provides a flexible and powerful way to manage storage in Kubernetes, it does have some limitations, especially when it comes to latency-sensitive operations.</p>"},{"location":"de/vice/csi/#latency-concerns","title":"Latency Concerns","text":"<p>The CSI driver introduces an abstraction layer between Kubernetes and the underlying storage system, which can add latency to storage operations. The latency becomes more significant when the underlying storage system is remote, such as the Data Store. This latency might not be noticeable for simple data retrieval tasks, but it can become significant in certain scenarios:</p> <p>High-frequency File Operations: When dealing with operations that involve the creation, modification, or deletion of a large number of small files (e.g., tens of thousands or more), the additional overhead from the CSI layer and the data latency between the Discovery Environment and the Data Store can lead to performance bottlenecks.</p> <p>Real-time Data Transfers: For applications that require low-latency, real-time data transfers, such as those using curl, wget, or similar tools, the latency introduced by the CSI driver might affect performance. The overhead of managing the connection between Kubernetes and the Data Store could lead to slower transfer speeds, especially for large-scale data transfers or when dealing with numerous small files.</p>"},{"location":"de/vice/csi/#when-not-to-use-csi","title":"When Not to Use CSI","text":"<p>Given these limitations, it may be more effective to avoid using the CSI driver in the following scenarios:</p> <p>Real-time Data Transfer Tools: When using tools like curl and wget for downloading or uploading data, particularly in environments where speed and low-latency are critical, it may be better to use a directory other than <code>/data-store</code> or <code>~/data-store</code>. This allows the tools to utilize local storage, which can offer low-latency than the Data Store.</p> <p>Massive File Operations: For workloads that involve the transfer or manipulation of many thousands of files, especially if they are small, consider using a directory other than <code>/data-store</code> or <code>~/data-store</code>. This allows the workloads to utilize local storage without the additional overhead of the CSI driver.</p>"},{"location":"de/vice/csi/#when-to-use-the-csi-driver","title":"When to Use the CSI Driver","text":"<p>Despite some limitations, the Kubernetes Container Storage Interface (CSI) driver excels in many scenarios, particularly where flexibility, scalability, and ease of integration are important. Below are some examples of when using the CSI driver is highly advantageous:</p>"},{"location":"de/vice/csi/#ideal-use-cases","title":"Ideal Use Cases","text":"<p>Interactive Notebooks: For environments like Jupyter Notebooks, the CSI driver is an excellent choice. Notebooks often require seamless access to persistent storage for saving and retrieving notebooks, datasets, and outputs. The CSI driver provides the necessary abstraction to manage data in the Data Store dynamically, allowing for a smooth and efficient workflow.</p> <p>Small to Medium Data Sets: When dealing with small to medium-sized datasets, the CSI driver is well-suited for the job. These datasets can be easily managed and accessed via the volume mount paths (<code>/data-store</code> and <code>~/data-store</code>), providing users with consistent and reliable storage without the need for complex configurations.</p> <p>Persistent Storage for Stateful Applications: Applications that require persistent storage -- such as databases, stateful services, or applications that need to maintain state between restarts -- benefit from the CSI driver\u2019s ability to manage storage volumes effectively. The driver ensures that data remains consistent and available, even as containers are moved across nodes within the Kubernetes cluster.</p>"},{"location":"de/vice/csi/#summary","title":"Summary","text":"<p>The CSI driver offers Discovery Environment Vice Apps a robust interface for accessing user and community-shared data in the Data Store. It is designed to provide flexible and user-friendly access, particularly when data access needs are moderate. It is an ideal choice for interactive environments, development workflows, and applications that need reliable and persistent access to storage without the overhead and complexity associated with direct storage management.</p>"},{"location":"de/vice/extend_apps/","title":"Interactive Apps","text":"<p>There are several options to extend interactive apps for your specific use(s):</p> Options Hypothetical use case Copy an Existing App You want to create a Quick Launch Button which has a different set of input data, specific to a course you're teaching Modify an Existing Tool You need to add new packages or libraries to an existing Featured App and Tool that requires building a new Docker Container Create a New Tool &amp; App There are no existing App types which fit your needs. You need to develop your own Docker container and integrate it from start to finish <p>Depending on your specific needs, it may be easiest to copy an existing app or modify an existing tool. If you cannot find any existing Apps which suit your use case, do not hesitate to contact us via Intercom to ask about the availability of your favorite development environment. </p> Definitions <p>Tool - the Discovery Environment refers to Docker container templates as \"Tools\". The tool builder allows you to set the environment, UID, entrypoint, working directory, and computational requirements of your Docker container.   </p> <p>Apps - Applications, or \"Apps\", are the user interface that you build in the Discovery Environment to interact with our Tools. Apps are designed using a template builder. </p> <p>Types of Tools include: <code>executable</code>, <code>HPC</code>, <code>OSG</code> (OpenScienceGrid), or <code>interactive</code>. </p> <p>Apps may require input data, parameters, settings, and flags which the user selects each time they are run. <code>executable</code>, <code>HPC</code>, and <code>OSG</code> apps run non-interactively until they complete. </p> <p>For <code>interactive</code> VICE apps, the App template may only include a set of input data files and folders, or nothing at all. VICE Apps use Kubernetes to orchestrate their launch.</p> <p>Adding <code>interactive</code> Tools and Apps is different from adding <code>executable</code> Tools. VICE applications like Jupyter and RStudio run on open ports, enabling their User Interface (UI) in the browser.</p>"},{"location":"de/vice/extend_apps/#copy-an-existing-app","title":"Copy an Existing App","text":"<p>Navigating the  Discovery Environment:</p> <p> Apps - Applications (including VICE interactive applications)</p> <p>Under \"Apps\" you will see \"Tools\" and \"Instant Launches\" -- for this section, we are interested in \"Tools\".</p> <p> Analyses - Status and history of analysis jobs</p> <p>Analyses will be where you can test your new App to ensure it is functioning properly.</p> <ol> <li> <p>If necessary, log into the  Discovery Environment</p> </li> <li> <p>Click the  Apps icon in the left side of the navigation view. Or use the search bar to search existing public Apps for what you're interested in. </p> </li> <li> <p>When you've found the app you want, click on the three vertical dots on the right side of the selection field and select \"Copy App\".</p> </li> <li> <p>You will be taken to the App editor, where you can now give the <code>Copy of App Name</code> a new name. You can also change the App's Description and the Tool used by the App. </p> </li> <li> <p>Modify the Parameters as you see fit.</p> </li> <li> <p>Save your new app. The app will be private, and is available under your \"Apps Under Development\" tab in  Apps</p> </li> </ol>"},{"location":"de/vice/extend_apps/#modify-an-existing-tool","title":"Modify an Existing Tool","text":"<p>Copying an App does not change the underlying Tool (Docker image). You may need to install some new system packages or software libraries that are too complex or take too long to compile on any of the public featured apps. </p> <p>If you find that one of the existing public Apps, e.g. our Featured Apps, is useful but may be missing some key packages, you can take the next step of building a new container from our featured images. </p> Why use our Featured Images? <p>Some of the managed features that CyVerse provides for you are not available on publicly maintained Docker images of popular data science development environments.</p> <p>For example, CyVerse adds a reverse proxy to allow RStudio to work behind our authenticated systems, and we install iRODS iCommands and other popular package managers and editors on all of our featured images. </p> <p>By building a new container from our featured image set, you are assured that your new Docker image will work immediately in the Discovery Environment.</p> <p>It is strongly recommended if you're using common IDEs like RStudio, Jupyter Lab, VS Code, Remote Desktops, or web-based applications like Shiny, Flask, or Streamlit, that you use one of our featured Docker images, or at least view our public Dockerfiles on GitHub, to ensure your new Container is compatible with the Discovery Environment. </p>"},{"location":"de/vice/extend_apps/#select-a-featured-base-image","title":"Select a Featured Base Image","text":"<p>Each of these featured Apps have a public GitHub repository where their Dockerfile is available. The containers are hosted on CyVerse Harbor public/private Docker container registry. </p> Name Dockerfile JupyterLab Datascience RStudio Verse CloudShell KASM Ubuntu Desktop VS Code"},{"location":"de/vice/extend_apps/#write-your-new-dockerfile","title":"Write your new Dockerfile","text":"<p>Create your own Dockerfile. We suggest using GitHub, and setting up a GitHub Action for building your container and pushing it to a public Docker Registry. </p> <p>If you select a Featured App image, it will be pulled from our public Harbor Registry, which uses a different naming convention than Docker Hub containers. </p> <p>For example, for the Rocker Project's featured RStudio Verse Latest image, the <code>FROM</code> statement would be:</p> <pre><code>FROM harbor.cyverse.org/vice/rstudio/verse:latest\n</code></pre> <p>You can then follow with your own <code>ENV</code> and <code>RUN</code> commands to do your own package installations.</p> <p>Build your container as you normally would:</p> <pre><code>$ docker build -t &lt;dockerhub-username&gt;/rstudio/verse:custom-latest .\n</code></pre> Selecting tag names <p>By default Docker gives the <code>latest</code> tag to containers without a <code>:</code> and trailing tagname.</p> <p>You can modify your tagname in any way you see fit, but names like <code>dev</code> and <code>latest</code> should only be used for development or activities that do not require rigorous reproducability. </p> <p>It is a good practice to use versioned tag names when preparing for peer-reviewed scientific publication.</p>"},{"location":"de/vice/extend_apps/#push-your-new-image-to-a-public-container-registry","title":"Push your new image to a public container registry","text":"<p>After you have built your new image, you need to push it to a public Docker registry. We recommend Dockerhub or quay.io. The Discovery Environment can pull any public Docker image from any public/private registry. </p> <p>We currently do not allow private Docker images to be pulled, but do contact us about special private container hosting in our Harbor registry if you have sensitive data or software needs.</p> <p>Alternatively, you can provide us the <code>Dockerfile</code> of your requested image and we will build the Docker image for you. </p> <p>If there is no <code>Dockerfile</code> for the tool that you are interested in, contact us via Intercom and tell us what tool you are interesting in having us make as a VICE app.</p>"},{"location":"de/vice/extend_apps/#create-a-new-tool","title":"Create a new Tool","text":""},{"location":"de/vice/extend_apps/#add-tool","title":"Add Tool","text":"<ol> <li> <p>If necessary, log into the  Discovery Environment.</p> </li> <li> <p>Click the  Apps and click on the \"Manage Tools\" wrench icon.</p> </li> <li> <p>You'll see a list of all of the tools in the DE. Click on \"More Actions\" and select \"Add Tool\".</p> </li> </ol> <p>Add Tool</p> <ul> <li><code>Tool name</code> is the name of the tool. This will appear in the DE's tool listing dialog. This is mandatory field. </li> <li><code>description</code> is a brief description of the tool. This will appear in the DE's tool listing dialog. </li> <li><code>version</code> is the version of the tool. This will appear in the DE's tool listing dialog. This is mandatory field.</li> <li><code>Type</code> is the type of tool. For VICE apps, choose \"interactive\"; for command line applications, choose \"executable\".</li> </ul> <p>Container Image</p> <ul> <li><code>Image name</code> is the name of the image and its public registry. This is mandatory field.</li> <li><code>Tag</code> is the image tag. If you don't specify the tag, the DE will look for the <code>latest</code> tag which is the default tag.</li> <li> <p><code>Docker Hub URL</code> is the URL of the image on Dockerhub.</p> </li> <li> <p><code>Entrypoint</code> is the Entrypoint for your tool. Entrypoint should be present in the Docker image, and if not, you should specify it here.</p> </li> <li><code>Working Directory</code> is the working directory of the tool and must be filled in with the value you gathered above, e.g., <code>/home/jovyan/work</code>.</li> <li><code>UID</code> is a number and must be filled in with the value you gathered from above. Typically <code>root</code> is <code>0</code> and default users are <code>1000</code>.</li> </ul> <p>Container Ports</p> <ul> <li><code>Ports</code> select the external port address that your graphic interface needs.</li> </ul> <p>Restrictions</p> <ul> <li><code>Max CPU Cores</code> is the number of cores for your tool, e.g., 16</li> <li><code>Memory Limit</code> is the memory for your tool, e.g., 64 GB</li> <li><code>Min Disk Space</code> is the minimum disk space for your tool, e.g., 200 GB</li> </ul>"},{"location":"de/vice/extend_apps/#required-settings","title":"Required settings","text":""},{"location":"de/vice/extend_apps/#set-the-workdir","title":"Set the <code>WORKDIR</code>","text":"<p>Executable apps to not require a working directory.</p> <p>The container needs to have a set working directory (for interactive apps), typically this is the home folder, e.g., <code>/home/jovyan</code> or <code>/home/rstudio</code> .</p> <p>Set the <code>WORKDIR</code> in the Dockerfile; if there is no set <code>WORKDIR</code>, you can set it in the Tool Builder.</p> Your Data in Your Container <p>We recommend that you set the working directory of your tool to the <code>username</code> home path in a new folder called <code>work</code>, e.g., <code>/home/jovyan/work</code> or <code>/home/rstudio/work</code>.</p> <p>This is because the Discovery Environment's interactive apps use a Kubernetes container storage interface (CSI) driver that connects the CyVerse Data Store to your working directory in the running container. This new mount can clobber any pre-existing files in the the container's <code>WORKDIR</code>. </p>"},{"location":"de/vice/extend_apps/#set-the-entrypoint","title":"Set the <code>ENTRYPOINT</code>","text":"<p>The container must have an <code>ENTRYPOINT</code> set in the Dockerfile, otherwise you must set it in the Tool itself. </p> <ol> <li>All commonly needed dependencies are installed in the container image - you will not have <code>root</code> privileges later.</li> <li>The default user set.</li> <li>Disable any additional authentication (CyVerse provides CAS authentication and authorization).</li> <li>URLs will work sanely behind a reverse proxy. If they don't, you may need to add nginx to the container.</li> </ol>"},{"location":"de/vice/extend_apps/#set-the-port","title":"Set the <code>PORT</code>","text":"<p>Interactive Apps rely on open ports to send display information to the browser.</p> <p>Ensure the listen port for the web UI has a sane default and is set in the Dockerfile, e.g. <code>PORT 8888</code> .</p> <p>You must set the port in the tool to the external port that the container is listening.</p> Understanding ports in Docker containers <p>For interactive containers like RStudio and JupyterLab, a conventional <code>docker run</code> execution will have the port set as <code>-p 8888:8888</code> where the port number on the left side of the <code>:</code> is the external port, and on the right the internal port. For VICE apps you need only be concerned about the external port number.</p> Using a reverse proxy <p>The Discovery Environment has its own authentication system, which requires us to use a reverse proxy for some containers. </p> <p>Our RStudio Server uses <code>nginx</code> to enable reverse proxy and thus we have changed the external port to <code>80</code> instead of the Rocker-Project default <code>8787</code> port number.</p> Managing ports in your new tool <p>Featured VICE apps have default port options based on the app: JupyterLab apps use port <code>8888</code>, RStudio apps use port <code>80</code>, and Shiny apps use port <code>3838</code>.</p> <p>It is strongly recommended you do not set the <code>bind to host</code> as <code>true</code> for your added ports when creating a new App.</p>"},{"location":"de/vice/extend_apps/#creating-a-vice-app-for-your-new-tool","title":"Creating a VICE app for your new tool","text":"<p>After your tool template has been saved, you can create an App for connecting your tool to the Discovery Environment. You can copy an existing app and select your tool if you like an existing App's layout. </p> <p>Alternatively, you can create a new app from a blank template.</p> Input data <p>For VICE apps, be sure to check the box \"Do not pass this argument to the command line\" for each option you add (for VICE, this is usually just input files and folders.</p>"},{"location":"de/vice/quick-app-launch/","title":"Creating a Shareable Quick Launch Button","text":""},{"location":"de/vice/quick-app-launch/#1-log-into-the-discovery-environment","title":"1. Log into the Discovery Environment","text":"<p>Log into https://de.cyverse.org</p> <p>If you have not yet created an account, go to the User Portal and sign up.</p>"},{"location":"de/vice/quick-app-launch/#2-select-app-you-want-to-share","title":"2. Select App You Want to Share","text":"<p>Navigate to the Apps tab on the left hand side menu, select the App that you want to share and click the Details button.</p> <p> </p>"},{"location":"de/vice/quick-app-launch/#3-creating-quick-launch-link","title":"3. Creating Quick Launch Link","text":"<p>At the bottom of the Details window, find the Quick Launch Share button. Clicking it will open a speech bubble with 3 choices: Saved Lunch, Embedded Code or Shared Saved Lunch URL. Copy the one you need.</p> <p> </p> <ul> <li>Saved Lunch: Saved Lunch allows you to create a launch button that starts the App with a specified set of resources.</li> <li>Embedded Code: Creates a button that can be used in websites; The button will then redirect to the App launch page. Note: to operate the App, users will require a CyVerse account. </li> <li>Shared Saved Lunch URL: Creates a link to the App.</li> </ul>"},{"location":"de/vice/quick-app-launch/#4-sharing-with-collaborators","title":"4. Sharing with Collaborators","text":"<p>Here is the link created with the Embedded Code choice:</p> <pre><code>&lt;a href=\"https://de.cyverse.org/apps/de/c2227314-1995-11ed-986c-008cfa5ae621/launch?saved-launch-id=f7eadb21-1b78-4da9-b587-baf0b5fc527e\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;&lt;img src=\"https://de.cyverse.org/Powered-By-CyVerse-blue.svg\"&gt;&lt;/a&gt;\n</code></pre> <p>This can be pasted onto a webpage to create the following button: </p>"},{"location":"de/vice/quick-cloudshell/","title":"Cloud Shell in 6 Steps","text":""},{"location":"de/vice/quick-cloudshell/#1-log-into-the-discovery-environment","title":"1. Log into the Discovery Environment","text":"<p>Log into https://de.cyverse.org</p> <p>If you have not yet created an account, go to the User Portal and sign up.</p>"},{"location":"de/vice/quick-cloudshell/#2-launch-the-app","title":"2. Launch the App","text":"<p>The Cloud Shell icon is found in the left-side navigation bar in the Discovery Environment.</p> <p></p> <p>Click on the Apps grid icon</p> <p>Cloud Shell is listed at the top of \"Featured Apps\".</p> <p>Instant Launches start Apps immediately when clicked.</p> <p>The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.</p> <p></p>"},{"location":"de/vice/quick-cloudshell/#3-open-the-analysis","title":"3. Open the Analysis","text":"<p>After you have started a VICE app, a new tab will automatically open in your browser and show the app's loading screen.</p> <p></p> <p>Once the app is ready, it will transition to the user interface (in this example, a Linux terminal).</p> <p></p> <p>You should see a \"message of the day\", information about the machine you're using, and your CyVerse username for when you initiate an iCommands connection.</p> <p>Long wait times?</p> <p>Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.</p>"},{"location":"de/vice/quick-cloudshell/#4-activate-a-conda-environment","title":"4. Activate a <code>conda</code> environment","text":"<p>The Cloud Shell comes with multiple languages and package managers pre-installed. These include <code>go</code>, <code>python</code>, and <code>rust</code>.</p> <p>Package managers include <code>conda</code> and <code>cargo</code>, in addition to linux <code>apt</code> and <code>apt-get</code>.</p> <p>Your identity inside the container is <code>user</code> and you have limited <code>sudo</code> privileges to install new packages into the container.</p> <p>These changes are not saved after the analyses ends, or when you start a new Cloud Shell Analysis later.</p> <p>Behind the CLI engine</p> <p>The Cloud Shell is running a terminal multiplexer called tmux which keeps your session active even after you've closed your browser tab. Here is a cheat sheet that can help you with tmux!</p> <p><code>tmux</code> key bindings are active.</p> <p>One side effect of using <code>tmux</code> is that you cannot scroll up in the Terminal to see previous outputs. This can make it difficult to view long outputs. If your output doesn't fit on the screen and you still want to see the whole thing, you can pipe the results of the command into <code>pager</code>.</p> <p>For instance, if you run <code>head big_file.csv -n 100</code> to view the first 100 lines of a CSV, it probably won't all fit on screen. If you run <code>head big_file.csv -n 100 | pager</code>, you will be able to move through the entire output. In the <code>pager</code>, you use the J key to scroll down, the K key to scroll up, and the Q key to exit.</p> <p>To activate conda:</p> <pre><code>conda init \n</code></pre> <p>and then:</p> <pre><code>conda activate base \n</code></pre> <p>If you receive a message about refreshing your screen, you can <code>exit</code> the Cloud Shell by typing \"exit\" and then clicking the refresh button on your browser tab.</p>"},{"location":"de/vice/quick-cloudshell/#5-using-icommands","title":"5. Using <code>icommands</code>","text":"<p>To connect to the CyVerse Data Store, you can initiate an iRODS iCommands <code>iinit</code>.</p> <p>You should now be connected to your <code>/iplant/home/username</code> home directory.</p>"},{"location":"de/vice/quick-cloudshell/#ils","title":"ils","text":"<pre><code>ils /iplant/home/username/ \n</code></pre> <p>To view the 'shared' directory, type:</p> <pre><code>ils /iplant/home/shared \n</code></pre>"},{"location":"de/vice/quick-cloudshell/#iget","title":"iget","text":"<p>Download data into your Cloud Shell with iCommands by running <code>iget</code>:</p> <p><code>iget -KPbvrf /iplant/home/shared/cyverse_training/</code></p>"},{"location":"de/vice/quick-cloudshell/#iput","title":"iput","text":"<p>After you finish your analyses, you can save the outputs to Data Store.</p> <p>Use <code>iput</code> to copy your new files back to your user space, or if you've left your new work in the <code>/home/user/work/data/outputs</code> folder, it will be copied back to your <code>/iplant/home/username/Analyses/</code> directory.</p> <p>To find the outputs you generated (if any), use the same steps as before, but this time select the 'Go To Output Folder'.</p>"},{"location":"de/vice/quick-cloudshell/#6-terminate-your-app","title":"6. Terminate your app","text":"<p>The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses.</p> <p>In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", and then \"Terminate\" to shut down the app.</p> <p>Any new data in the <code>/home/user/work/data/output</code> directory will begin copying back to your folder at this time.</p> <p>Any input data which you added when the app started using the conventional launch feature will not be copied.</p> <p>Automatic Termination and Extension</p> <p>VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours.  If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. </p> <p>To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.</p>"},{"location":"de/vice/quick-jupyter/","title":"JupyterLab in 6 Steps","text":""},{"location":"de/vice/quick-jupyter/#1-log-into-discovery-environment","title":"1. Log into Discovery Environment","text":"<p>Log into https://de.cyverse.org.</p> <p>If you have not yet created an account, go to the User Portal to sign up.</p>"},{"location":"de/vice/quick-jupyter/#2-launch-the-app","title":"2. Launch the App","text":"<p>Click on the Apps grid icon.</p> <p>Jupyter Lab Datascience is in \"Featured Apps\".</p> <p>Instant Launches start Apps immediately when clicked.</p> <p>The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.</p> <p></p>"},{"location":"de/vice/quick-jupyter/#3-open-the-analysis","title":"3. Open the Analysis","text":"<p>After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen.</p> <p></p> <p></p> <p>Once the app is ready, it will transition to the user interface. </p> <p></p> <p>The Jupyter Lab Interface:  While Jupyter Lab has many features found in traditional integrated development environments (IDEs), it remains focused on interactive, exploratory computing.  The Jupyter Lab interface consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list.</p> <p>More information about the Jupyter Lab can be found here.</p> <p>Long wait times?</p> <p>Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.</p>"},{"location":"de/vice/quick-jupyter/#4-create-a-new-conda-environment","title":"4. Create a new <code>conda</code> environment","text":"<p>From Jupyter's Launch menu, select the black Terminal console icon.</p> <p>This will take you to a command line shell.</p> <p>Change directory, or download a sample <code>environment.yml</code> file:</p> <pre><code>$ cd /home/shared/cyverse_training/platform_guides/discovery_environment/jupyterlab/\n$ conda env create -f environment.yml\n</code></pre> <p>or</p> <pre><code>$ wget https://data.cyverse.org/dav-anon/iplant/commons/community_released/cyverse_training/platform_guides/discovery_environment/jupyterlab/environment.yml\n$ conda env create -f environment.yml\n</code></pre> <p>and then:</p> <pre><code>$ conda activate python39 \n</code></pre>"},{"location":"de/vice/quick-jupyter/#5-create-jupyter-notebook","title":"5. Create Jupyter notebook","text":"<p>Jupyter notebooks (<code>.ipynb</code>) combine code with narrative text (Markdown), equations (LaTeX), images and interactive visualizations.</p> <p>To create a notebook, click the <code>+</code> button which opens the new Launcher tab.</p> <p>The JupyterLab Datascience containers have three pre-installed kernels: Python3, Julia, and R.</p> <p>Official Jupyter Notebooks</p> <p>To open the classic Notebook view from JupyterLab, select \"Launch Classic Notebook\" from the Help Menu.</p>"},{"location":"de/vice/quick-jupyter/#6-terminate-your-app","title":"6. Terminate your app","text":"<p>The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses.</p> <p>In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", then \"Terminate\" to shut down the app.</p> <p></p> <p>Any new data in the <code>/home/jovyan/work/data/outputs</code> directory will begin copying back to your folder at this time.</p> <p>Any input data which you added when the app started using the conventional launch feature will not be copied.</p> <p>Automatic Termination and Extension</p> <p>VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours.  If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. </p> <p>To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.</p>"},{"location":"de/vice/quick-ollama/","title":"Running your LLM for inference with Ollama","text":""},{"location":"de/vice/quick-ollama/#1-log-into-discovery-environment","title":"1. Log into Discovery Environment","text":"<p>Log into https://de.cyverse.org.</p> <p>If you have not yet created an account, go to the User Portal to sign up.</p>"},{"location":"de/vice/quick-ollama/#2-launch-the-jupyterlab-pytorch-gpu-app","title":"2. Launch the JupyterLab Pytorch GPU App","text":"<p>Click on the Apps grid icon.</p> <p>Jupyter Lab Pytorch GPU is in \"Featured Apps\".</p> <p>Instant Launches start Apps immediately when clicked.</p> <p>The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.</p> <p></p>"},{"location":"de/vice/quick-ollama/#3-open-the-analysis","title":"3. Open the Analysis","text":"<p>After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen.</p> <p></p> <p></p> <p>Once the app is ready, it will transition to the user interface. </p> <p></p> <p>We will focus on running an llm for inference using Ollama as a server. The Jupyter Lab with Pytorch GPU, comes with Ollama preinstalled, which is necessary to run LLMs. The Jupyter Lab interface consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running kernels and terminals, the command palette, the notebook cell tools inspector, and the tabs list.</p> <p>Long wait times?</p> <p>Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.</p>"},{"location":"de/vice/quick-ollama/#4-download-and-run-an-llm-using-ollama","title":"4. Download and run an LLM using Ollama","text":"<p>From Jupyter's Launch menu, select the black Terminal console icon.</p> <p>This will take you to a command line shell.</p> <p>Run the following command to start Ollama in server mode:</p> <p><pre><code>$ ollama serve\n</code></pre> Without closing the shell tab, Ollama will be running in server mode, ready to be called from any jupyter notebook or python script.</p> <p>Open a new tab with a console and then, pull the model you're interested in. For example <code>llama 3.1</code>:</p> <p><pre><code>$ ollama pull llama3.1\n</code></pre> It is necessary to fetch ahead of time the model you're interested in using. You can find the list of supported LLMs at (https://ollama.com/search)[Ollama's Hub].</p>"},{"location":"de/vice/quick-ollama/#5-create-jupyter-notebook-to-interface-with-the-llm","title":"5. Create Jupyter notebook to interface with the LLM.","text":"<p>Ollama LLM usage example</p> <p>After starting Ollama in server mode and downloading the relevant models, you can run your code that uses the aformentioned models.</p> <p>To create a notebook, click the <code>+</code> button which opens the new Launcher tab.</p> <p>To open the classic Notebook view from JupyterLab, select \"Launch Classic Notebook\" from the Help Menu.</p> <p>Create a new jupyter notebook to where can use any llm client library to interface with the LLM. DataLab has a reference notebook with a usage example using ollama's client libary.</p> <p>Alternatively, you can use langchain, llama-index, the OpenAI API client library or any other client library that speaks OpenAI's REST API.</p>"},{"location":"de/vice/quick-ollama/#6-terminate-your-app","title":"6. Terminate your app","text":"<p>The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses.</p> <p>In the Analyses window, select the app (by clicking the checkbox next to it), select \"More Actions\", then \"Terminate\" to shut down the app.</p> <p></p> <p>Any new data in the <code>/home/jovyan/work/data/outputs</code> directory will begin copying back to your folder at this time.</p> <p>Any input data which you added when the app started using the conventional launch feature will not be copied.</p> <p>Automatic Termination and Extension</p> <p>VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours.  If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. </p> <p>To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.</p>"},{"location":"de/vice/quick-rstudio/","title":"RStudio in 6 Steps","text":""},{"location":"de/vice/quick-rstudio/#1-log-into-discovery-environment","title":"1. Log into Discovery Environment","text":"<p>Log into https://de.cyverse.org</p> <p>If you have not yet created an account, go to the User Portal and sign up.</p>"},{"location":"de/vice/quick-rstudio/#2-launch-the-app","title":"2. Launch the App","text":"<p>Click on the Apps grid icon</p> <p>RStudio Verse is in \"Featured Apps\".</p> <p>Instant Launches start Apps immediately when clicked.</p> <p>The conventional launch menu allows you to modify the App parameters. You can add input data, increase the amount of RAM or CPU cores, and change the analysis directory.</p> <p></p>"},{"location":"de/vice/quick-rstudio/#3-open-the-analysis","title":"3. Open the Analysis","text":"<p>After you have started a VICE app, a new tab will automatically open in your browser and take you to the loading screen.</p> <p></p> <p>Once the app is ready, it will transition to the user interface. </p> <p></p> <p>RStudio Interface:  RStudio is a free, open source IDE (integrated development environment) for R.  Its interface is organized so that the user can clearly view graphs, data tables, R code and ouput at the same time.  It also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SAS (.sas7bdat), SPSS (.sav), and Stata (*.dta) files into R without having to write the code to do so.</p> <p>More information about RStudio can be found here.</p> <p>Long wait times?</p> <p>Normal wait time for a featured VICE app to launch is less than 2 minutes. If you're experiencing a significantly longer wait, consider terminating the Analysis and starting a new one.</p>"},{"location":"de/vice/quick-rstudio/#4-create-an-rstudio-project","title":"4. Create an RStudio Project","text":"<p>You can create RStudio projects using local data, or from Git.</p> <p></p> <p>This example uses Leaflet Maps in RStudio.</p> <p></p> <p>You can then run R commands and install packages.</p> <p></p> <p></p>"},{"location":"de/vice/quick-rstudio/#5-terminate-your-app","title":"5. Terminate your app","text":"<p>The Discovery Environment is a shared system. In fairness to the community, users should \"Terminate\" any apps that are no longer actively running analyses.</p> <p>In the Analyses window, select the app (by clicking the checkbox next to it), then select \"More Actions\", then \"Terminate\" to shut down the app.</p> <p></p> <p>Any new data in the <code>/home/rstudio/data-store/data/output</code> directory will begin copying back to your folder at this time.</p> <p>Any input data which you added when the app started using the conventional launch feature will not be copied.</p> <p>Automatic Termination and Extension</p> <p>VICE apps run for a pre-determined amount of time, typically between 4 and 48 hours.  If you have opted for email notifications from the DE, then you'll get a notification 1 day before and another 1 hour before the app will terminate. </p> <p>To extend the pre-set run time, go to your analysis and click the hour glass icon which automatically extends the app run time.</p>"},{"location":"dev/manuals/","title":"Documentation Webpages","text":"<p>Table: Documentation websites for each CyVerse platform</p> Platform Purpose Link Data Store data hosting and storage Data Store Discovery Environment UI analysis and workbench Discovery Environment Discovery Environment API API access DE API Manual CACAO Jetstream2 Cloud Services CACAO Documentation Atmosphere (Deprecated) Cloud Services Atmosphere Manual BISQUE (Deprecated) Image Analysis BiSQUE Guide DNA Subway (Deprecated) Genomics Education DNA Subway Guide TAPIS TACC APIs TAPIS"},{"location":"ds/","title":"Data Store","text":"<p>CyVerse Data Store runs the Integrated Rule-Oriented Data System (iRODS) Open Source Data Management Software.</p> <p>iRODS helps researchers, archivists, and others manage large, geographically dispersed computer files by providing a virtual filesystem, metadata catalog, and a rule engine to automate data management and enforce policies. </p> <p>The Data Store is designed for storing, managing, and sharing your data throughout its entire lifecycle. </p> <p>Integrated across all CyVerse platforms, the Data Store has high accessibility and connectivity.  </p> <p>The Data Store's features are aimed at helping you maintain data integrity and value, while making your data more FAIR (Findable, Accessible, Interoperable, and Reusable) with minimal effort.</p> <p>This guide will walk you through the essential steps to get started, assuming you\u2019ve already created a CyVerse account.</p>"},{"location":"ds/#data-management","title":"Data Management","text":"<p>There are several ways to access the Data Store. These methods vary in speed, flexibility, and technical knowledge required. Different methods may suit your needs for different projects at different times.</p> Method Access Point OS Upload/Download Installation/Setup Required Account Required Max File Size Discovery Environment Web Any Both No Yes 2GB/file upload, no limit for import WebDAV Web &amp; Command line Any Both No Yes (No for public data) No limit GoCommands Command line Any Both Yes Yes (No for public data) No limit iCommands Command line Linux &amp; macOS Both Yes Yes (No for public data) No limit SFTP Desktop App &amp; Command line Any Both No (Yes for desktop app) Yes (No for public data) No limit <p>This section covers each of the following data management methods:</p> <ol> <li>Discovery Environment: A comprehensive web-based platform for data analysis and management</li> <li>GoCommands: A lightweight, portable command-line tool for efficient data operations on any OS</li> <li>iCommands: A powerful command-line suite for advanced data management tasks on Linux</li> <li>SFTP: A secure file transfer protocol accessible via command-line or GUI applications on any OS</li> <li>WebDAV: A protocol extending HTTP for collaborative file management over the internet, usable on any OS</li> </ol> <p>Additional resources for managing your data and team collaboration:</p> <ol> <li>Getting a DOI: Obtain a Digital Object Identifier (DOI) for a permanent and stable link to your data</li> <li>Checking Data Usage: Monitor your data usage and storage limits</li> <li>Team Access Management: Create and manage teams in the Data Store for collaborative work</li> </ol>"},{"location":"ds/#manage-your-data-in-discovery-environment","title":"Manage Your Data in Discovery Environment","text":"<p>The Discovery Environment has a fully managed interface for uploading, downloading, sharing, and adding metadata to the Data Store through your browser.</p>"},{"location":"ds/#manage-your-data-with-gocommands","title":"Manage Your Data with GoCommands","text":"<p>GoCommands is a lightweight and portable command-line tool designed for efficient data management within the Data Store. This section provides guidance on how to set up and use GoCommands to interact with the Data Store.</p>"},{"location":"ds/#manage-your-data-with-icommands","title":"Manage Your Data with iCommands","text":"<p>iCommands is a powerful command-line tool designed for data management in iRODS. It enables you to manage data in the Data Store efficiently via the command line. This section covers how to install and use iCommands for streamlined data transfers and management.</p>"},{"location":"ds/#transferring-data-with-sftp","title":"Transferring Data with SFTP","text":"<p>SFTP (Secure File Transfer Protocol) is a widely adopted network protocol for secure file access, transfer, and management. This section explains how to use SFTP to move your data to and from the Data Store.</p>"},{"location":"ds/#http-access-with-webdav","title":"HTTP Access with WebDAV","text":"<p>WebDAV (Web Distributed Authoring and Versioning) is a protocol built on top of HTTP/HTTPS, allowing users to manage data on web servers. This section demonstrates how to use WebDAV for seamless data access and management within the Data Store.</p>"},{"location":"ds/#getting-a-doi","title":"Getting a DOI","text":"<p>A Digital Object Identifier (DOI) offers a permanent and stable link to your data. Learn how to obtain a DOI for your datasets stored in the Data Store, ensuring long-term citation and accessibility.</p>"},{"location":"ds/#checking-data-storage","title":"Checking Data Storage","text":"<p>Keep track of your data usage and storage limits. This section covers tools and techniques for monitoring your data storage within the Data Store.</p>"},{"location":"ds/#managing-data-within-a-team","title":"Managing Data within a Team","text":"<p>Efficiently manage team access and permissions for your data. Learn how to create and manage teams in the Data Store to facilitate collaborative data work.</p>"},{"location":"ds/de/","title":"Data Store in Discovery Environment","text":"<p>With CyVerse, you can manage data throughout the data lifecycle, from uploading, to adding metadata, to analyzing, sharing results, and making your data public for others to reuse. </p> <p>The  Discovery Environment interface is just one of many ways to access, view, and manage your files in the Data Store.</p> <p>What is the Data Store?</p> <p>The Data Store is not a separate platform; it is a service that crosscuts all of CyVerse so you can access your files (yours, shared with you, public) from anywhere in CyVerse.</p> <p>Data Store description</p>"},{"location":"ds/de/#browsing-data-in-the-discovery-environment","title":"Browsing Data in the Discovery Environment","text":"<ol> <li> <p>After logging in, click on the  Data icon in the left navigation menu.</p> <p></p> <p>To see and browse information about your data files in the Data view, press the \"Customize Columns\" button to select more (or fewer) columns to display, such as size, modification date, permissions, etc.</p> </li> <li> <p>If the folder you're viewing has many items in it, use the &lt; or &gt; at the bottom of the page to move between pages. You can also change the number of items displayed per page.</p> </li> <li> <p>In the upper left, you should see a \"Community Data\" box. If you click on this box, you can change directories to view your data files (\"Home\"), or data shared with your username (\"Shared with me\"), or files in your \"Trash\". </p> <p></p> <p>As you access the folders or files within your directory, breadcrumbs near the top of the page show the folder you are viewing and its parent folder(s).</p> </li> <li> <p>At the start of the breadcrumbs, you may select another root folder to view from within your home folder; click on the dropdown near your username to browse folders/files in \"Shared With Me\", \"Community Data\", or \"Trash\".</p> </li> </ol>"},{"location":"ds/de/#viewing-filefolder-details-in-the-discovery-environment","title":"Viewing File/Folder Details in the Discovery Environment","text":"<p>Both the \"Details\" button near the top right and the More Options menu (ellipses) at the far right in a file or folder's row allow you to view and manage several types of information about your file/folder.</p> <p>You must be logged in to view file/folder details.</p> <ol> <li> <p>From the  Data view, click the checkbox next to a file or folder to select it and then click the \"Details\" or the ellipses to see specific information about the selected item, to copy the file path to the item, to add tags to the item, to edit metadata, or to set a file's info type.</p> </li> <li> <p>To view your permissions on the item and those of other users, click the \"Permissions\" tab under \"Details\".</p> </li> </ol>"},{"location":"ds/de/#uploading-filesfolders-to-the-data-store-via-the-discovery-environment","title":"Uploading Files/Folders to the Data Store via the Discovery Environment","text":"<p>The Data view shows a directory of the files and folders in your Data Store. </p> <p>You can select an existing folder as the destination for your uploaded file(s) or click the Folder button to create a new folder. The default file destination is your home Data Store folder (i.e., <code>/iplant/home/&lt;your_username&gt;</code>).</p> <p>Click the \"Upload\" button to choose your options for importing files into the Data Store:</p> <ul> <li>To upload files from your local computer, choose Browse Local; a file browser will open and you may select files to upload.</li> <li>To upload files from a URL, choose Import by URL; you may paste in a valid HTTP or an FTP URL, then click Import. You may paste additional URLs or close the window by clicking Done.</li> <li>When you have begun the upload, you will get an automated notification that the file(s) has been queued. To view the status of an upload or import, click the Upload button and choose View Upload Queue.</li> </ul>"},{"location":"ds/de/#deleting-filesfolders-in-the-discovery-environment","title":"Deleting Files/Folders in the Discovery Environment","text":"<p>You must be logged in and you must own the files or folders you wish to delete. </p> <p>From the  Data view, select the desired file/folder by clicking the checkbox to its left. You can select multiple files/folders. To unselect an individual file/folder, click the checkbox again. You can select (or unselect) all files/folders at once by clicking the checkbox at the top of the list.</p> <p>Click on the More Options menu (ellipsis) in the upper right corner of the  Data view and select Delete from the pop-up menu. When the file has been fully deleted, you will receive an automated notification (bell icon, upper right). When deleting or moving a file/folder, you cannot change anything associated with that file/folder until you receive the completion notification.</p> <p>Deleted files can be retrieved from your Trash. </p> <p>Uploading/Importing Data via the Browser</p> <ul> <li>You can use the DE interface to upload files of &lt;2GB to the Data Store.</li> <li>When your Data Store file browser is open, you can also upload files from your computer by dragging them into your browser window.</li> <li>While uploading or downloading data via your browser, you must remain on the Data View until the task completes.</li> <li>The queue will only display the status of uploads from local files. </li> <li>Files imported by URL will generate an automated notification upon completion (or failure) to upload.</li> <li>When importing data from a URL, you can log out or navigate to another page or operation after you start the import; you will recieve an automated email notification when the task is complete.</li> <li>For larger files or large numbers of files, we recommend using other methods such as SFTP or GoCommands. </li> </ul>"},{"location":"ds/de/#emptying-trash-after-deleting-filesfolders-in-the-discovery-environment","title":"Emptying Trash after Deleting Files/Folders in the Discovery Environment","text":"<p>Your data store allocation will not reflect deleted files/folders until you have deleted files from your Trash. To empty Trash, follow these steps:</p> <ul> <li>Empty the Trash: Navigate to your Trash folder. (You may find it under \"Data\" icon in the left navigation menu, click on the dropdown near your username to browse folders/files in \"Trash\")</li> <li>Once you're in the \"Trash\" folder, navigate to the right corner and click \"Trash\" followed by \"Empty Trash\" to permanently delete the data from your Trash folder. </li> <li>Wait for processing: It sometimes takes CyVerse systems a few hours to fully process file deletions, so you may not see your data storage allocation increase for several hours.</li> </ul>"},{"location":"ds/de/#advanced-data-management-features-in-the-discovery-environment","title":"Advanced Data Management Features in the Discovery Environment","text":"<p>The Discovery Environment also supports advanced data management tasks such as organizing your datasets, search, adding metadata to data, requesting a Digital Object Identifier (DOI), and importing or submitting data to/from NCBI SRA. </p> <p>To use the Advanced Search, run a query in the Search menu, then select \"Advanced Search Options\".</p> <p></p>"},{"location":"ds/de/check_data/","title":"Checking Your Data Storage Quotas","text":"<p>You can see how much data you are storing in the Data Store from the Resource Usage area of the Discovery Environment Home screen. But what if you want to delete some large folders, or check for duplicate files? The DataHog app can help you understand more about the size of the folders and files you have in the Data Store.</p>"},{"location":"ds/de/check_data/#resource-usage-view-discovery-environment","title":"Resource Usage view Discovery Environment","text":"<p>Log into the Discovery Environment. After logging in, your resource usage will be displayed on the main page.</p>"},{"location":"ds/de/check_data/#checking-folder-size-using-datahog","title":"Checking Folder Size using DataHog","text":"<ol> <li>Log into the Discovery Environment.</li> <li>Click on the  to view or browse Apps.</li> <li>In the search bar, at the top of the page, enter <code>DataHog</code>, and the click on the App suggestion that appears in the drop-down box.</li> <li>Proceed through the app launch wizard, choosing the defaults. During the Review and Launch step, push the Launch Analysis button.</li> <li>When the app is running, push the Go to Analysis button.</li> <li>Enter your CyVerse password and click Import from iRODS. You will also see a CyVerse tab but the iRODS tab is currently the preferred way to view data in CyVerse.</li> <li> <p>Once the import is complete, you will see a Summary of your data including a breakdown by file type, lists of files and folders by size, and lists of files and folders by date. There are other tabs to identify Duplicated Files as well as to import other storage sources so that you get a global view of your data. Click here to watch a 1-minute video on how to use DataHog.</p> <p> </p> </li> </ol>"},{"location":"ds/de/doi/","title":"Getting a DOI","text":"<p>CyVerse provides Digital Object Identifiers (DOIs) for archiving research data, ensuring long-term stability and citability. DOIs are assigned through CyVerse Curated Data in the Data Commons, our dedicated space for preserving research outputs.</p> <p>DOIs are only available to users with a paid subscription. 'Basic' (free) CyVerse accounts do not qualify. To upgrade, explore our pricing and subscription options here: https://cyverse.org/subscribe.</p>"},{"location":"ds/de/doi/#doi-request-quickstart","title":"DOI Request Quickstart","text":""},{"location":"ds/de/doi/#organize-data","title":"Organize data","text":""},{"location":"ds/de/doi/#create-submission-folder","title":"Create submission folder","text":"<ul> <li>Organize your data so that there is one folder for each DOI (named according to the Data Commons Naming Conventions--see Step\u00a01.b)</li> <li>Within that folder, include all files in your data package plus the ReadMe file and the inventory.</li> <li>You may have subfolders within a data package.</li> <li>You may include compressed files in a package, as described on the FAQ, but do not compress the entire folder/package.</li> </ul>"},{"location":"ds/de/doi/#name-your-top-level-folder-according-to-the-data-commons-naming-conventions","title":"Name your top level folder according to the Data Commons Naming Conventions**","text":"<p>CyVerse Curated Data datasets are searchable and discoverable based on their metadata. While the dataset itself can have any name chosen by the creator (within reason), the folder that contains the dataset must follow the naming practices described on this page.</p>"},{"location":"ds/de/doi/#general-guidelines","title":"General guidelines","text":"<ul> <li>Folder names must be unique.</li> <li>No invalid characters: Be sure there are no spaces or special characters in the folder name.</li> <li>Use underscores between each segment.</li> </ul>"},{"location":"ds/de/doi/#folder-name-format","title":"Folder Name Format","text":"<p>$Creator_$subject_$date</p> <p>$Creator:</p> <ul> <li>The Creator entry should be the same as entered in the Creator field of the DOI request - DataCite Metadata request form.</li> <li>The Creator is the lead author, the senior author, or the organization with the primary responsibility for the dataset. Start the field (the creator's name) with a capital letter.</li> </ul> <p>Co-creators:</p> <ul> <li>If there are two co-creators, use both names, separated by an underscore or using camel case.</li> <li>For three or more co-creators, select only one name or use a consortium name. Other contributors should be acknowledged in the metadata (as creators or contributors), which will display on the dataset landing page.</li> </ul> <p>$subject:</p> <ul> <li>Very briefly describes what the dataset is about.</li> <li>If the subject is more than one word, use either camel case (example: camelCase) or underscores (example: underscore_between_words) to separate the words.</li> <li>If another folder has the exact same name, you may modify the subject slightly to maintain uniqueness.</li> </ul> <p>$date:</p> <ul> <li>Either just the year, or the month and year, in which the dataset was created.</li> <li>Month and year should be used only if there is likely to be more than one dataset with the same creator and subject within the same year.</li> <li>Month must be a three-letter abbreviation: Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Nov, or Dec.</li> </ul>"},{"location":"ds/de/doi/#examples","title":"Examples","text":"<p>Valid Names</p> <ul> <li>Walls_yam_variation_2015</li> <li>DeBarry_yamGenomicVariation_2016</li> <li>Esteva_yam_variation_Mar2016</li> <li>Esteva_Walls_yam_genomic_variation_Jun2016</li> <li>YamConsortium_Dioscorea_variation_Nov2017</li> </ul> <p>Invalid Names</p> <ul> <li>WallsYamVariation_2016 (Missing underscore between the creator and the subject)</li> <li>Esteva_yam_variation_June2016 (Month should be three letters: Jun)</li> <li>YamConsortium_Nov2017 (No subject)</li> <li>Walls_yam_variation_2016#1 (Contains a special character)</li> <li>Walls YamVariation 2020 (Contains spaces)</li> </ul> <p>Not recommended</p> <p>Although the following will pass validation, they are not recommended because the subject is too vague or too detailed:</p> <ul> <li>Walls_variation_2016 (Subject too vague)</li> <li>Esteva_yam_Mar2016 (Subject too vague)</li> <li>DeBarry_yam_genetic_and_environmental_variation_with_phenotype_data_version3_Dioscorea_2016 (Too detailed)</li> </ul>"},{"location":"ds/de/doi/#create-a-readme-file","title":"Create a ReadMe file","text":"<p>Create a text file labeled something like README with the following information:</p> <ul> <li>How you obtained, organized, and labeled your dataset.</li> <li>How to reuse the data, such as which apps can analyze the data.</li> <li>The inventory (see Step\u00a01.d) may be included as part of the ReadMe file.</li> <li>If your data include sequences, the ReadMe should include a list of corresponding BioSample IDs.</li> <li> <p>Examples of good ReadMe files:</p> <ul> <li>https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Carolyn_Lawrence_Dill_GOMAP_Cacao_NCBI_CriolloV2_March_2021.r1/_README.txt</li> <li>https://datacommons.cyverse.org/browse/iplant/home/shared/commons_repo/curated/Liang_Schnable_UNLPlantVision_2017/readMe.txt</li> </ul> </li> </ul>"},{"location":"ds/de/doi/#create-an-inventory","title":"Create an inventory","text":"<p>You must create a plain text document that includes an inventory of the contents of the organized dataset (at a minimum, your dataset will contain one data file and one ReadMe file).</p> <ul> <li>The inventory may be part of the ReadMe file or a separate file.</li> <li>The inventory should include the ReadMe file and any other additional non-data materials you add to your dataset.</li> <li>If your dataset contains folders with many files (e.g., large collections of images), you do not need to list each file in the inventory. Simply describe the folder and what it contains.</li> <li>Describe the file naming conventions, if that is helpful.</li> </ul>"},{"location":"ds/de/doi/#example-inventory","title":"Example Inventory","text":"<pre><code>Lyons_DOI-Example-Aug2020/:  Top level directory name\n   README.txt:               Plain text file that describes the origin of the data,\n                                experiments, data processing, etc. Also contains a list and\n                                description for the contents of the top-level directory\n                                (unless a separate inventory file is provided)\n   License.txt:              License file (e.g., GPL, MIT) that governs the use of the data\n   a.data1/:                 Directory containing data\n   b.data2/:                 Directory containing more data\n   c.data3/:                 Directory containing even more data\n</code></pre>"},{"location":"ds/de/doi/#add-metadata","title":"Add metadata","text":"<ul> <li>You must provide all required metadata in the DOI Request--Datacite 4.1 template at a minimum.</li> <li>You may add any additional metadata that is appropriate. We encourage the use of additional metadata to make your data better understood and more discoverable. For more information, including how to apply metadata, see Adding Metadata.</li> </ul> <p>Tip</p> <p>Get recognition for your work by including ORCIDs for yourself and all creators and contributors.</p> <ol> <li> </li> <li> </li> <li> </li> <li> </li> <li> </li> <li> </li> </ol>"},{"location":"ds/de/doi/#in-the-data-window-click-the-checkbox-next-to-the-folder","title":"In the Data window, click the checkbox next to the folder.","text":""},{"location":"ds/de/doi/#select-more-actions-metadata","title":"Select More Actions &gt; Metadata.","text":""},{"location":"ds/de/doi/#select-more-actions-again-view-in-template","title":"Select More Actions (again) &gt; View in Template.","text":""},{"location":"ds/de/doi/#choose-the-doi-request-datacite41-metadata-template","title":"Choose the DOI Request - DataCite4.1 metadata template.","text":""},{"location":"ds/de/doi/#complete-the-required-fields-marked-with-an-asterisk-and-as-many-of-the-optional-fields-as-possible","title":"Complete the required fields (marked with an asterisk) and as many of the optional fields as possible.","text":"<p>Warning</p> <p>Be sure to include at least 3 subject key words or phrases, so that people can discover your data (Findability)! Each subject should be in its own field (click on the plus next to Subject to add a subject field. DO NOT use a comma-separated list.)</p>"},{"location":"ds/de/doi/#save-the-template","title":"Save the template.","text":""},{"location":"ds/de/doi/#submit-request-and-wait-for-validations","title":"Submit request and wait for validations","text":""},{"location":"ds/de/doi/#before-you-submit","title":"Before you submit","text":"<p>Check the following to be sure everything is in order.</p> <ul> <li>There are no spaces or special characters in your file or folder names.</li> <li>You have included a ReadMe file that includes all the information specified in Step\u00a01.c.</li> <li>You followed the Data Commons Naming Conventions</li> <li>You have filled in all the required fields in the DOI Request - DataCite 4.1 metadata template</li> <li>You have included at least 3 subjects in your metadata</li> <li>Each subject is in a separate field (not comma-separated).</li> <li>The description in your metadata is adequate (other users can tell what your data describe).</li> <li>You understand that once the DOI is issued you cannot change the data. If you know your data will change you should consider waiting to request a DOI. If you do need to make changes later this DOI can be deprecated, a new DOI issued, and the two DOIs linked together as versions.</li> </ul>"},{"location":"ds/de/doi/#submit-doi-request","title":"Submit DOI request","text":"<p>In the Data tab, click the checkbox next to the folder.</p> <p></p> <p>Select More Actions &gt; Request DOI.</p> <p> </p> <p>After verifying you have read the instructions (i.e., this guide), click Request DOI. You will receive a verification email that your request has been received, and a notification will be listed in the Notifications list in the DE.</p> <p>At this point, your folder will move to a new location under Community Data/commons_repo/staging.</p>"},{"location":"ds/de/doi/#validations","title":"Validations","text":"<ul> <li>After submitting your request, a CyVerse curator begins validating your dataset, metadata, and overall configuration of your dataset.</li> <li>Validations are based solely on the required DOI metadata and folder-naming conventions, as well as the data's potential utility to the CyVerse and larger scientific community, not the quality of your data. This is not a peer review process.</li> </ul> <p>Possible validation actions</p> <ul> <li>If the curator determines that minor changes are needed, they may make those changes themselves.</li> <li>If the curator determines that substantive changes are needed, they will contact you with required changes.</li> <li>If the curator determines that your dataset is not appropriate for the Curated Data section of the Data Commons (e.g., because it belongs in NCBI), you will be notified.</li> <li>If the curator determines that the dataset is adequately organized and the DataCite metadata are accurate, they will provide a DOI, and you will be notified of the DOI and the final dataset location.</li> </ul> <p>To check the status of your DOI request, click Notifications (the bell icon) at the top right of the DE screen.</p>"},{"location":"ds/de/doi/#after-publication","title":"After publication","text":""},{"location":"ds/de/doi/#get-your-dataset-noticed","title":"Get your dataset noticed","text":"<p>Metadata, the description about your data, is key to getting your dataset noticed in the world wide web. Search engines and bibliographic aggregators index the metadata that you create to obtain a DOI. Thus, it is important that you do the following:</p> <ul> <li>Make sure the metadata are complete.</li> <li>Include precise keywords in the Subject attribute.</li> <li>Include descriptive terms about the science and themes involved in your research. These can go in the Subject attribute, but you can also create additional metadata attributes specific to your dataset.</li> <li>Include methods used to generate the dataset in the Description attribute, and in more detail in a ReadMe file.</li> <li>Describe the dataset for a broader audience so that they understand your research. Use the Description field for this.</li> <li>If you or team members have an ORCID ID, make sure to include it in the metadata.</li> </ul>"},{"location":"ds/de/doi/#publicize-your-dataset","title":"Publicize your dataset","text":"<ul> <li>Consider using social media to share the DOI of your dataset, and tag CyVerse.</li> <li>If you have an interesting story about your data, contact us at learning@cyverse.org, and we may be able to share it through CyVerse outreach.</li> <li>If you have a tool or workflow you developed to analyze your data in CyVerse, consider presenting it as part of our CyVerse Webinars.</li> </ul>"},{"location":"ds/de/doi/#faq","title":"FAQ","text":"<p>Why should I publish my data in CyVerse Curated Data?</p> <p>CyVerse Curated Data is the ideal platform for ease of data reuse. Because it is assigned a permanent identifier (DOI), it is stable and unchangeable, making it ideal for data citation. Because the data is stored in large-scale storage resources that are monitored 24/7, it is secure. Because it allows transfer, upload, and download across different computers and platforms, it can store very large datasets. And because its data is accessible to CyVerse's suite of large-scale computational analysis resources, users can seamlessly analyze, manage, and publish new results. For more information, see Is CyVerse Curated Data Right for My Data?.</p> <p>What are the conditions for data to be published through CyVerse Curated Data?</p> <p>Several conditions must exist in your data before it can be published in CyVerse Curated Data:</p> <ul> <li>You must be a registered CyVerse account holder. To register for an account, see the Create Account Quickstart.</li> <li>A dataset may be up to 100\u00a0GB in size. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier using this form.</li> <li>Data must be both curated and static. Once the data is published, it cannot be amended (although newer versions can be published).</li> <li>Data must be organized to identify the different components (raw, preprocessed, analysis, etc.).</li> <li>Compressed files must be in LASzip or open-source gzip family of compression formats including zip, tar, or tar.gz (tgz).</li> <li>At minimum, the dataset must include a complete description according to the DataCite standard. Domain-specific schemas, however, and the addition of ReadMe files, publications, or help notes that explain the data as well as how they were obtained and can be used, are encouraged. In organizing and documenting the data, users should ask themselves, Why would someone need to reuse this data?</li> </ul> <p>Can I publish to the Data Commons if my data is not static and curated by CyVerse?</p> <p>Yes, you can make data available to the public via Community Released Data. You can request a community release data folder using this form.</p> <p>What is a DOI?</p> <p>A DOI is a Digital Object Identifier. It is a permanent, redirectable identifier and URL for your dataset, so that even if the location of your dataset changes, it can still be found with the same ID. DOIs are issued by CyVerse through the DataCite service.</p> <p>Do I need to contact CyVerse before requesting a DOI?</p> <p>The process of requesting a DOI is automated through the DE, but some tasks must be handled manually, such as DOIs for datasets with more than 1000 files or DOIs for datasets that are stored somewhere other than <code>/iplant/home/share/commons_repo/curated</code>. If you match either of those cases, please contact us at doi@cyverse.org.</p> <p>Also contact us if you have questions about how to organize your data or what scientific metadata to include.</p> <p>How much does a CyVerse permanent identifier cost?</p> <p>At this time, CyVerse does not charge for DOIs. However, the dataset must meet the requirements given in the section Is CyVerse Curated Data Right for My Data?. In the future, there may be a charge for issuing permanent identifiers in the CyVerse Data Commons.</p> <p>How long will it take to obtain a permanent identifier and publish my data?</p> <p>Provided that your dataset is in good order and ready to be published, the process may take up to one week, as it may involve a dialogue with the CyVerse data curators. If your data is well organized and the metadata is complete and accurate, the process will be much faster (usually 1-2 business days). It is best to submit your request at least one week before you need the identifier (e.g., for a manuscript submission) or more for very large of complex datasets.</p> <p>Can I publish different versions of my data?</p> <p>Yes. Each new version must be documented, and will be assigned a new permanent identifier that references the original dataset. For new versions, contact us at doi@cyverse.org.</p> <p>How small or big should my data be to be published?</p> <p>The size of the dataset is less important than its utility to the scientific community. Although there is no lower size limit for requesting a DOI, the default upper size limit for data allocations on CyVerse is 100\u00a0GB. If you are interested in depositing a larger dataset, please request an increased data allocation before requesting a permanent identifier.</p> <p>How do I Determine what to include?</p> <p>A data collection may be composed of multiple files and different datasets. In preparing your data for publication identify the data and other materials that you consider useful for validation and reuse of your research:</p> <ul> <li>Data associated with a research project may include multiple files with different roles.</li> <li>If there are components of your dataset that belong in a public repository such as NCBI (e.g., fastq files), submit them to the repository, rather than to CyVerse Curated Data. You may want to include a list of external files in your dataset, with links.</li> <li>Beyond data, you will include the ReadMe file (see Step\u00a01.c), and you may include scripts or links to scripts to run your analysis. Links to analysis tools can also be included as metadata (see Step\u00a02).</li> </ul> <p>How do I Determine how many permanent identifiers to request?</p> <p>To determine how many DOIs to request for a given data collection, consider the following:</p> <ul> <li>Size and number of components.</li> <li>How many studies or publications does it represent?</li> <li>Is your data collection formed by different datasets and are those likely to be used separately?</li> <li>Do you want to create a data collection with one DOI for the entire project and additional related DOIs for distinct datasets so that they are cited individually? DOIs can be nested, so that one dataset is part of another.</li> <li>If you are uncertain about how many DOIs to request, contact us at doi@cyverse.org.</li> </ul> <p>What is the policy for submitting compressed data to CyVerse Curated Data?</p> <p>Certain file types are regularly transferred, stored, and used in applications in a compressed form, such as FASTQ for genomic data and LAZ for LIDAR data. Curated Data supports the deposition of files in the following open compressed formats: LASzip and the open source gzip family of compression formats including zip, tar, or tar.gz (tgz).</p> <p>Can I publish data in CyVerse if I am not a CyVerse user?</p> <p>You must have a CyVerse account to publish your data in the Data Commons repositories (Community Contributed or Curated Data). You do not have to be a user of the entire platform, but at minimum you must be able to upload data, add metadata, and use the Discovery Environment to request a DOI. If you have not used the DE's metadata features before, start with Using Metadata in the DE and read the section on metadata templates.</p> <p>How secure is the data in the Curated Data site?</p> <p>Data in our platform is stored in large-scale storage resources that are monitored 24/7. Data is authenticated through checksum analysis at ingest, and is locally and geographically replicated so that if any one system fails there will always be a safe copy of your data.</p> <p>What is CyVerse Data Commons' long-term commitment to hosting public data?</p> <p>If and when the Data Commons cannot host your data in CyVerse Curated Data, it will transfer custody of the data to another repository and will change the target URL to which the identifier points.</p> <p>What if in the future I want to move my data to another repository?</p> <p>If you want to move your data to another repository, please send a ticket with the DOI and new URL location and we will change the DOI target. You may leave a copy of the dataset in the CyVerse Curated Data site for ease of reuse within the computational environment. CyVerse will update the metadata to reflect the relationship between the two identical datasets.</p> <p>How can I make it easier for people to give me (and my co-creators) credit for using my dataset?</p> <p>Encourage others to cite your data using the DOI. Each dataset landing page includes a citation that can be copied or downloaded in standard formats (BibTEX or EndNote).</p> <p>Connecting your data to your ORCID (see http://orcid.org/) also ensures that you get credit for your work. ORCID provides a persistent digital identifier that distinguishes you from every other researcher and supports automated linkages between you and your professional activities, ensuring that your work is recognized. The DataCite metadata template includes places to list ORCIDs of the creator. The DOI creation metadata template has a place for ORCIDs of creators and contributors.</p> <p>If you have published a paper that goes with your data, be sure to cite the DOI in the paper. Provide a link to the paper's DOI in the metadata under relatedIdentifier.</p> <p>If your data include specific instructions for citing or reuse, to provide those in the ReadMe file and (if brief) in the reuse_or_citation_conditions metadata field.</p> <p>Who do I choose for the creator versus contributor?</p> <p>Creators are the main researchers involved in producing the data, or the authors of the publication, in priority order. To supply multiple creators, repeat this property. A creator may be a corporate/institutional or personal name; it does not need to be the person who is submitting the identifier request.</p> <p>A Contributor is the institution or person(s) responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. To supply multiple contributors, repeat this property. For software, if there is an alternate entity that holds, archives, publishes, prints, distributes, releases, issues, or produces the code, use the contributorType hostingInstitution for the code repository.</p> <p>You must include the role of all contributors. Choose from the dropdown list in the DOI request template.</p> <p>Which license can I use to publish my data?</p> <p>You can choose one of two open source licenses, depending on the materials you will be publishing:</p> <ul> <li>ODC PDDL for non-copyrightable materials (i.e., data only).</li> <li>CC0 for copyrightable material (Workflows, White Papers, Project Documents). If you have special circumstances that require a different license (e.g., your dataset is aggregated from previously published data that already has another license), please contact us at doi@cyverse.org.</li> </ul> <p>What metadata standards does CyVerse support for data publication?</p> <p>All data will follow the DataCite metadata schema (currently using version 4.1). However, DataCite metadata is citation metadata that does not represent the complexity of the research that went behind creating your data. Therefore, we encourage you to include additional metadata. We suggest that you include the metadata records and other help documents in your publication package within a folder labeled as metadata so it is easily identifiable for other users. Consider taking advantage of the DE's bulk metadata application feature for adding file level metadata, especially for large datasets.</p> <p>What if I want to change or add metadata to my public data?</p> <p>If you need to make changes to the metadata of a dataset with a DOI, contact us at doi@cyverse.org. If your dataset is connected to a paper that is published after the DOI is created, please contact us with the paper's DOI so we can link it in the metadata.</p> <p>Where can I go for help on permanent identifiers?</p> <p>Email the CyVerse DOI team.</p>"},{"location":"ds/de/doi/#is-the-cyverse-curated-data-repository-right-for-my-data","title":"Is the CyVerse Curated Data Repository right for my data?","text":"<p>Before requesting a permanent identifier in CyVerse Curated Data through the Data Commons, answer the following series of questions.</p>"},{"location":"ds/de/doi/#question-1-do-you-have-a-cyverse-account","title":"Question 1. Do you have a CyVerse account?","text":"<ul> <li>Are you a registered CyVerse user? If not, register at CyVerse User Portal.</li> <li>If so, have you used the Discovery Environment (DE)?</li> <li>The tools for submitting data to Data Commons Curated Data are simple to use and available as part of the DE. At a minimum, you should be able to upload and organize your data using the DE or command-line tools, and be able to apply a template.</li> </ul>"},{"location":"ds/de/doi/#question-2-is-your-data-ready-for-publication","title":"Question 2. Is your data ready for publication?","text":"<ul> <li>Is the dataset complete, stable, and ready for public consumption?</li> <li>Are you and all contributors to the dataset prepared to move the data into the public domain (meaning that anyone can access and use the data for any purpose, including commercial purposes)? Have you sufficiently documented how the data was created such that other scientists in your field will be able to reuse it?</li> <li>If there is a standard or commonly used format for your datatype, is your data in that format? If no standard exists, is your data in a format that can be easily used by most people with open source software (e.g., tables as a CSV or text file, rather than a Microsoft Excel spreadsheet)?</li> <li>Is your data organized in a clear and reasonable structure that others will be able to understand?</li> </ul> <p>If you answered no to any of these questions, your dataset is not yet ready for a permanent identifier through Data Commons Curated Data. Please continue to work on your dataset until it meets these requirements. Data will be reviewed by a curator to ensure that it meets these requirements.</p> <p>If you would like to make your data public, but it is not complete and/or stable, you may request data hosting in the Data Commons.</p>"},{"location":"ds/de/doi/#question-3-is-your-data-suitable-for-reuse-in-scientific-analyses","title":"Question 3. Is your data suitable for reuse in scientific analyses?","text":"<ul> <li>Is your data of the type and format that allow it to be reused in other analyses?</li> <li>Are you prepared to supply metadata for your dataset?</li> <li>Does your dataset or metadata include sufficient instructions (e.g., a ReadMe file) such that someone in your field can understand how to reuse the data?</li> </ul>"},{"location":"ds/de/doi/#question-4-is-there-a-canonical-repository-for-your-data","title":"Question 4. Is there a canonical repository for your data?","text":"<ul> <li>Does a canonical repository exist for your data? Examples include NCBI, EBI, and MG-RAST.</li> <li>If a canonical repository exists, you should use it. CyVerse is there to help fill a gap, not replace an existing resource.</li> </ul>"},{"location":"ds/de/doi/#if-you-answered-no","title":"If you answered no","text":"<p>If you answered no to any of the questions above, your data may be suitable for a DOI, but not through Data Commons Curated Data. You should consider other repositories that are not geared specifically toward data analysis, such as your institution's library.</p> <p>If your data was generated by or was input for an analysis algorithm or software that you developed yourself, please consider making the method available through CyVerse infrastructure (e.g., the Discovery Environment or Atmosphere) as well.</p>"},{"location":"ds/de/metadata/","title":"Adding Metadata to Data","text":"<p>CyVerse supports a variety of solutions that allow you to associate your raw data with metadata. Metadata is critically important to quality research (see this article on FAIR Principles), yet it is often an afterthought until you are ready to publish and share. Here are a few metadata features in CyVerse that you should know about and can adopt at the outset.</p> <p>Some things to remember about the CyVerse Discovery Environment</p> <ul> <li>You can add metadata to a single file/folder, or in bulk to large collections of data. </li> <li>You can use your own metadata schema or apply one of several metadata templates supported in the Discovery Environment.</li> <li>Additional templates you may wish to use can be found at resources like https://fairsharing.org/.</li> <li>Metadata can be managed through the DE's graphical user interface or by using iCommands at the command line. </li> <li>This guide only covers metadata options in the Discovery Environment.</li> </ul>"},{"location":"ds/de/metadata/#viewing-and-editing-metadata-for-a-single-filefolder-in-the-discovery-environment","title":"Viewing and Editing Metadata for a Single File/Folder in the Discovery Environment","text":"<p>You must have write or own permission to edit an object's metadata.</p> <ol> <li>Log into the Discovery Environment.</li> <li>Click on the   (Data Icon) to view or browse data. Select (checkbox) a single file/folder for which you want to add metadata.</li> <li>Under the More Actions menu, click on 'Metadata'. You will see existing metadata for the file/folder in the Attribute, Value, Unit (AVU) format.</li> </ol> <p></p> <p>Tip</p> <p>A single piece of metadata, or an AVU, comprises an attribute, value, and unit. An attribute is a changeable property or characteristic of the file or folder you have selected that can be set to a value. For example, \"time point\" might be an attribute of a file, while '7' could be its value, and \"hour\" a unit of the time point.</p> <p>Adding metadata</p> <ol> <li>Click the \"+ Add Metadata\" button to add a new entry. Then follow the directions for editing metadata below.</li> </ol> <p>Editing or deleting metadata</p> <ol> <li>You may use the \"pencil\" icon to edit an existing entry or the \"trash can\" icon to delete an entry.</li> <li>After you have made edits or deletions, click 'Save' to save all entries and apply the metadata.</li> </ol>"},{"location":"ds/de/metadata/#adding-metadata-to-multiple-filesfolders-in-the-discovery-environment","title":"Adding Metadata to Multiple Files/Folders in the Discovery Environment","text":"<p>Adding Metadata using a CyVerse Template</p> <ol> <li>Log into the Discovery Environment.</li> <li>Click on the  (Data Icon) to open a Data window. Select (checkbox) a single file/folder to which you want to add metadata.</li> <li> <p>Under the More Actions menu, click on Metadata. Click on the subsequent More Actions menu and select View in Template. You have two choices in using the template:</p> <p>A. Choose a template; clicking Select will allow you to apply the template and edit the metadata manually in the DE interface.  B. Clicking the (Download icon) will download a .csv file you can edit and upload (see Applying bulk metadata below).</p> <p>Click OK to download. (In this example, we will use the DOI Request - DataCite Metadata) template.</p> </li> </ol> <p>Editing a metadata template in the DE</p> <p>Follow the steps in the \"Editing or deleting metadata\" from the section above.</p> <p>Editing a downloaded metadata template</p> <ol> <li> <p>Unzip the downloaded template; it will contain two files: blank.csv and guide.csv. Open these files using the spreadsheet editor of your choice.</p> <p>Tip</p> <ul> <li>blank.csv is the metadata template that you will complete for your data.      </li> <li>guide.csv contains instructions for your template, and will usually include controlled vocabulary terms for metadata descriptors.</li> </ul> </li> <li> <p>Edit the template in one of two ways:</p> <ol> <li> <p>If all data will be in a single folder:</p> <ul> <li>In the blank.csv spreadsheet, in the 'file name or path' column, enter the file names of all the files in that folder you wish to annotate with metadata.</li> <li>In any data window, click the '\u22ee' (3-dots or ellipsis menu) next to any file or folder; choose 'copy path' to get the path to that item in the Data Store.          </li> <li>In the remaining columns of the template, enter the values for each file/attribute combination that applies.</li> <li>If desired, add additional columns to the end of the template. The metadata in the additional columns will be saved in the Data Store but will not be stored as part of the template.</li> <li>Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format.</li> </ul> </li> <li> <p>If data will be in multiple folders:</p> <ul> <li>In the blank.csv spreadsheet, in the 'filename or path' column, enter the full path of the top-level folder (e.g., <code>/iplant/home/YOURUSERNAME/FOLDERNAME</code>) </li> <li>In the remaining columns in the first row, enter the values for each file/attribute combination.</li> <li>Repeat for each file, making sure to add the full file path (e.g., <code>/iplant/home/YOURUSERNAME/FOLDERNAME</code>) for each file.</li> <li>If desired, add additional columns to the end of the template. The metadata in the columns will be saved in the Data Store but will not be stored as part of the template.</li> <li>Save the file in CSV format (i.e., [filename].csv). Avoid using spaces or specal characters when naming the file or parent folder. You may name this metadata file anything you wish, but keep it in CSV format.</li> </ul> </li> </ol> </li> <li> <p>In an open 'Data' window in the Discovery Environment, navigate to the appropriate location for uploading the template:</p> <ul> <li>If the first column of your metadata file contains only filenames (i.e., all data files are in the same folder), navigate to the folder and use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to that folder.</li> <li>If the first column of your metadata file contains the full path to each file (i.e., the data files are in different folders), it does not matter where the metadata file is located on the Data Store. Use the Upload button (Browse local) or your choice of upload tool to upload the metadata (csv file) to an appropriate location on the Data Store.</li> </ul> <p>Tip</p> <p>For convenient management and editing, use absolute file paths (e.g., <code>/iplant/home/your_file_location</code>) so that all of your metadata spreadsheets  will be in one location on the Data Store.</p> </li> <li> <p>To apply the metadata, select (checkbox) in the Data window the name of the folder containing the data files to which you want to apply the metadata in bulk.</p> </li> <li>Click the More Actions menu, select 'Apply Bulk Metadata'; browse to the uploaded metadata spreadsheet and select it.</li> </ol> <p>Your metadata should now be applied to your files. You should receive anotification (bell icon) in the Discovery Environment and you can confirm the metadata have been correctly applied by following the steps in the preceding section to view metadata.</p>"},{"location":"ds/de/share/","title":"Sharing Data in the Discovery Environment","text":"<p>This quickstart is focused on using the Discovery Environment to upload your data. For more information on alternative methods for data management, please refer to the Manage Your Data section or the Data Sharing page.</p> <ol> <li> <p>Log into the  Discovery Environment.</p> </li> <li> <p>Open the  Data icon on the left.</p> <p></p> </li> <li> <p>Click the Upload button on the top right; in the dropdown menu that appears, select the preferred upload method (Browse Local or Import from URL). Additionally, you can also view your upload queue.</p> <p></p> </li> <li> <p>Once your file(s) is uploaded, click on the ellipses (3 dots) on the right of the file. This will open a dropdown menu with a number of options; Choose Share.</p> <p></p> </li> <li> <p>In the Share window, choose which CyVerse collaborator to share with. If your collaborator is not a registered CyVerse user, choose anonymous.</p> <p></p> </li> <li> <p>You can also generate a public URL for files, making it easier to share your files. To do so, click on the ellipses (3 dots) on the right of the file, and click Public Link(s). A window will appear with the generated URL,  which collaborators can use to download your file.</p> <p>Generating a public URL works for files, not folders! It is suggested to compress large numbers of files prior to sharing them.</p> <p></p> </li> </ol>"},{"location":"ds/de/teams/","title":"Managing Data within a Team","text":"<p>The  Teams feature allows you to create, organize, and join public or private groups of collaborators. Teams is accessible through the left side menu, or by going through the following link: https://de.cyverse.org/teams. The goal of Teams is to enable a simpler method to share apps, Tools and data with collaborators.</p> <p></p> <p>On the  Teams page, users are able to:</p> <ul> <li>See all public teams and teams one is part of (top left drop down menu All Teams )</li> <li>Create a team (top right  Team)</li> </ul>"},{"location":"ds/de/teams/#creating-a-team","title":"Creating a Team","text":"<p>To create a team, click the  Team button on the top right. This is what the Team creation page looks like:</p> <p></p> <p>Here, you can:</p> <ul> <li>Pick a name of your team and add a description</li> <li>Choose whether this team is public or private</li> <li>Add (or remove) members using the Search bar</li> <li>Choose the user's privilege level between admin or member (Admins can allow other Members to join)</li> <li>Delete the team</li> </ul> <p>What's the difference between public and private teams?</p> <p>One can only be able to join a private team if added by the admin. Public teams allow users request to join a team through the Join button on the top right. Admins of that specific team will be notified.</p> <p></p> <p>Remember to save your changes before exiting the page!</p>"},{"location":"ds/de/teams/#sharing-apps-tools-and-data","title":"Sharing Apps, Tools, and Data","text":"<p>Being part of a team does not mean that your apps, tools and data are automatically shared. The steps below will enable sharing of apps and tools, for example, with your team, (these steps are applicable to sharing data as well):</p> <ol> <li>Navigate to the app or tool you want to share and select it. The app/tool should be highlighted.</li> <li>Click the  Share button on the top of the page. This will open the Sharing dialog. </li> <li>Use the Search box to look for your team.</li> <li>Select the permission level (Read, Write, or Own) that you want for your team and click Done.</li> </ol> <p>Your team should now have access to the app or tool you shared!</p> <p>When adding a new member to an existing team, everything that has already been shared with the team will be automatically be shared with the new member. Be careful of what you share to the team!</p>"},{"location":"ds/de/teams/#faq","title":"FAQ","text":"<p>What happens if I delete my team?</p> <p>If you delete your team, remove someone from your team or unshare any app, tool, or data, the app/tool/data will not be available for use by your collaborators.</p> <p>What about versions?</p> <p>Any changes you make to a shared app or tool will be reflected to the rest of the team. For example, if you add a version to an app, the team will be able to see the changes you have made.</p>"},{"location":"ds/gocommands/","title":"Manage Your Data with GoCommands","text":"<p>GoCommands is a lightweight, portable command-line tool designed for seamless data management within the Data Store. It provides comprehensive support for data transfers, bulk transfers, synchronization, access control, SFTP configuration, and metadata management. As a versatile alternative to iCommands, GoCommands runs on virtually any operating system, including embedded environments like Raspberry Pi, offering greater flexibility across platforms.</p> <p>This guide covers installation, data transfer methods, access management, and metadata handling to help you efficiently manage your data in the Data Store.</p>"},{"location":"ds/gocommands/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation and Upgrade</li> <li>Configuration</li> <li>Data Management</li> <li>Data Transfer</li> <li>Access Management</li> <li>Metadata Management</li> <li>SFTP Public-key Authentication Configuration</li> <li>Troubleshooting and Issue Report</li> </ol>"},{"location":"ds/gocommands/#installation-and-upgrade","title":"Installation and Upgrade","text":"<p>Install GoCommands in your environment to efficiently manage your data in the Data Store. This section also provides best practices for keeping GoCommands up-to-date.</p>"},{"location":"ds/gocommands/#configuration","title":"Configuration","text":"<p>Set up GoCommands in your environment for seamless interaction with the Data Store.</p>"},{"location":"ds/gocommands/#data-management","title":"Data Management","text":"<p>Navigate the file structure and efficiently manage your data, including organizing, renaming, and deleting files and directories.</p>"},{"location":"ds/gocommands/#data-transfer","title":"Data Transfer","text":"<p>Upload and download data between your local system and the Data Store. Learn different transfer methods to optimize speed and reliability.</p>"},{"location":"ds/gocommands/#access-management","title":"Access Management","text":"<p>Manage file and directory permissions effectively. Learn how to grant, modify, and revoke access.</p>"},{"location":"ds/gocommands/#metadata-management","title":"Metadata Management","text":"<p>Enhance data discoverability and organization by adding, updating, and managing metadata for files stored in the Data Store.</p>"},{"location":"ds/gocommands/#sftp-public-key-authentication-configuration","title":"SFTP Public-key Authentication Configuration","text":"<p>Set up and configure public-key authentication for secure SFTP access to the Data Store.</p>"},{"location":"ds/gocommands/#troubleshooting-and-issue-report","title":"Troubleshooting and Issue Report","text":"<p>Encountered an issue? Learn how to report bugs, troubleshoot errors, and contribute to the improvement of GoCommands.</p>"},{"location":"ds/gocommands/access_management/","title":"Access Management using GoCommands","text":"<p>GoCommands provides features to manage access of users and groups to data in the Data Store. The <code>chmod</code> and <code>chmodinherit</code> commands allow users to manage access permissions for data objects (files) and collections (directories). The <code>ls -A</code> command displays the current access levels assigned to users for a given file or directory.</p>"},{"location":"ds/gocommands/access_management/#list-access-permissions-of-users-for-a-data-object-or-collection","title":"List Access Permissions of Users for a Data Object or Collection","text":"<pre><code>gocmd ls -A &lt;data-object-or-collection&gt;\n</code></pre> <p>The <code>-A</code> flag in <code>ls</code> command displays access permissions in the result.</p> <p>This command will show the data objects and collections along with their access control lists (ACLs). For example:</p> <pre><code>/iplant/home/myUser/mydata:\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n        Inheritance - Disabled\n    file1.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    file2.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre> <ul> <li>The <code>g:</code> prefix in the ACL username indicates that the user is a group.</li> <li>The ACL is displayed in the <code>username#zone:access_level</code> format.</li> <li>Most common access levels are:<ul> <li><code>read_object</code>: Allows read access to the data object or collection.</li> <li><code>modify_object</code>: Allows modification (write) of the data object or collection.</li> <li><code>own</code>: Grants ownership of the data object or collection.</li> </ul> </li> </ul>"},{"location":"ds/gocommands/access_management/#example-usage","title":"Example Usage","text":"<ol> <li>List current access levels for a data object or collection: <pre><code>gocmd ls -A /iplant/home/myUser/mydata\n</code></pre></li> </ol>"},{"location":"ds/gocommands/access_management/#change-a-users-or-groups-access-permission-for-a-data-object-or-collection","title":"Change a User's or Group's Access Permission for a Data Object or Collection","text":"<pre><code>gocmd chmod &lt;access-level&gt; &lt;user-or-group(#zone)&gt; &lt;data-object-or-collection&gt;\n</code></pre>"},{"location":"ds/gocommands/access_management/#access-levels","title":"Access Levels","text":"Access Level Description <code>null</code> Removes all permissions <code>read</code> Allows reading the object or collection <code>write</code> Allows reading and modifying the object or collection <code>own</code> Grants full control, including the ability to change permissions"},{"location":"ds/gocommands/access_management/#example-usage_1","title":"Example Usage","text":"<ol> <li> <p>Grant a user read permission to a data object: <pre><code>gocmd chmod read anotherUser /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Grant a user from a different zone read permission to a data object: <pre><code>gocmd chmod read anotherUser#anotherZone /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Grant a user read permission to a collection and its contents: <pre><code>gocmd chmod -r read anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Grant a user write permission to a collection and its contents: <pre><code>gocmd chmod -r write anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Grant a user owner permission to a collection and its contents: <pre><code>gocmd chmod -r owner anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Remove access permission from a user to a collection and its contents: <pre><code>gocmd chmod -r none anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/access_management/#enable-or-disable-access-permission-inheritance-for-a-collection","title":"Enable or Disable Access Permission Inheritance for a Collection","text":"<p>When inheritance is enabled for a collection, any new data objects or subcollections created within it will automatically inherit the same access permissions as the parent collection.</p> <pre><code>gocmd chmodinherit &lt;inheritance_option&gt; &lt;collection_path&gt;\n</code></pre>"},{"location":"ds/gocommands/access_management/#inheritance-options","title":"Inheritance Options","text":"Flag Description <code>inherit</code> Enable access inheritance. Data objects and sub-collections inherit permissions from the parent collection <code>noinherit</code> Disable access inheritance. Data objects and sub-collections do not inherit permissions from the parent collection"},{"location":"ds/gocommands/access_management/#example-usage_2","title":"Example Usage","text":"<ol> <li> <p>Enable inheritance for a collection: <pre><code>gocmd chmodinherit inherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Disable inheritance for a collection: <pre><code>gocmd chmodinherit noinherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Enable inheritance recursively for a collection and its subcollections: <pre><code>gocmd chmodinherit -r inherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Disable inheritance recursively for a collection and its subcollections: <pre><code>gocmd chmodinherit -r noinherit /iplant/home/myUser/dir\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/configuration/","title":"GoCommands Configuration","text":""},{"location":"ds/gocommands/configuration/#using-the-init-command","title":"Using the <code>init</code> Command","text":"<p>The <code>init</code> command sets up the iRODS Host and access account for use with other GoCommands tools. Once the configuration is set, configuration files are created under the <code>~/.irods</code> directory. The configuration is fully compatible with that of iCommands.</p> <ol> <li> <p>Run the following command to configure GoCommands: <pre><code>gocmd init\n</code></pre></p> <p>Getting 'Command not found error?'</p> <p> This error indicates that the system could not locate <code>gocmd</code> binary in the directories specified by the <code>$PATH</code> environment variable. To resolve this:</p> <ol> <li>Use an absolute path: Run <code>./gocmd init</code> from the directory where you downloaded the <code>gocmd</code> binary.</li> <li>For easier future use: Move the <code>gocmd</code> binary to a directory in your <code>$PATH</code>, such as <code>/usr/local/bin</code>.</li> <li>Windows users: Ensure the executable is named <code>gocmd.exe</code> and run <code>gocmd.exe init</code> to initialize.</li> </ol> </li> <li> <p>Enter your Data Store account credentials when prompted. Use the following information:</p> Configuration Key Value <code>irods_host</code> <code>data.cyverse.org</code> <code>irods_port</code> <code>1247</code> <code>irods_zone_name</code> <code>iplant</code> <code>irods_user_name</code> <code>&lt;CyVerse Username&gt;</code> <code>irods_user_password</code> <code>&lt;CyVerse Password&gt;</code> <p>Use these credentials for anonymous access to the Data Store:</p> Configuration Key Value <code>irods_user_name</code> <code>anonymous</code> <code>irods_user_password</code> (leave empty) </li> <li> <p>To verify the current configuration, use: <pre><code>gocmd env\n</code></pre></p> <p>This will display the current configurations.</p> </li> <li> <p>Execute GoCommands for your task: <pre><code>gocmd ls\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/configuration/#using-icommands-configuration","title":"Using iCommands Configuration","text":"<p>GoCommands is compatible with iCommands' configuration files. It can automatically detect and use the existing iCommands configuration files located in <code>~/.irods</code>. Additionally, GoCommands creates its own configuration files in this directory, allowing users to work with both iCommands and GoCommands interchangeably.</p>"},{"location":"ds/gocommands/configuration/#using-an-external-configuration-file-yaml-or-json-without-init","title":"Using an External Configuration File (YAML or JSON) without <code>init</code>","text":"<p>GoCommands can read configurations from YAML or JSON files without running <code>init</code> to create the <code>~/.irods</code> directory. This approach offers flexibility but requires specifying the configuration file path for each command. Here's how to use this method:</p> <ol> <li> <p>Create a file named <code>config.yaml</code> using your preferred text editor: <pre><code>irods_host: \"data.cyverse.org\"\nirods_port: 1247\nirods_zone_name: \"iplant\"\nirods_user_name: \"&lt;CyVerse Username&gt;\"\nirods_user_password: \"&lt;CyVerse Password&gt;\"\n</code></pre></p> <p>Prefer not to include your password in the file?</p> <p> You can omit sensitive fields like <code>irods_user_password</code>, and GoCommands will prompt you to enter the missing values during runtime.</p> </li> <li> <p>To use this configuration file, provide its path with the <code>-c</code> flag when running GoCommands: <pre><code>gocmd -c config.yaml env\n</code></pre></p> </li> <li> <p>Execute GoCommands for your task: <pre><code>gocmd -c config.yaml ls\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/configuration/#using-an-external-configuration-file-yaml-or-json","title":"Using an External Configuration File (YAML or JSON)","text":"<p>The <code>init</code> command can be executed with an external file to automate configuration.</p> <ol> <li> <p>Create a file named <code>config.yaml</code> using your preferred text editor: <pre><code>irods_host: \"data.cyverse.org\"\nirods_port: 1247\nirods_zone_name: \"iplant\"\nirods_user_name: \"&lt;CyVerse Username&gt;\"\nirods_user_password: \"&lt;CyVerse Password&gt;\"\n</code></pre></p> <p>Prefer not to include your password in the file?</p> <p> You can omit sensitive fields like <code>irods_user_password</code>, and GoCommands will prompt you to enter the missing values during runtime.</p> </li> <li> <p>Execute the <code>init</code> command with the <code>-c</code> flag to configure: <pre><code>gocmd -c config.yaml init\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/configuration/#using-environmental-variables-without-init","title":"Using Environmental Variables without <code>init</code>","text":"<p>GoCommands can read configuration directly from environmental variables, which take precedence over other configuration sources.</p> <ol> <li> <p>Export the required variables in your terminal: <pre><code>export IRODS_HOST=\"data.cyverse.org\"\nexport IRODS_PORT=1247\nexport IRODS_ZONE_NAME=\"iplant\"\nexport IRODS_USER_NAME=\"&lt;CyVerse Username&gt;\"\nexport IRODS_USER_PASSWORD=\"&lt;CyVerse Password&gt;\"\n</code></pre></p> <p>Prefer not to set your password as an environment variable?</p> <p> You can omit sensitive fields like <code>IRODS_USER_PASSWORD</code>, and GoCommands will prompt you to enter the missing values during runtime.</p> </li> <li> <p>Run GoCommands to verify the environment settings: <pre><code>gocmd env\n</code></pre></p> </li> <li> <p>Execute GoCommands for your task: <pre><code>gocmd ls\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/configuration/#using-environmental-variables","title":"Using Environmental Variables","text":"<p>The <code>init</code> command can be executed with environmental variables to automate configuration.</p> <ol> <li> <p>Export the required variables in your terminal: <pre><code>export IRODS_HOST=\"data.cyverse.org\"\nexport IRODS_PORT=1247\nexport IRODS_ZONE_NAME=\"iplant\"\nexport IRODS_USER_NAME=\"&lt;CyVerse Username&gt;\"\nexport IRODS_USER_PASSWORD=\"&lt;CyVerse Password&gt;\"\n</code></pre></p> <p>Prefer not to set your password as an environment variable?</p> <p> You can omit sensitive fields like <code>IRODS_USER_PASSWORD</code>, and GoCommands will prompt you to enter the missing values during runtime.</p> </li> <li> <p>Execute the <code>init</code> command: <pre><code>gocmd init\n</code></pre></p> <p>Note: GoCommands will prompt you to input only the missing fields.</p> </li> </ol>"},{"location":"ds/gocommands/configuration/#full-list-of-supported-configuration-fields","title":"Full List of Supported Configuration Fields","text":"<p>Below is a comprehensive list of supported fields, along with their corresponding names in JSON, YAML, and environmental variables:</p> Field Name JSON/YAML Key Environmental Variable Default Value AuthenticationScheme <code>irods_authentication_scheme</code> <code>IRODS_AUTHENTICATION_SCHEME</code> native AuthenticationFile <code>irods_authentication_file</code> <code>IRODS_AUTHENTICATION_FILE</code> ~/irods/.irodsA ClientServerNegotiation <code>irods_client_server_negotiation</code> <code>IRODS_CLIENT_SERVER_NEGOTIATION</code> off ClientServerPolicy <code>irods_client_server_policy</code> <code>IRODS_CLIENT_SERVER_POLICY</code> CS_NEG_REFUSE Host <code>irods_host</code> <code>IRODS_HOST</code> Port <code>irods_port</code> <code>IRODS_PORT</code> 1247 ZoneName <code>irods_zone_name</code> <code>IRODS_ZONE_NAME</code> ClientZoneName <code>irods_client_zone_name</code> <code>IRODS_CLIENT_ZONE_NAME</code> Username <code>irods_user_name</code> <code>IRODS_USER_NAME</code> ClientUsername <code>irods_client_user_name</code> <code>IRODS_CLIENT_USER_NAME</code> DefaultResource <code>irods_default_resource</code> <code>IRODS_DEFAULT_RESOURCE</code> CurrentWorkingDir <code>irods_cwd</code> <code>IRODS_CWD</code> Home <code>irods_home</code> <code>IRODS_HOME</code> DefaultHashScheme <code>irods_default_hash_scheme</code> <code>IRODS_DEFAULT_HASH_SCHEME</code> SHA256 MatchHashPolicy <code>irods_match_hash_policy</code> <code>IRODS_MATCH_HASH_POLICY</code> Debug <code>irods_debug</code> <code>IRODS_DEBUG</code> LogLevel <code>irods_log_level</code> <code>IRODS_LOG_LEVEL</code> 0 EncryptionAlgorithm <code>irods_encryption_algorithm</code> <code>IRODS_ENCRYPTION_ALGORITHM</code> AES-256-CBC EncryptionKeySize <code>irods_encryption_key_size</code> <code>IRODS_ENCRYPTION_KEY_SIZE</code> 32 EncryptionSaltSize <code>irods_encryption_salt_size</code> <code>IRODS_ENCRYPTION_SALT_SIZE</code> 8 EncryptionNumHashRounds <code>irods_encryption_num_hash_rounds</code> <code>IRODS_ENCRYPTION_NUM_HASH_ROUNDS</code> 16 SSLCACertificateFile <code>irods_ssl_ca_certificate_file</code> <code>IRODS_SSL_CA_CERTIFICATE_FILE</code> SSLCACertificatePath <code>irods_ssl_ca_certificate_path</code> <code>IRODS_SSL_CA_CERTIFICATE_PATH</code> SSLVerifyServer <code>irods_ssl_verify_server</code> <code>IRODS_SSL_VERIFY_SERVER</code> hostname SSLCertificateChainFile <code>irods_ssl_certificate_chain_file</code> <code>IRODS_SSL_CERTIFICATE_CHAIN_FILE</code> SSLCertificateKeyFile <code>irods_ssl_certificate_key_file</code> <code>IRODS_SSL_CERTIFICATE_KEY_FILE</code> SSLDHParamsFile <code>irods_ssl_dh_params_file</code> <code>IRODS_SSL_DH_PARAMS_FILE</code> Password <code>irods_user_password</code> <code>IRODS_USER_PASSWORD</code> Ticket <code>irods_ticket</code> <code>IRODS_TICKET</code> PAMToken <code>irods_pam_token</code> <code>IRODS_PAM_TOKEN</code> PAMTTL <code>irods_pam_ttl</code> <code>IRODS_PAM_TTL</code> SSLServerName <code>irods_ssl_server_name</code> <code>IRODS_SSL_SERVER_NAME</code>"},{"location":"ds/gocommands/data_management/","title":"Data Management using GoCommands","text":"<p>GoCommands offers a variety of commands to help you manage your data in the Data Store. In the Data Store, <code>file</code> and <code>directory</code> are treated as <code>data objects</code> and <code>collections</code>, respectively. It's perfectly fine to consider these terms interchangeable.</p>"},{"location":"ds/gocommands/data_management/#display-the-current-working-collection","title":"Display the Current Working Collection","text":"<p>In the Data Store, the current working collection is equivalent to the concept of a current working directory in traditional file systems. You can display or change your current working collection using GoCommands.</p> <pre><code>gocmd pwd\n</code></pre> <p>By default, after configuring GoCommands, your current working collection is set to your home directory, which is typically located at: <pre><code>/&lt;Zone Name&gt;/home/&lt;Username&gt;\n</code></pre></p> <p>Note: Paths in the Data Store always start with the zone name <code>/iplant</code>.</p>"},{"location":"ds/gocommands/data_management/#change-the-current-working-collection","title":"Change the Current Working Collection","text":"<ol> <li> <p>Change to a specific collection using an absolute path: <pre><code>gocmd cd /iplant/home/myUser/mydata\n</code></pre></p> <p>This changes your current working collection to <code>/iplant/home/myUser/mydata</code>.</p> </li> <li> <p>Use a relative path from your current location:     Assuming your current working collection is <code>/iplant/home/myUser</code>:</p> <pre><code>gocmd cd mydata\n</code></pre> </li> <li> <p>Return to your home collection: <pre><code>gocmd cd \"~\"\n</code></pre></p> <p>Note: The <code>~</code> must be quoted to prevent shell expansion by your local shell. Without quotes, it will expand to your local machine's home directory instead of your Data Store home directory.</p> </li> <li> <p>Move up one level: <pre><code>gocmd cd ..\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/data_management/#list-data-objects-files-and-collections-directories","title":"List Data Objects (files) and Collections (directories)","text":"<ol> <li> <p>List the content of a collection: <pre><code>gocmd ls /iplant/home/myUser/mydata\n</code></pre></p> <p>This will display the data objects and collections in the <code>/iplant/home/myUser/mydata</code> collection: <pre><code>/iplant/home/myUser/mydata:\n    file1.bin\n    file2.bin\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <p>The <code>C-</code> prefix indicates that the item is a collection (directory).</p> </li> <li> <p>List the content of the current working collection: <pre><code>gocmd ls\n</code></pre></p> </li> <li> <p>List the contents of a collection in long format with additional details: <pre><code>gocmd ls -l /iplant/home/myUser/mydata\n</code></pre></p> <p>This command will show the data objects and collections within <code>/iplant/home/myUser/mydata</code>, along with their additional details: <pre><code>/iplant/home/myUser/mydata:\n    myUser  0   demoRes1;rs1    436 2024-04-02.13:36    &amp;   file1.bin\n    myUser  1   demoRes2;rs2    436 2024-04-02.13:36    &amp;   file1.bin\n    myUser  0   demoRes1;rs1    700 2024-04-02.17:15    &amp;   file2.bin\n    myUser  1   demoRes2;rs2    700 2024-04-02.17:15    &amp;   file2.bin\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <ul> <li>Each output line for a data object represents a replica. If iRODS is configured to create multiple replicas, you will see one line for each replica of the data object. For example, if two replicas are created, two lines will be displayed for each file.</li> <li>Each line is shown in the <code>owner replica_id resource_server size creation_time replica_state name</code> format.</li> <li>Possible replica states are:<ul> <li><code>&amp;</code>: Good</li> <li><code>X</code>: Stale</li> <li><code>?</code>: Unknown</li> </ul> </li> </ul> </li> <li> <p>List the contents of a collection with their access control lists: <pre><code>gocmd ls -A /iplant/home/myUser/mydata\n</code></pre></p> <p>This command will show the data objects and collections within <code>/iplant/home/myUser/mydata</code>, along with their access control lists (ACLs): <pre><code>/iplant/home/myUser/mydata:\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n        Inheritance - Disabled\n    file1.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    file2.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <ul> <li>The <code>g:</code> prefix in the ACL username indicates that the user is a group.</li> <li>The ACL is displayed in the <code>username#zone:access_level</code> format.</li> <li>Most common access levels are:<ul> <li><code>read_object</code>: Allows read access to the data object or collection.</li> <li><code>modify_object</code>: Allows modification (write) of the data object or collection.</li> <li><code>own</code>: Grants ownership of the data object or collection.</li> </ul> </li> </ul> </li> </ol>"},{"location":"ds/gocommands/data_management/#make-a-collections-directories","title":"Make a Collections (directories)","text":"<ol> <li> <p>Create a new collection: <pre><code>gocmd mkdir /iplant/home/myUser/newCollection\n</code></pre></p> </li> <li> <p>Create parent collections if they do not exist: <pre><code>gocmd mkdir -p /iplant/home/myUser/parentCollection/newCollection\n</code></pre></p> <p>This command creates the <code>newCollection</code> along with its parent collection <code>parentCollection</code> if it does not already exist.</p> </li> </ol>"},{"location":"ds/gocommands/data_management/#upload-data-objects-files-and-collections-directories-to-the-data-store","title":"Upload Data Objects (files) and Collections (directories) to the Data Store","text":"<p>Warning</p> <p>When uploading your data to the Data Store, avoid using:</p> <ul> <li>Spaces in names (e.g., <code>experiment one.fastq</code>)</li> <li>Special characters: ~ `` ! @ # $ % ^ &amp; * ( ) + = { } [ ] | : ; \" ' &lt; &gt; , ? / and \\</li> </ul> <p>These may cuase issues with Discovery Environment Apps and command-line applications.</p> <p>Recommendation: Use underscores for long names (e.g., <code>experiment_one.fastq</code>).</p> <ol> <li> <p>Upload a single file: <pre><code>gocmd put /local/path/file.txt /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the file <code>/local/path/file.txt</code> to <code>/iplant/home/myUser/</code>, creating <code>/iplant/home/myUser/file.txt</code> in the Data Store.</p> </li> <li> <p>Upload a directory and its contents: <pre><code>gocmd put /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the contents of the directory <code>/local/dir</code> to <code>/iplant/home/myUser/dir</code> in the Data Store. The uploaded files and subdirectories will be placed within the <code>/iplant/home/myUser/dir</code> folder.</p> </li> <li> <p>Upload with progress bars: <pre><code>gocmd put --progress /local/path/largefile.dat /iplant/home/myUser/\n</code></pre></p> </li> <li> <p>Force upload: <pre><code>gocmd put -f /local/path/largefile.dat /iplant/home/myUser/\n</code></pre></p> <p>This command overwrites the existing file in the Data Store without prompting.</p> </li> <li> <p>Upload and verify checksum: <pre><code>gocmd put -K /local/path/important_data.txt /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the file and verifies its integrity by calculating a checksum during transfer.</p> </li> <li> <p>Upload only different or new contents: <pre><code>gocmd put --diff /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command uploads only files that are different or don't exist in the destination. It compares file sizes and checksums to determine which files need updating.</p> </li> <li> <p>Upload via iCAT: <pre><code>gocmd put --icat /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command uses iCAT as a transfer broker, useful when direct access to the resource server is unstable.</p> </li> <li> <p>Upload via resource server: <pre><code>gocmd put --redirect /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command bypasses the iCAT server for data transfer, directly accessing the specified resource server for optimized performance.</p> </li> </ol>"},{"location":"ds/gocommands/data_management/#download-data-objects-files-and-collections-directories-from-the-data-store","title":"Download Data Objects (files) and Collections (directories) From the Data Store","text":"<ol> <li> <p>Download a data object to a specific local path: <pre><code>gocmd get /iplant/home/myUser/file.txt /local/path/file_new_name.txt\n</code></pre></p> <p>This command downloads the data object <code>/iplant/home/myUser/file.txt</code> and saves it as <code>/local/path/file_new_name.txt</code>.</p> </li> <li> <p>Download a collection to a specific local path: <pre><code>gocmd get /iplant/home/myUser/dir /local/path/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/dir</code> and its contents to <code>/local/path</code>. A new directory named <code>dir</code> will be created under <code>/local/path</code>, resulting in <code>/local/path/dir</code> containing all the downloaded files and subdirectories.</p> </li> <li> <p>Download with progress bars: <pre><code>gocmd get --progress /iplant/home/myUser/largefile.dat /local/dir/\n</code></pre></p> </li> <li> <p>Force download: <pre><code>gocmd get -f /iplant/home/myUser/largefile.dat .\n</code></pre></p> <p>This command overwrites the local file without prompting if it already exists.</p> </li> <li> <p>Download and verify checksum: <pre><code>gocmd get -K /iplant/home/myUser/important_data.txt .\n</code></pre></p> <p>This command downloads the file and verifies its integrity by calculating the checksum after download and comparing it with the original in the Data Store. This ensures data consistency and detects any corruption during transfer.</p> </li> <li> <p>Download only different or new contents: <pre><code>gocmd get --diff /iplant/home/myUser/dir /local/dir\n</code></pre></p> <p>This command downloads the source collection to the local directory, transferring only files that are different or don't exist locally. It compares file sizes and checksums to determine which files need updating, making the transfer more efficient by skipping unchanged files.</p> </li> <li> <p>Download via iCAT: <pre><code>gocmd get --icat /iplant/home/myUser/dir /local/dir\n</code></pre></p> <p>This command uses iCAT as a transfer broker, which is useful when direct access to the resource server is unstable. It ensures reliable data transfer by routing through the iCAT server.</p> </li> <li> <p>Download via resource server: <pre><code>gocmd get --redirect /iplant/home/myUser/dir /local/dir\n</code></pre></p> <p>This command bypasses the iCAT server for data transfer, directly accessing the specified resource server. It optimizes performance for large files by direct connection to the resource server.</p> </li> <li> <p>Download with wildcard: <pre><code>gocmd get -w /iplant/home/myUser/dir/file*.txt /local/dir\n</code></pre></p> <p>This command downloads all data objects matching the pattern \"file*.txt\" from the specified collection to the local directory.</p> </li> </ol>"},{"location":"ds/gocommands/data_management/#remove-data-objects-files-or-collections-directories-from-the-data-store","title":"Remove Data Objects (files) or Collections (directories) From the Data Store","text":"<ol> <li> <p>Remove a single data object: <pre><code>gocmd rm /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Remove an empty collection: <pre><code>gocmd rmdir /iplant/home/myUser/emptyCollection\n</code></pre></p> </li> <li> <p>Remove a collection and its contents recursively: <pre><code>gocmd rm -r /iplant/home/myUser/parentCollection\n</code></pre></p> </li> <li> <p>Force remove a collection and its contents recursively: <pre><code>gocmd rm -rf /iplant/home/myUser/parentCollection\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/data_management/#moverename-data-objects-files-or-collections-directories","title":"Move/Rename Data Objects (files) or Collections (directories)","text":"<ol> <li> <p>Rename a data object: <pre><code>gocmd mv /iplant/home/myUser/oldfile.txt /iplant/home/myUser/newfile.txt\n</code></pre></p> </li> <li> <p>Move a data object to a different collection: <pre><code>gocmd mv /iplant/home/myUser/file.txt /iplant/home/myUser/subcollection/\n</code></pre></p> </li> <li> <p>Rename a collection: <pre><code>gocmd mv /iplant/home/myUser/oldcollection /iplant/home/myUser/newcollection\n</code></pre></p> </li> <li> <p>Move multiple data objects with wildcard: <pre><code>gocmd mv -w /iplant/home/myUser/*.txt /iplant/home/myUser/targetcollection/\n</code></pre></p> <p>This command will move all data objects with the <code>.txt</code> extension from the /iplant/home/myUser/ collection to the <code>targetcollection</code>. The asterisk (*) wildcard matches any number of characters in the filename.</p> <p>You can use more specific wildcard patterns for precise file selection, such as <code>file*.txt</code> to move all text files starting with \"file\".</p> </li> </ol>"},{"location":"ds/gocommands/data_management/#additional-resources","title":"Additional Resources","text":"<p>For detailed information on GoCommands, refer to the GoCommands GitHub repository. The following command-specific documentation is available:</p> <ul> <li>init: Initialize GoCommands configuration</li> <li>env: Display or modify environment variables</li> <li>passwd: Change user password</li> <li>cd and pwd: Change and print working directory</li> <li>ls: List directory contents</li> <li>touch: Create empty files or update timestamps</li> <li>mkdir: Create directories</li> <li>rm: Remove files or directories</li> <li>rmdir: Remove directories</li> <li>mv: Move or rename files and directories</li> <li>cp: Copy files or directories</li> <li>cat: Display contents of a file</li> <li>get: Download files from the Data Store</li> <li>put: Upload files to the Data Store</li> <li>bput: Bulk upload files to the Data Store</li> <li>sync: Synchronize local and remote directories</li> <li>chmod: Change access permission of files or directories</li> <li>chmodinherit: Change access permission inheritance of directories</li> <li>lsmeta: List metadata of data objects, collections, resources, or users in iRODS</li> <li>addmeta: Add metadata to data objects, collections, resources, or users in iRODS</li> <li>rmmeta: Remove metadata from data objects, collections, resources, or users in iRODS</li> <li>copy-sftp-id: Configure SFTP Public-key Authentication</li> <li>svrinfo: Display server information</li> <li>ps: Display current iRODS sessions</li> <li>upgrade: Upgrade GoCommands</li> <li>copy-sftp-id: Copy SFTP identity file to the Data Store for SFTP public-key authentication</li> </ul>"},{"location":"ds/gocommands/data_transfer/","title":"Data Transfer using GoCommands","text":"<p>GoCommands provides a range of commands designed to efficiently and conveniently transfer large datasets between your local machine and the Data Store.</p>"},{"location":"ds/gocommands/data_transfer/#download-data-from-the-data-store","title":"Download Data from the Data Store","text":"<ol> <li> <p>Download a collection to a specific local path: <pre><code>gocmd get --progress -f -K --icat /iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code>. A new directory named <code>mydir</code> will be created under <code>/local/dir/</code>, resulting in <code>/local/dir/mydir</code> containing all the downloaded files and subdirectories.</p> <ul> <li>The <code>--progress</code> flag shows progress bars, providing visual feedback during file transfers.</li> <li>The <code>-f</code> flag forces overwriting of existing local files without confirmation.</li> <li>The <code>-K</code> flag ensures file integrity by verifying checksums after the download.</li> <li>The <code>--icat</code> flag uses iCAT as a transfer broker, bypassing direct resource server access to prevent potential transfer failures.</li> </ul> </li> <li> <p>Sync a collection in the Data Store with a local directory: <pre><code>gocmd get --progress -f -K --icat --diff --delete /iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code>, syncing any new updates made to the original data.</p> <ul> <li>The <code>--diff</code> flag transfers only new or modified files, comparing sizes and checksums.</li> <li>The <code>--delete</code> flag removes files from the destination that don't exist in the source.</li> </ul> <p>This command is equivalent to: <pre><code>gocmd sync --progress -K --icat --delete i:/iplant/home/myUser/mydir /local/dir/\n</code></pre></p> </li> <li> <p>Download a collection using multiple parallel transfers: <pre><code>gocmd get --progress -f -K --icat --thread_num 10 /iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code> using 10 parallel transfer threads. Utilizing more transfer threads can maximize I/O and network bandwidth, often speeding up the transfer process significantly.</p> <ul> <li>The <code>--thread_num</code> flag sets the maximum number of threads to use for the transfer.</li> </ul> <p>Thread Count Considerations</p> <ol> <li>Higher thread counts require more CPU and memory. Excessive threads may overload your system, causing performance issues. For example, Discovery Environment (DE) apps limit transfer threads to 5 due to RAM constraints.</li> <li>The Data Store limits concurrent connections, potentially restricting high thread counts.</li> </ol> <p>Using GoCommands on the University of Arizona Campus Network?</p> <p>When using GoCommands on the UA Campus network, include the <code>--icat</code> flag for stable large file transfers.</p> </li> </ol>"},{"location":"ds/gocommands/data_transfer/#upload-data-to-the-data-store","title":"Upload Data to the Data Store","text":"<ol> <li> <p>Upload a local directory to a specific path in the Data Store: <pre><code>gocmd put --progress -f -K --icat /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> and its contents to the Data Store at <code>/iplant/home/myUser/mydir/</code>. A new directory named <code>dir</code> will be created under <code>/iplant/home/myUser/mydir/</code>, resulting in <code>/iplant/home/myUser/mydir/dir</code> containing all the uploaded files and subdirectories.</p> <ul> <li>The <code>--progress</code> flag shows progress bars during file transfers.</li> <li>The <code>-f</code> flag forces overwriting of existing files in the Data Store without confirmation.</li> <li>The <code>-K</code> flag ensures file integrity by verifying checksums after upload.</li> <li>The <code>--icat</code> flag uses iCAT as a transfer broker, bypassing direct resource server access to prevent potential transfer failures.</li> </ul> </li> <li> <p>Sync a local directory with a collection in the Data Store: <pre><code>gocmd put --progress -f -K --icat --diff --delete /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> to <code>/iplant/home/myUser/mydir/</code> in the Data Store, syncing any new or updated files. It also removes extra files in the destination collection that do not exist locally.</p> <ul> <li>The <code>--diff</code> flag transfers only new or modified files, comparing sizes and checksums.</li> <li>The <code>--delete</code> flag removes files from the destination that don't exist in the source.</li> </ul> <p>This command is equivalent to: <pre><code>gocmd sync --progress -K --icat --delete /local/dir/ i:/iplant/home/myUser/mydir/\n</code></pre></p> </li> <li> <p>Upload a local directory using multiple parallel transfers: <pre><code>gocmd put --progress -f -K --icat --thread_num 10 /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> and its contents to <code>/iplant/home/myUser/mydir/</code> in the Data Store using 10 parallel transfer threads. This can significantly speed up the upload process by maximizing I/O and network bandwidth.</p> <ul> <li>The <code>--thread_num</code> flag sets the maximum number of threads to use for the transfer.</li> </ul> <p>Thread Count Considerations</p> <ol> <li>Higher thread counts require more CPU and memory. Excessive threads may overload your system, causing performance issues. For example, Discovery Environment (DE) apps limit transfer threads to 5 due to RAM constraints.</li> <li>The Data Store limits concurrent connections, potentially restricting high thread counts.</li> </ol> <p>Using GoCommands on the University of Arizona Campus Network?</p> <p>When using GoCommands on the UA Campus network, include the <code>--icat</code> flag for stable large file transfers.</p> </li> <li> <p>Upload a local directory containing many small files: <pre><code>gocmd bput --progress -K --icat --thread_num 10 /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> containing numerous small files to <code>/iplant/home/myUser/mydir/</code> in the Data Store. Using bundle transfer and parallel transfer can significantly speed up the transfer of many small files.</p> <p>This command is equivalent to: <pre><code>gocmd sync --bulk_upload --progress -K --icat /local/dir/ i:/iplant/home/myUser/mydir/\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/installation/","title":"GoCommands Installation and Upgrade","text":""},{"location":"ds/gocommands/installation/#installation-using-pre-built-binaries","title":"Installation using Pre-built Binaries","text":"<p>GoCommands provides pre-built binaries for various operating systems and architectures. Choose the appropriate command for your system to install the latest version.</p>"},{"location":"ds/gocommands/installation/#macos","title":"macOS","text":"<p>macOS runs on a variety of Apple devices, including MacBook, MacBook Pro, MacBook Air, iMac, Mac mini, Mac Studio, and Mac Pro. Depending on the model, it may use either an Intel/AMD 64-bit CPU or Apple Silicon (M1/M2). Follow the appropriate installation instructions based on your processor.</p> <p>Unsure which CPU architecture your Mac uses?</p> <p> Run the following command in the terminal: <pre><code>uname -p\n</code></pre> This will return <code>aarch64</code> / <code>arm64</code> for Apple Silicon (M1/M2) or <code>x86_64</code> for Intel-based Macs.</p>"},{"location":"ds/gocommands/installation/#intel-64-bit","title":"Intel 64-bit","text":"<p>Intel processors were used in Mac devices released before 2020. If you're using an older Mac, install GoCommands with the following command:  </p> <pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-darwin-amd64.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#apple-silicon-m1m2","title":"Apple Silicon (M1/M2)","text":"<p>Apple introduced its custom Silicon chips (M1, M2) in 2020, replacing Intel processors in newer Mac models. If your device runs on Apple Silicon, use the following command to install GoCommands:  </p> <pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-darwin-arm64.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#linux","title":"Linux","text":"<p>Linux supports a wide range of CPU architectures. Follow the appropriate installation instructions based on your processor type.  </p> <p>Unsure which CPU architecture your system uses?</p> <p> Run the following command in the terminal: <pre><code>uname -p\n</code></pre> This command will return the architecture type, such as <code>x86_64</code> for 64-bit Intel/AMD processors, <code>i386</code> / <code>i686</code> for 32-bit Intel/AMD processors, <code>aarch64</code> / <code>arm64</code> for 64-bit ARM processors, or <code>arm</code> for 32-bit ARM processors.</p>"},{"location":"ds/gocommands/installation/#intelamd-64-bit","title":"Intel/AMD 64-bit","text":"<pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-linux-amd64.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#intelamd-32-bit","title":"Intel/AMD 32-bit","text":"<pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-linux-386.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#arm-64-bit","title":"ARM 64-bit","text":"<pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-linux-arm64.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#arm-32-bit","title":"ARM 32-bit","text":"<pre><code>GOCMD_VER=$(curl -L -s https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt); \\\ncurl -L -s https://github.com/cyverse/gocommands/releases/download/${GOCMD_VER}/gocmd-${GOCMD_VER}-linux-arm.tar.gz | tar zxvf -\n</code></pre>"},{"location":"ds/gocommands/installation/#windows","title":"Windows","text":"<p>Windows primarily runs on Intel/AMD CPU architectures. Most modern systems use 64-bit Intel/AMD processors, while very old systems may run on 32-bit processors.  </p> <p>Windows includes two main terminal applications: <code>Command Prompt (CMD)</code> and <code>PowerShell</code>. Follow the appropriate installation instructions based on your processor type and preferred terminal.</p>"},{"location":"ds/gocommands/installation/#command-prompt-cmd","title":"Command Prompt (CMD)","text":"<p>Unsure which CPU architecture your system uses?</p> <p> Run the following command in the Command Prompt (CMD): <code>echo %PROCESSOR_ARCHITECTURE%</code>sh This command will return the architecture type, such as <code>AMD64</code> for 64-bit Intel/AMD processors or <code>x86</code> for 32-bit Intel/AMD processors.</p>"},{"location":"ds/gocommands/installation/#intelamd-64-bit_1","title":"Intel/AMD 64-bit","text":"<pre><code>curl -L -s -o gocmdv.txt https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt &amp;&amp; set /p GOCMD_VER=&lt;gocmdv.txt\ncurl -L -s -o gocmd.zip https://github.com/cyverse/gocommands/releases/download/%GOCMD_VER%/gocmd-%GOCMD_VER%-windows-amd64.zip &amp;&amp; tar zxvf gocmd.zip &amp;&amp; del gocmd.zip gocmdv.txt\n</code></pre>"},{"location":"ds/gocommands/installation/#intelamd-32-bit_1","title":"Intel/AMD 32-bit","text":"<pre><code>curl -L -s -o gocmdv.txt https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt &amp;&amp; set /p GOCMD_VER=&lt;gocmdv.txt\ncurl -L -s -o gocmd.zip https://github.com/cyverse/gocommands/releases/download/%GOCMD_VER%/gocmd-%GOCMD_VER%-windows-386.zip &amp;&amp; tar zxvf gocmd.zip &amp;&amp; del gocmd.zip gocmdv.txt\n</code></pre>"},{"location":"ds/gocommands/installation/#powershell","title":"PowerShell","text":"<p>Unsure which CPU architecture your system uses?</p> <p> Run the following command in the PowerShell: <pre><code>$env:PROCESSOR_ARCHITECTURE\n</code></pre> This command will return the architecture type, such as <code>AMD64</code> for 64-bit Intel/AMD processors or <code>x86</code> for 32-bit Intel/AMD processors.</p>"},{"location":"ds/gocommands/installation/#intelamd-64-bit_2","title":"Intel/AMD 64-bit","text":"<pre><code>curl -o gocmdv.txt https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt ; $env:GOCMD_VER = (Get-Content gocmdv.txt)\ncurl -o gocmd.zip https://github.com/cyverse/gocommands/releases/download/$env:GOCMD_VER/gocmd-$env:GOCMD_VER-windows-amd64.zip ; tar zxvf gocmd.zip ; del gocmd.zip ; del gocmdv.txt\n</code></pre>"},{"location":"ds/gocommands/installation/#intelamd-32-bit_2","title":"Intel/AMD 32-bit","text":"<pre><code>curl -o gocmdv.txt https://raw.githubusercontent.com/cyverse/gocommands/main/VERSION.txt ; $env:GOCMD_VER = (Get-Content gocmdv.txt)\ncurl -o gocmd.zip https://github.com/cyverse/gocommands/releases/download/$env:GOCMD_VER/gocmd-$env:GOCMD_VER-windows-386.zip ; tar zxvf gocmd.zip ; del gocmd.zip ; del gocmdv.txt\n</code></pre>"},{"location":"ds/gocommands/installation/#installation-via-conda","title":"Installation via Conda","text":"<p>GoCommands can be installed via <code>conda</code> if you are using Linux or Mac OS. Unfortunately, Windows system is not yet supported. Please follow instructions below to install.</p> <ol> <li> <p>Add <code>conda-forge</code> channel to <code>conda</code>. This is required because GoCommands is added to <code>conda-forge</code> channel.     <pre><code>conda config --add channels conda-forge\nconda config --set channel_priority strict\n</code></pre></p> </li> <li> <p>Install GoCommands with <code>conda</code>.     <pre><code>conda install gocommands\n</code></pre></p> </li> </ol> <p>This will install the latest version of GoCommands available in the conda-forge repository.</p>"},{"location":"ds/gocommands/installation/#manual-installation-or-specific-versions","title":"Manual Installation or Specific Versions","text":"<p>If you need a specific release version or prefer to manually download the binaries, visit the GoCommands releases page:  </p> <p>GoCommands Releases</p> <p>Here, you can browse and download any available version of GoCommands for your operating system.</p>"},{"location":"ds/gocommands/installation/#upgrade","title":"Upgrade","text":"<p>Keeping GoCommands up to date ensures you have the latest features and bug fixes. To upgrade to the latest version, follow these steps:  </p> <ol> <li> <p>Run the upgrade command: <pre><code>gocmd upgrade\n</code></pre></p> </li> <li> <p>If GoCommands is installed in a system directory, you may need administrative privileges. On Unix-like systems, use: <pre><code>sudo gocmd upgrade\n</code></pre></p> </li> </ol> <p>This command automatically downloads and installs the latest release.</p>"},{"location":"ds/gocommands/issue_report/","title":"GoCommands Troubleshooting and Issue Report","text":""},{"location":"ds/gocommands/issue_report/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ds/gocommands/issue_report/#command-not-found-error","title":"Command Not Found Error","text":"<p>This error indicates that the system could not locate <code>gocmd</code> binary in the directories specified by the <code>$PATH</code> environment variable. </p> <p>To resolve this:</p> <ol> <li>Use an absolute or relative path: Run <code>./gocmd init</code> from the directory where you downloaded the <code>gocmd</code> binary.</li> <li>For easier future use: Move the <code>gocmd</code> binary to a directory in your <code>$PATH</code>, such as <code>/usr/local/bin</code>.</li> <li>Windows users: Ensure the executable is named <code>gocmd.exe</code> and run <code>gocmd.exe init</code> to initialize.</li> </ol>"},{"location":"ds/gocommands/issue_report/#cannot-execute-binary-file-exec-format-error","title":"Cannot Execute Binary File (Exec Format Error)","text":"<p>This error occurs when the <code>gocmd</code> binary is incompatible with your CPU architecture or operating system. To resolve this issue:</p> <ol> <li>Review the installation instructions to ensure you downloaded the correct version for your system.</li> <li>Verify your system's architecture and OS version:<ul> <li>On Linux/macOS, use the command <code>uname -m</code> for architecture and <code>uname -s</code> for OS.</li> <li>On Windows, check System Information in the Control Panel.</li> </ul> </li> <li>Download the appropriate <code>gocmd</code> binary that matches your system specifications.</li> <li>If the problem persists, seek support from the CyVerse community.</li> </ol>"},{"location":"ds/gocommands/issue_report/#path-not-found-error-in-windows","title":"Path Not Found Error in Windows","text":"<p>In Windows, the backslash (<code>\\</code>) is used as the default path delimiter, while the forward slash (<code>/</code>) is used in Linux and macOS. If you encounter a \"Path not found\" error, ensure the following:</p> <ol> <li> <p>Local Path: Verify that your local path is correctly specified using the backslash (<code>\\</code>) as the delimiter. For example:</p> <ul> <li>Correct: <code>C:\\Users\\YourName\\Documents</code></li> <li>Incorrect: <code>C:/Users/YourName/Documents</code></li> </ul> </li> <li> <p>Data Store Path: Use the forward slash (<code>/</code>) as the delimiter for paths in the Data Store. For example:</p> <ul> <li>Correct: <code>/iplant/home/username/folder</code></li> <li>Incorrect: <code>\\iplant\\home\\username\\folder</code></li> </ul> </li> </ol>"},{"location":"ds/gocommands/issue_report/#keep-failing-large-file-transfer","title":"Keep Failing Large File Transfer","text":"<p>If you are using GoCommands within the University of Arizona Campus or the Discovery Environment, large file transfers may fail due to campus firewall restrictions. This issue occurs when transferring files via resource servers using commands like <code>get</code>, <code>put</code>, <code>bput</code>, and <code>sync</code>. By default, these commands transfer large files (\u22651GB) through resource servers or when the <code>--redirect</code> flag is specified. To avoid such failures, use the <code>--icat</code> flag to transfer data directly through ICAT.</p>"},{"location":"ds/gocommands/issue_report/#request-support","title":"Request Support","text":"<p>If you encounter an issue that you cannot resolve, please contact support@cyverse.org for assistance. Your Data Store access via GoCommands may be limited or fail due to various factors, including configuration issues, network problems, authentication errors, or data policies. The support team is available to help you identify and resolve these issues.</p>"},{"location":"ds/gocommands/issue_report/#report-bugs","title":"Report Bugs","text":"<p>If you encounter a bug, please report it to our GitHub repository. Your detailed bug report is valuable in helping us improve the stability and usability of GoCommands.</p> <p>When submitting a bug report, please include the following information:</p> <ul> <li>System Information: Specify your CPU architecture and operating system (OS).</li> <li>Failing Command: Provide the exact command you used that resulted in the error.</li> <li>Debug Log: Run the command with the <code>-d</code> flag to display debug output, then copy and paste the relevant error messages into your report. This provides valuable context for troubleshooting.</li> </ul>"},{"location":"ds/gocommands/metadata_management/","title":"Metadata Management using GoCommands","text":"<p>GoCommands provides features to manage metadata for data objects, collections, resources, and users in the Data Store using the <code>lsmeta</code>, <code>addmeta</code>, and <code>rmmeta</code> commands.</p> <p>Metadata consists of three components:</p> <ul> <li>Name (Attribute): The name of information.</li> <li>Value: The actual data or information.</li> <li>Unit (Optional): Specifies the unit of measurement, if applicable.</li> </ul>"},{"location":"ds/gocommands/metadata_management/#list-metadata-of-data-objects-collections-resources-or-users","title":"List Metadata of Data Objects, Collections, Resources, or Users","text":"<pre><code>gocmd lsmeta [flags] &lt;irods-object&gt;...\n</code></pre>"},{"location":"ds/gocommands/metadata_management/#irods-objects","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> or <code>collection</code> <code>-P</code> List metadata of data objects or collections <code>resource</code> <code>-R</code> List metadata of resources <code>user</code> <code>-U</code> List metadata of users"},{"location":"ds/gocommands/metadata_management/#example-usage","title":"Example Usage","text":"<ol> <li> <p>List metadata of a data object: <pre><code>gocmd lsmeta -P /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>List metadata of multiple data objects: <pre><code>gocmd lsmeta -P /iplant/home/myUser/file1.txt /iplant/home/myUser/file2.txt\n</code></pre></p> </li> <li> <p>List metadata of a collection: <pre><code>gocmd lsmeta -P /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>List metadata of a resource: <pre><code>gocmd lsmeta -R myResc\n</code></pre></p> </li> <li> <p>List metadata of a user: <pre><code>gocmd lsmeta -U myUser\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/metadata_management/#add-metadata-to-data-objects-collections-resources-or-users","title":"Add Metadata to Data Objects, Collections, Resources, or Users","text":"<pre><code>gocmd addmeta [flags] &lt;irods-object&gt; &lt;metadata-name&gt; &lt;metadata-value&gt; [metadata-unit]\n</code></pre>"},{"location":"ds/gocommands/metadata_management/#irods-objects_1","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> or <code>collection</code> <code>-P</code> Add metadata to a data object or collection <code>resource</code> <code>-R</code> Add metadata to a resource <code>user</code> <code>-U</code> Add metadata to a user"},{"location":"ds/gocommands/metadata_management/#example-usage_1","title":"Example Usage","text":"<ol> <li> <p>Add metadata to a data object: <pre><code>gocmd addmeta -P /iplant/home/myUser/file.txt meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a data object with metadata-unit: <pre><code>gocmd addmeta -P /iplant/home/myUser/file.txt meta_name meta_value meta_unit\n</code></pre></p> </li> <li> <p>Add metadata to a collection: <pre><code>gocmd addmeta -P /iplant/home/myUser/dir meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a resource: <pre><code>gocmd addmeta -R myResc meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a user: <pre><code>gocmd addmeta -U myUser meta_name meta_value\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/metadata_management/#remove-metadata-from-data-objects-collections-resources-or-users","title":"Remove Metadata from Data Objects, Collections, Resources, or Users","text":"<pre><code>gocmd rmmeta [flags] &lt;irods-object&gt; &lt;metadata-ID-or-name&gt;\n</code></pre> <p>Note: The <code>metadata-ID</code> is a numeric identifier for the metadata. It can be obtained from the output of the <code>lsmeta</code> command.</p>"},{"location":"ds/gocommands/metadata_management/#irods-objects_2","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> or <code>collection</code> <code>-P</code> Remove metadata from a data object or collection <code>resource</code> <code>-R</code> Remove metadata from a resource <code>user</code> <code>-U</code> Remove metadata from a user"},{"location":"ds/gocommands/metadata_management/#example-usage_2","title":"Example Usage","text":"<ol> <li> <p>Remove metadata from a data object by name: <pre><code>gocmd rmmeta -P /iplant/home/myUser/file.txt meta_name\n</code></pre></p> </li> <li> <p>Remove metadata from a data object by ID: <pre><code>gocmd rmmeta -P /iplant/home/myUser/file.txt 979206950\n</code></pre></p> </li> <li> <p>Remove metadata from a collection: <pre><code>gocmd rmmeta -P /iplant/home/myUser/dir meta_name\n</code></pre></p> </li> <li> <p>Remove metadata from a resource: <pre><code>gocmd rmmeta -R myResc meta_name\n</code></pre></p> </li> <li> <p>Remove metadata from a user: <pre><code>gocmd rmmeta -U myUser meta_name\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/sftp_public_key_auth/","title":"SFTP Public-key Authentication Configuration using GoCommands","text":"<p>GoCommands provides a feature to configure public-key authentication for the Data Store's SFTP service. The <code>copy-sftp-id</code> command uploads your local SSH public keys to the Data Store, enabling password-less authentication for the SFTP service.</p>"},{"location":"ds/gocommands/sftp_public_key_auth/#setting-up-public-key-authentication","title":"Setting Up Public-key Authentication","text":"<ol> <li> <p>Generate an SSH key (if needed): <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre></p> <p>This creates a private key <code>id_rsa</code> and a public key <code>id_rsa.pub</code> in the <code>~/.ssh</code> directory.</p> </li> <li> <p>To copy all SSH public keys from your <code>~/.ssh</code> directory, run: <pre><code>gocmd copy-sftp-id\n</code></pre></p> <p>This command automatically detects all SSH public keys for the current local user in the <code>~/.ssh</code> directory at local machine and copies them to <code>/iplant/home/&lt;username&gt;/.ssh/authorized_keys</code> in the Data Store. This process is similar to standard SSH public-key registration.</p> </li> <li> <p>To copy the specified SSH public key, use: <pre><code>gocmd copy-sftp-id -i ~/.ssh/id_rsa.pub\n</code></pre></p> <p>This command copies only the SSH public key from the <code>~/.ssh/id_rsa.pub</code> file to <code>/iplant/home/&lt;username&gt;/.ssh/authorized_keys</code> in the Data Store.</p> </li> </ol>"},{"location":"ds/gocommands/sftp_public_key_auth/#advanced-configuration","title":"Advanced Configuration","text":"<p>For advanced usage, you can control public-key access by manually editing the <code>/iplant/home/&lt;username&gt;/.ssh/authorized_keys</code> file in the Data Store. This process involves downloading the file, making changes, and then uploading it back. Here's how to do it:</p> <ol> <li> <p>Download the <code>authorized_keys</code> file: <pre><code>gocmd get /iplant/home/myUser/.ssh/authorized_keys .\n</code></pre></p> </li> <li> <p>Edit the file locally with a editor:     Open it with a text editor (e.g., <code>vi</code>, <code>nano</code>):     <pre><code>vi authorized_keys\n</code></pre></p> <p>Add parameters in <code>key=value</code> format before each SSH key. Example: <pre><code>expiry-time=\"20250320\" from=\"10.11.12.13\" ssh-rsa AAAAB3Nza... myUser\n</code></pre></p> </li> <li> <p>Upload the modified file back to the Data Store: <pre><code>gocmd put authorized_keys /iplant/home/myUser/.ssh/\n</code></pre></p> </li> </ol>"},{"location":"ds/gocommands/sftp_public_key_auth/#available-parameters","title":"Available Parameters","text":"Parameter Description Example <code>expiry-time</code> Sets expiration date-time in <code>YYYYMMDD</code>, <code>YYYYMMDDhhmm</code>, or <code>YYYYMMDDhhmmss</code> format <code>expiry-time=\"20250320\"</code> <code>from</code> Allows access from specific IP addresses. Use IP address, CIDR, or <code>!</code> prefix to negate. Separate multiple entries with commas <code>from=\"10.11.12.13,!10.11.12.14\"</code> <code>home</code> Sets a specific home collection path for SFTP access within the Data Store. Use absolute path of the collection in the Data Store <code>home=/iplant/home/myUser/sftp_home</code>"},{"location":"ds/icommands/","title":"Manage Your Data with iCommands","text":"<p>iCommands is a command-line tool designed for efficient data management in iRODS. Developed by the iRODS Consortium, which created the iRODS data system powering the Data Store, iCommands provides robust support for data transfers, synchronization, access control, and metadata management. It is compatible with popular Linux environments.  </p> <p>This guide covers installation, data transfer, access management, and metadata handling to help you efficiently manage your data in the Data Store.</p>"},{"location":"ds/icommands/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>Configuration</li> <li>Data Management</li> <li>Data Transfer</li> <li>Access Management</li> <li>Metadata Management</li> <li>Troubleshooting and Issue Report</li> </ol>"},{"location":"ds/icommands/#installation","title":"Installation","text":"<p>Set up iCommands on your system and configure it for seamless interaction with the Data Store.</p>"},{"location":"ds/icommands/#configuration","title":"Configuration","text":"<p>Set up iCommands in your environment for seamless interaction with the Data Store.</p>"},{"location":"ds/icommands/#data-management","title":"Data Management","text":"<p>Navigate the file structure and efficiently manage your data, including organizing, renaming, and deleting files and directories.</p>"},{"location":"ds/icommands/#data-transfer","title":"Data Transfer","text":"<p>Upload and download data between your local system and the Data Store. Learn different transfer methods to optimize speed and reliability.</p>"},{"location":"ds/icommands/#access-management","title":"Access Management","text":"<p>Manage file and directory permissions effectively. Learn how to grant, modify, and revoke access.</p>"},{"location":"ds/icommands/#metadata-management","title":"Metadata Management","text":"<p>Enhance data discoverability and organization by adding, updating, and managing metadata for files stored in the Data Store.</p>"},{"location":"ds/icommands/#troubleshooting-and-issue-report","title":"Troubleshooting and Issue Report","text":"<p>Encountered an issue? Learn how to report bugs, troubleshoot errors, and contribute to the improvement of iCommands.</p>"},{"location":"ds/icommands/access_management/","title":"Access Management using iCommands","text":"<p>iCommands provides features to manage access of users and groups to data in the Data Store. The <code>ichmod</code> command allows users to manage access permissions for data objects (files) and collections (directories). The <code>ils -A</code> command displays the current access levels assigned to users for a given file or directory.</p>"},{"location":"ds/icommands/access_management/#list-access-permissions-of-users-for-a-data-object-or-collection","title":"List Access Permissions of Users for a Data Object or Collection","text":"<pre><code>ils -A &lt;data-object-or-collection&gt;\n</code></pre> <p>The <code>-A</code> flag in <code>ils</code> command displays access permissions in the result.</p> <p>This command will show the data objects and collections along with their access control lists (ACLs). For example:</p> <pre><code>/iplant/home/myUser/mydata:\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n        Inheritance - Disabled\n    file1.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    file2.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre> <ul> <li>The <code>g:</code> prefix in the ACL username indicates that the user is a group.</li> <li>The ACL is displayed in the <code>username#zone:access_level</code> format.</li> <li>Most common access levels are:<ul> <li><code>read_object</code>: Allows read access to the data object or collection.</li> <li><code>modify_object</code>: Allows modification (write) of the data object or collection.</li> <li><code>own</code>: Grants ownership of the data object or collection.</li> </ul> </li> </ul>"},{"location":"ds/icommands/access_management/#example-usage","title":"Example Usage","text":"<ol> <li>List current access levels for a data object or collection: <pre><code>ils -A /iplant/home/myUser/mydata\n</code></pre></li> </ol>"},{"location":"ds/icommands/access_management/#change-a-users-or-groups-access-permission-for-a-data-object-or-collection","title":"Change a User's or Group's Access Permission for a Data Object or Collection","text":"<pre><code>ichmod &lt;access-level&gt; &lt;user-or-group(#zone)&gt; &lt;data-object-or-collection&gt;\n</code></pre>"},{"location":"ds/icommands/access_management/#access-levels","title":"Access Levels","text":"Access Level Description <code>null</code> Removes all permissions <code>read</code> Allows reading the object or collection <code>write</code> Allows reading and modifying the object or collection <code>own</code> Grants full control, including the ability to change permissions"},{"location":"ds/icommands/access_management/#example-usage_1","title":"Example Usage","text":"<ol> <li> <p>Grant a user read permission to a data object: <pre><code>ichmod read anotherUser /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Grant a user from a different zone read permission to a data object: <pre><code>ichmod read anotherUser#anotherZone /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Grant a user read permission to a collection and its contents: <pre><code>ichmod -r read anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Grant a user write permission to a collection and its contents: <pre><code>ichmod -r write anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Grant a user owner permission to a collection and its contents: <pre><code>ichmod -r owner anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Remove access permission from a user to a collection and its contents: <pre><code>ichmod -r none anotherUser /iplant/home/myUser/dir\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/access_management/#enable-or-disable-access-permission-inheritance-for-a-collection","title":"Enable or Disable Access Permission Inheritance for a Collection","text":"<p>When inheritance is enabled for a collection, any new data objects or subcollections created within it will automatically inherit the same access permissions as the parent collection.</p> <pre><code>ichmod &lt;inheritance_option&gt; &lt;collection_path&gt;\n</code></pre>"},{"location":"ds/icommands/access_management/#inheritance-options","title":"Inheritance Options","text":"Flag Description <code>inherit</code> Enable access inheritance. Data objects and sub-collections inherit permissions from the parent collection <code>noinherit</code> Disable access inheritance. Data objects and sub-collections do not inherit permissions from the parent collection"},{"location":"ds/icommands/access_management/#example-usage_2","title":"Example Usage","text":"<ol> <li> <p>Enable inheritance for a collection: <pre><code>ichmod inherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Disable inheritance for a collection: <pre><code>ichmod noinherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Enable inheritance recursively for a collection and its subcollections: <pre><code>ichmod -r inherit /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>Disable inheritance recursively for a collection and its subcollections: <pre><code>ichmod -r noinherit /iplant/home/myUser/dir\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/configuration/","title":"iCommands Configuration","text":""},{"location":"ds/icommands/configuration/#using-the-iinit-command","title":"Using the <code>iinit</code> Command","text":"<p>The <code>iinit</code> command sets up the iRODS Host and access account for use with other iCommands tools. Once the configuration is set, configuration files are created under the <code>~/.irods</code> directory.</p> <p>Running iCommands in an HPC environment?</p> <p> To use pre-installed iCommands in an HPC environment, run following to access iCommands: <pre><code>module load irods\n</code></pre></p> <ol> <li> <p>Run the following command to configure iCommands: <pre><code>iinit\n</code></pre></p> </li> <li> <p>Enter your Data Store account credentials when prompted. Use the following information:</p> Configuration Key Value <code>irods_host</code> <code>data.cyverse.org</code> <code>irods_port</code> <code>1247</code> <code>irods_zone_name</code> <code>iplant</code> <code>irods_user_name</code> <code>&lt;CyVerse Username&gt;</code> <code>irods_user_password</code> <code>&lt;CyVerse Password&gt;</code> <p>Use these credentials for anonymous access to the Data Store:</p> Configuration Key Value <code>irods_user_name</code> <code>anonymous</code> <code>irods_user_password</code> (leave empty) </li> <li> <p>To verify the current configuration, use: <pre><code>ienv\n</code></pre></p> <p>This will display the current configurations.</p> </li> <li> <p>Execute iCommands for your task: <pre><code>ils\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/configuration/#using-environmental-variables","title":"Using Environmental Variables","text":"<p>The <code>iinit</code> command can be executed with environmental variables to automate configuration.</p> <ol> <li> <p>Export the required variables in your terminal: <pre><code>export IRODS_HOST=\"data.cyverse.org\"\nexport IRODS_PORT=1247\nexport IRODS_ZONE_NAME=\"iplant\"\nexport IRODS_USER_NAME=\"&lt;CyVerse Username&gt;\"\n</code></pre></p> <p>Note: iCommands does not support setting passwords via environment variables.</p> </li> <li> <p>Execute the <code>iinit</code> command: <pre><code>iinit\n</code></pre></p> <p>Note: <code>iinit</code> will prompt you to input only the missing fields.</p> </li> </ol>"},{"location":"ds/icommands/configuration/#full-list-of-supported-configuration-fields","title":"Full List of Supported Configuration Fields","text":"<p>Below is a comprehensive list of supported fields, along with their corresponding names in JSON, and environmental variables:</p> Field Name JSON Key Environmental Variable Default Value AuthenticationScheme <code>irods_authentication_scheme</code> <code>IRODS_AUTHENTICATION_SCHEME</code> native AuthenticationFile <code>irods_authentication_file</code> <code>IRODS_AUTHENTICATION_FILE</code> ~/irods/.irodsA ClientServerNegotiation <code>irods_client_server_negotiation</code> <code>IRODS_CLIENT_SERVER_NEGOTIATION</code> off ClientServerPolicy <code>irods_client_server_policy</code> <code>IRODS_CLIENT_SERVER_POLICY</code> CS_NEG_REFUSE Host <code>irods_host</code> <code>IRODS_HOST</code> Port <code>irods_port</code> <code>IRODS_PORT</code> 1247 ZoneName <code>irods_zone_name</code> <code>IRODS_ZONE_NAME</code> ClientZoneName <code>irods_client_zone_name</code> <code>IRODS_CLIENT_ZONE_NAME</code> Username <code>irods_user_name</code> <code>IRODS_USER_NAME</code> ClientUsername <code>irods_client_user_name</code> <code>IRODS_CLIENT_USER_NAME</code> DefaultResource <code>irods_default_resource</code> <code>IRODS_DEFAULT_RESOURCE</code> CurrentWorkingDir <code>irods_cwd</code> <code>IRODS_CWD</code> Home <code>irods_home</code> <code>IRODS_HOME</code> DefaultHashScheme <code>irods_default_hash_scheme</code> <code>IRODS_DEFAULT_HASH_SCHEME</code> SHA256 MatchHashPolicy <code>irods_match_hash_policy</code> <code>IRODS_MATCH_HASH_POLICY</code> Debug <code>irods_debug</code> <code>IRODS_DEBUG</code> LogLevel <code>irods_log_level</code> <code>IRODS_LOG_LEVEL</code> 0 EncryptionAlgorithm <code>irods_encryption_algorithm</code> <code>IRODS_ENCRYPTION_ALGORITHM</code> AES-256-CBC EncryptionKeySize <code>irods_encryption_key_size</code> <code>IRODS_ENCRYPTION_KEY_SIZE</code> 32 EncryptionSaltSize <code>irods_encryption_salt_size</code> <code>IRODS_ENCRYPTION_SALT_SIZE</code> 8 EncryptionNumHashRounds <code>irods_encryption_num_hash_rounds</code> <code>IRODS_ENCRYPTION_NUM_HASH_ROUNDS</code> 16 SSLCACertificateFile <code>irods_ssl_ca_certificate_file</code> <code>IRODS_SSL_CA_CERTIFICATE_FILE</code> SSLCACertificatePath <code>irods_ssl_ca_certificate_path</code> <code>IRODS_SSL_CA_CERTIFICATE_PATH</code> SSLVerifyServer <code>irods_ssl_verify_server</code> <code>IRODS_SSL_VERIFY_SERVER</code> hostname SSLCertificateChainFile <code>irods_ssl_certificate_chain_file</code> <code>IRODS_SSL_CERTIFICATE_CHAIN_FILE</code> SSLCertificateKeyFile <code>irods_ssl_certificate_key_file</code> <code>IRODS_SSL_CERTIFICATE_KEY_FILE</code> SSLDHParamsFile <code>irods_ssl_dh_params_file</code> <code>IRODS_SSL_DH_PARAMS_FILE</code>"},{"location":"ds/icommands/data_management/","title":"Data Management using iCommands","text":"<p>iCommands offers a variety of commands to help you manage your data in the Data Store. In the Data Store, <code>file</code> and <code>directory</code> are treated as <code>data objects</code> and <code>collections</code>, respectively. It's perfectly fine to consider these terms interchangeable.</p>"},{"location":"ds/icommands/data_management/#display-the-current-working-collection","title":"Display the Current Working Collection","text":"<p>In the Data Store, the current working collection is equivalent to the concept of a current working directory in traditional file systems. You can display or change your current working collection using iCommands.</p> <pre><code>ipwd\n</code></pre> <p>By default, after configuring iCommands, your current working collection is set to your home directory, which is typically located at: <pre><code>/&lt;Zone Name&gt;/home/&lt;Username&gt;\n</code></pre></p> <p>Note: Paths in the Data Store always start with the zone name <code>/iplant</code>.</p>"},{"location":"ds/icommands/data_management/#change-the-current-working-collection","title":"Change the Current Working Collection","text":"<ol> <li> <p>Change to a specific collection using an absolute path: <pre><code>icd /iplant/home/myUser/mydata\n</code></pre></p> <p>This changes your current working collection to <code>/iplant/home/myUser/mydata</code>.</p> </li> <li> <p>Use a relative path from your current location:     Assuming your current working collection is <code>/iplant/home/myUser</code>:</p> <pre><code>icd mydata\n</code></pre> </li> <li> <p>Return to your home collection: <pre><code>icd \"~\"\n</code></pre></p> <p>Note: The <code>~</code> must be quoted to prevent shell expansion by your local shell. Without quotes, it will expand to your local machine's home directory instead of your Data Store home directory.</p> </li> <li> <p>Move up one level: <pre><code>icd ..\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/data_management/#list-data-objects-files-and-collections-directories","title":"List Data Objects (files) and Collections (directories)","text":"<ol> <li> <p>List the content of a collection: <pre><code>ils /iplant/home/myUser/mydata\n</code></pre></p> <p>This will display the data objects and collections in the <code>/iplant/home/myUser/mydata</code> collection: <pre><code>/iplant/home/myUser/mydata:\n    file1.bin\n    file2.bin\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <p>The <code>C-</code> prefix indicates that the item is a collection (directory).</p> </li> <li> <p>List the content of the current working collection: <pre><code>ils\n</code></pre></p> </li> <li> <p>List the contents of a collection in long format with additional details: <pre><code>ils -l /iplant/home/myUser/mydata\n</code></pre></p> <p>This command will show the data objects and collections within <code>/iplant/home/myUser/mydata</code>, along with their additional details: <pre><code>/iplant/home/myUser/mydata:\n    myUser  0   demoRes1;rs1    436 2024-04-02.13:36    &amp;   file1.bin\n    myUser  1   demoRes2;rs2    436 2024-04-02.13:36    &amp;   file1.bin\n    myUser  0   demoRes1;rs1    700 2024-04-02.17:15    &amp;   file2.bin\n    myUser  1   demoRes2;rs2    700 2024-04-02.17:15    &amp;   file2.bin\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <ul> <li>Each output line for a data object represents a replica. If iRODS is configured to create multiple replicas, you will see one line for each replica of the data object. For example, if two replicas are created, two lines will be displayed for each file.</li> <li>Each line is shown in the <code>owner replica_id resource_server size creation_time replica_state name</code> format.</li> <li>Possible replica states are:<ul> <li><code>&amp;</code>: Good</li> <li><code>X</code>: Stale</li> <li><code>?</code>: Unknown</li> </ul> </li> </ul> </li> <li> <p>List the contents of a collection with their access control lists: <pre><code>ils -A /iplant/home/myUser/mydata\n</code></pre></p> <p>This command will show the data objects and collections within <code>/iplant/home/myUser/mydata</code>, along with their access control lists (ACLs): <pre><code>/iplant/home/myUser/mydata:\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n        Inheritance - Disabled\n    file1.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    file2.bin\n        ACL - g:rodsadmin#iplant:own    myUser#iplant:own\n    C- /iplant/home/myUser/mydata/subdir1\n</code></pre></p> <ul> <li>The <code>g:</code> prefix in the ACL username indicates that the user is a group.</li> <li>The ACL is displayed in the <code>username#zone:access_level</code> format.</li> <li>Most common access levels are:<ul> <li><code>read_object</code>: Allows read access to the data object or collection.</li> <li><code>modify_object</code>: Allows modification (write) of the data object or collection.</li> <li><code>own</code>: Grants ownership of the data object or collection.</li> </ul> </li> </ul> </li> </ol>"},{"location":"ds/icommands/data_management/#make-a-collections-directories","title":"Make a Collections (directories)","text":"<ol> <li> <p>Create a new collection: <pre><code>imkdir /iplant/home/myUser/newCollection\n</code></pre></p> </li> <li> <p>Create parent collections if they do not exist: <pre><code>imkdir -p /iplant/home/myUser/parentCollection/newCollection\n</code></pre></p> <p>This command creates the <code>newCollection</code> along with its parent collection <code>parentCollection</code> if it does not already exist.</p> </li> </ol>"},{"location":"ds/icommands/data_management/#upload-data-objects-files-and-collections-directories-to-the-data-store","title":"Upload Data Objects (files) and Collections (directories) to the Data Store","text":"<p>Warning</p> <p>When uploading your data to the Data Store, avoid using:</p> <ul> <li>Spaces in names (e.g., <code>experiment one.fastq</code>)</li> <li>Special characters: ~ `` ! @ # $ % ^ &amp; * ( ) + = { } [ ] | : ; \" ' &lt; &gt; , ? / and \\</li> </ul> <p>These may cuase issues with Discovery Environment Apps and command-line applications.</p> <p>Recommendation: Use underscores for long names (e.g., <code>experiment_one.fastq</code>).</p> <ol> <li> <p>Upload a single file: <pre><code>iput /local/path/file.txt /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the file <code>/local/path/file.txt</code> to <code>/iplant/home/myUser/</code>, creating <code>/iplant/home/myUser/file.txt</code> in the Data Store.</p> </li> <li> <p>Upload a directory and its contents: <pre><code>iput /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the contents of the directory <code>/local/dir</code> to <code>/iplant/home/myUser/dir</code> in the Data Store. The uploaded files and subdirectories will be placed within the <code>/iplant/home/myUser/dir</code> folder.</p> </li> <li> <p>Upload with progress output: <pre><code>iput -P /local/path/largefile.dat /iplant/home/myUser/\n</code></pre></p> </li> <li> <p>Force upload: <pre><code>iput -f /local/path/largefile.dat /iplant/home/myUser/\n</code></pre></p> <p>This command overwrites the existing file in the Data Store without prompting.</p> </li> <li> <p>Upload and verify checksum: <pre><code>iput -K /local/path/important_data.txt /iplant/home/myUser/\n</code></pre></p> <p>This command uploads the file and verifies its integrity by calculating a checksum during transfer.</p> </li> <li> <p>Upload via resource server: <pre><code>iput -I /local/dir /iplant/home/myUser/\n</code></pre></p> <p>This command bypasses the iCAT server for data transfer, directly accessing the specified resource server for optimized performance.</p> </li> <li> <p>Upload with connection auto-renewal: <pre><code>iput -T /local/dir /iplant/home/myUser/\n</code></pre></p> <p>Renews connections every 10 minutes to prevent failures due to connection or firewall issues.</p> </li> </ol>"},{"location":"ds/icommands/data_management/#download-data-objects-files-and-collections-directories-from-the-data-store","title":"Download Data Objects (files) and Collections (directories) From the Data Store","text":"<ol> <li> <p>Download a data object to a specific local path: <pre><code>iget /iplant/home/myUser/file.txt /local/path/file_new_name.txt\n</code></pre></p> <p>This command downloads the data object <code>/iplant/home/myUser/file.txt</code> and saves it as <code>/local/path/file_new_name.txt</code>.</p> </li> <li> <p>Download a collection to a specific local path: <pre><code>iget /iplant/home/myUser/dir /local/path/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/dir</code> and its contents to <code>/local/path</code>. A new directory named <code>dir</code> will be created under <code>/local/path</code>, resulting in <code>/local/path/dir</code> containing all the downloaded files and subdirectories.</p> </li> <li> <p>Download with progress output: <pre><code>iget -P /iplant/home/myUser/largefile.dat /local/dir/\n</code></pre></p> </li> <li> <p>Force download: <pre><code>iget -f /iplant/home/myUser/largefile.dat .\n</code></pre></p> <p>This command overwrites the local file without prompting if it already exists.</p> </li> <li> <p>Download and verify checksum: <pre><code>iget -K /iplant/home/myUser/important_data.txt .\n</code></pre></p> <p>This command downloads the file and verifies its integrity by calculating the checksum after download and comparing it with the original in the Data Store. This ensures data consistency and detects any corruption during transfer.</p> </li> <li> <p>Download via resource server: <pre><code>iget -I /iplant/home/myUser/dir /local/dir\n</code></pre></p> <p>This command bypasses the iCAT server for data transfer, directly accessing the specified resource server. It optimizes performance for large files by direct connection to the resource server.</p> </li> <li> <p>Download with connection auto-renewal: <pre><code>iget -T /iplant/home/myUser/dir /local/dir\n</code></pre></p> <p>Renews connections every 10 minutes to prevent failures due to connection or firewall issues.</p> </li> </ol>"},{"location":"ds/icommands/data_management/#remove-data-objects-files-or-collections-directories-from-the-data-store","title":"Remove Data Objects (files) or Collections (directories) From the Data Store","text":"<ol> <li> <p>Remove a single data object: <pre><code>irm /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>Remove an empty collection: <pre><code>irmdir /iplant/home/myUser/emptyCollection\n</code></pre></p> </li> <li> <p>Remove a collection and its contents recursively: <pre><code>irm -r /iplant/home/myUser/parentCollection\n</code></pre></p> </li> <li> <p>Force remove a collection and its contents recursively: <pre><code>irm -rf /iplant/home/myUser/parentCollection\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/data_management/#moverename-data-objects-files-or-collections-directories","title":"Move/Rename Data Objects (files) or Collections (directories)","text":"<ol> <li> <p>Rename a data object: <pre><code>imv /iplant/home/myUser/oldfile.txt /iplant/home/myUser/newfile.txt\n</code></pre></p> </li> <li> <p>Move a data object to a different collection: <pre><code>imv /iplant/home/myUser/file.txt /iplant/home/myUser/subcollection/\n</code></pre></p> </li> <li> <p>Rename a collection: <pre><code>imv /iplant/home/myUser/oldcollection /iplant/home/myUser/newcollection\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/data_management/#additional-resources","title":"Additional Resources","text":"<p>For detailed information on iCommands, refer to the iRODS iCommands Docs.</p>"},{"location":"ds/icommands/data_transfer/","title":"Data Transfer using iCommands","text":"<p>iCommands provides a range of commands designed to efficiently and conveniently transfer large datasets between your local machine and the Data Store.</p>"},{"location":"ds/icommands/data_transfer/#download-data-from-the-data-store","title":"Download Data from the Data Store","text":"<ol> <li> <p>Download a collection to a specific local path: <pre><code>iget -P -f -K -T /iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code>. A new directory named <code>mydir</code> will be created under <code>/local/dir/</code>, resulting in <code>/local/dir/mydir</code> containing all the downloaded files and subdirectories.</p> <ul> <li>The <code>-P</code> flag outputs download progress.</li> <li>The <code>-f</code> flag forces overwriting of existing local files without confirmation.</li> <li>The <code>-K</code> flag ensures file integrity by verifying checksums after the download.</li> <li>The <code>-T</code> flag renews connections every 10 minutes to prevent failures due to connection or firewall issues.</li> </ul> </li> <li> <p>Sync a collection in the Data Store with a local directory: <pre><code>irsync -r -K i:/iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code>, syncing any new updates made to the original data.</p> </li> <li> <p>Download a collection using multiple parallel transfers: <pre><code>iget -P -f -K -T -N 10 /iplant/home/myUser/mydir /local/dir/\n</code></pre></p> <p>This command downloads the collection <code>/iplant/home/myUser/mydir</code> and its contents to <code>/local/dir/</code> using 10 parallel transfer threads. Utilizing more transfer threads can maximize I/O and network bandwidth, often speeding up the transfer process significantly.</p> <ul> <li>The <code>-N</code> flag sets the maximum number of threads to use for the transfer.</li> </ul> <p>Thread Count Considerations</p> <ol> <li>Higher thread counts require more CPU and memory. Excessive threads may overload your system, causing performance issues. For example, Discovery Environment (DE) apps limit transfer threads to 4 due to RAM constraints.</li> <li>The Data Store limits concurrent connections, potentially restricting high thread counts.</li> </ol> </li> </ol>"},{"location":"ds/icommands/data_transfer/#upload-data-to-the-data-store","title":"Upload Data to the Data Store","text":"<ol> <li> <p>Upload a local directory to a specific path in the Data Store: <pre><code>iput -P -f -K -T /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> and its contents to the Data Store at <code>/iplant/home/myUser/mydir/</code>. A new directory named <code>dir</code> will be created under <code>/iplant/home/myUser/mydir/</code>, resulting in <code>/iplant/home/myUser/mydir/dir</code> containing all the uploaded files and subdirectories.</p> <ul> <li>The <code>-P</code> flag outputs upload progress.</li> <li>The <code>-f</code> flag forces overwriting of existing files in the Data Store without confirmation.</li> <li>The <code>-K</code> flag ensures file integrity by verifying checksums after upload.</li> <li>The <code>-T</code> flag renews connections every 10 minutes to prevent failures due to connection or firewall issues.</li> </ul> </li> <li> <p>Sync a local directory with a collection in the Data Store: <pre><code>irsync -r -K /local/dir/ i:/iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> to <code>/iplant/home/myUser/mydir/</code> in the Data Store, syncing any new or updated files.</p> </li> <li> <p>Upload a local directory using multiple parallel transfers: <pre><code>iput -P -f -K -T -N 10 /local/dir/ /iplant/home/myUser/mydir/\n</code></pre></p> <p>This command uploads the local directory <code>/local/dir/</code> and its contents to <code>/iplant/home/myUser/mydir/</code> in the Data Store using 10 parallel transfer threads. This can significantly speed up the upload process by maximizing I/O and network bandwidth.</p> <ul> <li>The <code>-N</code> flag sets the maximum number of threads to use for the transfer.</li> </ul> <p>Thread Count Considerations</p> <ol> <li>Higher thread counts require more CPU and memory. Excessive threads may overload your system, causing performance issues. For example, Discovery Environment (DE) apps limit transfer threads to 4 due to RAM constraints.</li> <li>The Data Store limits concurrent connections, potentially restricting high thread counts.</li> </ol> </li> </ol>"},{"location":"ds/icommands/installation/","title":"iCommands Installation and Upgrade","text":""},{"location":"ds/icommands/installation/#installing-icommands-using-linux-package-managers","title":"Installing iCommands Using Linux Package Managers","text":"<p>iCommands can be installed using popular Linux package managers such as <code>apt</code>, <code>yum</code>, or <code>zypper</code>. Follow the instructions below to install the latest version of iCommands based on your system's package manager.</p> <p>Note: You need administrative privileges to install the iCommands package on the system.</p>"},{"location":"ds/icommands/installation/#apt-debianubuntu","title":"APT (Debian/Ubuntu)","text":"<p>APT is the default package manager for Debian-based distributions like Ubuntu. Use the following commands to add the iRODS repository, import the signing key, and update your package list:</p> <pre><code>wget -qO - https://packages.irods.org/irods-signing-key.asc | sudo apt-key add -\necho \"deb [arch=amd64] https://packages.irods.org/apt/ $(lsb_release -sc) main\" | sudo tee /etc/apt/sources.list.d/renci-irods.list\nsudo apt-get update\n</code></pre> <p>Then use the following command to install iCommands:</p> <pre><code>sudo apt install irods-icommands\n</code></pre>"},{"location":"ds/icommands/installation/#yum-rhelcentosfedora","title":"YUM (RHEL/CentOS/Fedora)","text":"<p>YUM is the default package manager for Red Hat-based distributions such as RHEL, CentOS, and Fedora. To install the public signing key and add the iRODS repository, execute the following commands:</p> <pre><code>sudo rpm --import https://packages.irods.org/irods-signing-key.asc\nwget -qO - https://packages.irods.org/renci-irods.yum.repo | sudo tee /etc/yum.repos.d/renci-irods.yum.repo\n</code></pre> <p>Then use the following command to install iCommands:</p> <pre><code>sudo yum install irods-icommands\n</code></pre>"},{"location":"ds/icommands/installation/#zypper-opensusesuse-linux-enterprise","title":"ZYPPER (openSUSE/SUSE Linux Enterprise)","text":"<p>ZYPPER is the package manager for SUSE-based distributions like openSUSE and SUSE Linux Enterprise. Use these commands to import the signing key and add the iRODS repository:</p> <pre><code>sudo rpm --import https://packages.irods.org/irods-signing-key.asc\nwget -qO - https://packages.irods.org/renci-irods.zypp.repo | sudo tee /etc/zypp/repos.d/renci-irods.zypp.repo\n</code></pre> <p>Then use the following command to install iCommands:</p> <pre><code>sudo zypper install irods-icommands\n</code></pre>"},{"location":"ds/icommands/installation/#manual-installation-or-specific-versions","title":"Manual Installation or Specific Versions","text":"<p>If you prefer to manually download binaries or require a specific version of iCommands, visit the official iRODS download page for more information:</p> <p>iRODS Download Page</p> <p>Alternatively, you can directly browse the repositories for specific versions:</p> <ul> <li>APT Repository: https://packages.irods.org/apt/pool/</li> <li>YUM/ZYPPER Repository: https://packages.irods.org/yum/pool</li> </ul>"},{"location":"ds/icommands/issue_report/","title":"iCommands Troubleshooting and Issue Report","text":""},{"location":"ds/icommands/issue_report/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ds/icommands/issue_report/#installing-icommands-on-windows-and-macos","title":"Installing iCommands on Windows and macOS","text":"<p>iCommands has limited support for Windows and macOS. While there are options available, such as using Windows Subsystem for Linux (WSL) or custom iCommands packages for macOS, we highly recommend using GoCommands as a more versatile alternative.</p> <p>GoCommands is a cross-platform tool that offers similar functionality to iCommands with several advantages:</p> <ul> <li>Cross-platform compatibility: Works seamlessly on Windows, macOS, and Linux</li> <li>No installation required: Simply download and run the executable</li> <li>User-friendly commands: Provides essential data access functions</li> </ul> <p>For detailed instructions on downloading, setting up, and using GoCommands, please refer to the GoCommands documentation.</p>"},{"location":"ds/icommands/issue_report/#running-icommands-in-an-hpc-environment","title":"Running iCommands in an HPC Environment","text":"<p>To use pre-installed iCommands in an HPC environment:</p> <pre><code>module load irods\n</code></pre> <p>This command provides access to iRODS iCommands.</p>"},{"location":"ds/icommands/issue_report/#request-support","title":"Request Support","text":"<p>If you encounter an issue that you cannot resolve, please contact support@cyverse.org for assistance. Your Data Store access via iCommands may be limited or fail due to various factors, including configuration issues, network problems, authentication errors, or data policies. The support team is available to help you identify and resolve these issues.</p>"},{"location":"ds/icommands/issue_report/#report-bugs","title":"Report Bugs","text":"<p>Encountered a bug in iCommands? We encourage you to report it on the iCommands GitHub issues page.  Your detailed bug reports are invaluable for improving the stability and usability of iCommands for the entire iRODS community. When submitting, please provide as much information as possible to help with diagnosis and resolution.</p>"},{"location":"ds/icommands/metadata_management/","title":"Metadata Management using iCommands","text":"<p>GoCommands provides features to manage metadata for data objects, collections, resources, and users in the Data Store using the <code>imeta</code> command.</p> <p>Metadata consists of three components:</p> <ul> <li>Name (Attribute): The name of information.</li> <li>Value: The actual data or information.</li> <li>Unit (Optional): Specifies the unit of measurement, if applicable.</li> </ul>"},{"location":"ds/icommands/metadata_management/#list-metadata-of-data-objects-collections-resources-or-users","title":"List Metadata of Data Objects, Collections, Resources, or Users","text":"<pre><code>imeta ls [flags] &lt;irods-object&gt;...\n</code></pre>"},{"location":"ds/icommands/metadata_management/#irods-objects","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> <code>-d</code> List metadata of data objects <code>collection</code> <code>-C</code> List metadata of collections <code>resource</code> <code>-R</code> List metadata of resources <code>user</code> <code>-u</code> List metadata of users"},{"location":"ds/icommands/metadata_management/#example-usage","title":"Example Usage","text":"<ol> <li> <p>List metadata of a data object: <pre><code>imeta ls -d /iplant/home/myUser/file.txt\n</code></pre></p> </li> <li> <p>List metadata of a collection: <pre><code>imeta ls -C /iplant/home/myUser/dir\n</code></pre></p> </li> <li> <p>List metadata of a resource: <pre><code>imeta ls -R myResc\n</code></pre></p> </li> <li> <p>List metadata of a user: <pre><code>imeta ls -u myUser\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/metadata_management/#add-metadata-to-data-objects-collections-resources-or-users","title":"Add Metadata to Data Objects, Collections, Resources, or Users","text":"<pre><code>imeta add [flags] &lt;irods-object&gt; &lt;metadata-name&gt; &lt;metadata-value&gt; [metadata-unit]\n</code></pre>"},{"location":"ds/icommands/metadata_management/#irods-objects_1","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> <code>-d</code> List metadata of data objects <code>collection</code> <code>-C</code> List metadata of collections <code>resource</code> <code>-R</code> List metadata of resources <code>user</code> <code>-u</code> List metadata of users"},{"location":"ds/icommands/metadata_management/#example-usage_1","title":"Example Usage","text":"<ol> <li> <p>Add metadata to a data object: <pre><code>imeta add -d /iplant/home/myUser/file.txt meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a data object with metadata-unit: <pre><code>imeta add -d /iplant/home/myUser/file.txt meta_name meta_value meta_unit\n</code></pre></p> </li> <li> <p>Add metadata to a collection: <pre><code>imeta add -C /iplant/home/myUser/dir meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a resource: <pre><code>imeta add -R myResc meta_name meta_value\n</code></pre></p> </li> <li> <p>Add metadata to a user: <pre><code>imeta add -u myUser meta_name meta_value\n</code></pre></p> </li> </ol>"},{"location":"ds/icommands/metadata_management/#remove-metadata-from-data-objects-collections-resources-or-users","title":"Remove Metadata from Data Objects, Collections, Resources, or Users","text":"<p>Remove metadata by name (attribute) and value:</p> <pre><code>imeta rm [flags] &lt;irods-object&gt; &lt;metadata-name&gt; &lt;metadata-value&gt;\n</code></pre> <p>Remove metadata by ID:</p> <pre><code>imeta rmi [flags] &lt;irods-object&gt; &lt;metadata-ID&gt;\n</code></pre> <p>Note: The <code>metadata-ID</code> is a numeric identifier for the metadata. It can be obtained from the output of the <code>imeta ls</code> command.</p>"},{"location":"ds/icommands/metadata_management/#irods-objects_2","title":"iRODS Objects","text":"iROD Object Flag Description <code>data object</code> <code>-d</code> List metadata of data objects <code>collection</code> <code>-C</code> List metadata of collections <code>resource</code> <code>-R</code> List metadata of resources <code>user</code> <code>-u</code> List metadata of users"},{"location":"ds/icommands/metadata_management/#example-usage_2","title":"Example Usage","text":"<ol> <li> <p>Remove metadata from a data object by name: <pre><code>imeta rm -d /iplant/home/myUser/file.txt meta_name meta_value\n</code></pre></p> </li> <li> <p>Remove metadata from a data object by ID: <pre><code>imeta rmi -d /iplant/home/myUser/file.txt 979206950\n</code></pre></p> </li> <li> <p>Remove metadata from a collection: <pre><code>imeta rm -C /iplant/home/myUser/dir meta_name meta_value\n</code></pre></p> </li> <li> <p>Remove metadata from a resource: <pre><code>imeta rm -R myResc meta_name meta_value\n</code></pre></p> </li> <li> <p>Remove metadata from a user: <pre><code>imeta rm -u myUser meta_name meta_value\n</code></pre></p> </li> </ol>"},{"location":"ds/old/quick-data-share/","title":"Sharing Data in the Discovery Environment","text":"<p> This quickstart is focused on using the Discovery Environment to upload your data. For more information on alternative methods for data management, please refer to the Manage Your Data section or the Data Sharing page.</p> <ol> <li> <p>Log into the  Discovery Environment.</p> </li> <li> <p>Open the  Data icon on the left.</p> </li> </ol> <p></p> <p>3. Click the Upload button on the top right; in the dropdown menu that appears, select the preferred upload method (Browse Local or Import from URL). Additionally, you can also view your upload queue.</p> <p></p> <p>4. Once your file(s) is uploaded, click on the ellipses (3 dots) on the right of the file. This will open a dropdown menu with a number of options; Choose Share.</p> <p></p> <p>5. In the Share window, choose which CyVerse collaborator to share with. If your collaborator is not a registered CyVerse user, choose anonymous.</p> <p></p> <p>6. You can also generate a public URL for files, making it easier to share your files. To do so, click on the ellipses (3 dots) on the right of the file, and click Public Link(s). A window will appear with the generated URL,  which collaborators can use to download your file.</p> <p>Generating a public URL works for files, not folders! It is suggested to compress large numbers of files prior to sharing them.</p> <p></p>"},{"location":"ds/old/share/","title":"Sharing Data","text":"<p>One of the most powerful features of the Data Store is the ability to share all of your data instantly with fine-grained permission control. You can share your data with other CyVerse users, and you can also make data available to anonymous users and with identifiers (i.e., a DOI) through the CyVerse Data Commons. This guide covers the most basic, commonly used sharing features of the Discovery Environment and Data Store.</p>"},{"location":"ds/old/share/#share-a-file-in-the-discovery-environment-with-a-url-public-link","title":"Share a File in the Discovery Environment with a URL (Public Link)","text":"<p>You can quickly share files in your Data Store using a Discovery Environment Public Link.</p> <p>Note</p> <p>You can only share individual files using the public link. Since files are shared over HTTP, this is only recommended for small files. This is a convenient but less secure method for file transfer. Do not share sensitive/private data using these public links.</p> <p>Tip</p> <p>You can use this method to view files, for example in a genome browser.</p> <ol> <li> <p>If necessary, login to the Discovery Environment.</p> </li> <li> <p>In the Data window, select ( checkbox) one or more individual file(s)     (not folders) you wish to share.</p> </li> <li> <p>From the More actions menu, select Public Link(s).</p> </li> <li> <p>A new URL will be provided for you in a pop-up. Highlight and copy     or click on Copy in order to get a window that will     allow you to copy the URL to your clipboard. Anyone you share     this link with will be able to download the file. You can test the     link in a new web browser window.</p> <p></p> <p>Tip</p> <p>You can quickly create a link to a file by clicking the \"3 dots\" (ellipsis) icon next to any file and selecting \"Public Link\".</p> </li> </ol> <p>To deactivate a public link:</p> <ol> <li>To deactivate a link, select ( checkbox) one or more individual file(s)     that have been shared with a public link; then click on the Details     menu.</li> <li>In the Details menu under the Permissions tab, click the     \"pencil\" icon next to \"cyverse-anonymous@cyverse.org\" to edit     the file's permissions.</li> </ol>"},{"location":"ds/old/share/#share-a-filefolder-in-the-discovery-environment-with-another-cyverse-user-or-group","title":"Share a File/Folder in the Discovery Environment with Another CyVerse User or Group","text":"<p>You can share data with another CyVerse user or a group of users by granting the user name or group name permission to <code>read</code>, <code>write</code>, or <code>own</code> your files/folders.</p> <ol> <li> <p>If necessary, login to the Discovery Environment.</p> </li> <li> <p>In the Data window, select ( checkbox) file(s) or folder(s) you wish to     share with another user; then under the Share menu, enter the     CyVerse username, email, or group name you wish to share with.</p> </li> <li> <p>Next, under 'Permissions' choose which permission to grant to     the recipient(s) you are sharing this file or folder with.</p> <p></p> </li> <li> <p>Once you are finished, click Done to begin sharing. The user will be     notified that a file has been shared with them.</p> <p>Tip</p> <p>You can share several files/folders at once by selecting them and then clicking the \"Add to Bag\" button in the Data window and then sharing the bag.</p> <p>Hint</p> <p>By managing access to data, the DE allows you to share large datasets instantaneously. Data permissions (based on UNIX permissions) are described in this chart:</p> Permission level Read Download/Save Metadata Rename Move Delete Read X X View Write X X Add/Edit Own X X Add/Edit X X X </li> </ol>"},{"location":"ds/old/share/#sharing-a-filefolder-with-the-public","title":"Sharing a File/Folder with the Public","text":"<ul> <li> <p>You can share your data with the public CyVerse community by adding the <code>public</code> user to the shared folder as read only.</p> </li> <li> <p>You can share your data with the open internet by adding the <code>anonymous</code> user to the shared folder as read only.</p> </li> </ul> <p>Never share files or folders as 'write' or 'own' permission with the <code>anonymous</code> or <code>public</code> user</p> <p>Files that are shared publicly should only ever have <code>read</code> access.</p> <ol> <li> <p>If necessary, login to the Discovery Environment.</p> </li> <li> <p>In the Data window, select ( checkbox) file(s) or folder(s) you wish to share with another user; then under the Share menu, enter the name <code>public</code> or <code>anonymous</code></p> </li> <li> <p>Next, under 'Permissions' choose <code>read</code></p> <p></p> </li> <li> <p>Go to https://data.cyverse.org/</p> </li> </ol> <p>The WebDav has two services <code>/dav</code> and <code>/dav-anon</code></p> <ul> <li> <p> https://data.cyverse.org/dav/ requires you to authenticate with your CyVerse username and password, once you have authenticated, you have access to all your data, and all data that are shared with your username, including all data that have been shared with the <code>public</code> user in both individual user accounts and in Community Released Data folders. </p> <p></p> </li> <li> <p> The https://data.cyverse.org/dav-anon/  directories that have been shared with the <code>anonymous</code> user. This endpoint does not require authentication or an account with CyVerse to access.</p> <p></p> </li> </ul>"},{"location":"ds/sftp/","title":"Manage Your Data Using SFTP","text":"<p>SFTP (Secure File Transfer Protocol) is a widely adopted network protocol for secure file transfer and management. It operates over an encrypted communication channel, ensuring safe data exchange between the client and server. With broad compatibility across various environments, SFTP offers a flexible and reliable solution for managing data.  </p> <p>This guide covers how to configure SFTP clients to efficiently manage your data in the Data Store.</p>"},{"location":"ds/sftp/#limitations","title":"Limitations","text":"<p>Using SFTP for File Transfers</p> <p>WebDAV is ideal for transferring small files or small collections of files. While there is no strict size limit, it is not recommended for files larger than 10 GiB due to performance issues.</p> <p>Alternatives for Large Files</p> <p>For large files or extensive datasets, consider using GoCommands or iCommands instead. These tools offer better performance and efficiency for handling large data transfers.</p> <p>For more details on GoCommands and iCommands, visit their respective documentation pages: - GoCommands - iCommands</p>"},{"location":"ds/sftp/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Command-line Tools</li> <li>FileZilla</li> <li>Cyberduck</li> <li>Directory Structure</li> <li>Public-key Authentication Configuration</li> </ol>"},{"location":"ds/sftp/#command-line-tools","title":"Command-line Tools","text":"<p>Use your operating system's built-in SFTP client to access and manage data in the Data Store via the command line.</p>"},{"location":"ds/sftp/#filezilla","title":"FileZilla","text":"<p>Connect to the Data Store using FileZilla, a user-friendly SFTP GUI client for easy file transfers and management.</p>"},{"location":"ds/sftp/#cyberduck","title":"Cyberduck","text":"<p>Connect to the Data Store using Cyberduck, a user-friendly SFTP GUI client for easy file transfers and management.</p>"},{"location":"ds/sftp/#directory-structure","title":"Directory Structure","text":"<p>Learn how to navigate your files using SFTP by understanding its directory structure.</p>"},{"location":"ds/sftp/#public-key-authentication-configuration","title":"Public-key Authentication Configuration","text":"<p>Set up and configure public-key authentication for secure SFTP access to the Data Store.</p>"},{"location":"ds/sftp/#acknowledgments","title":"Acknowledgments","text":"<p>The SFTP functionality for the Data Store is powered by SFTPGo, an open-source, fully featured, and highly configurable SFTP server created by Nicola Murino. SFTPGo supports various storage backends, including local filesystems, S3 Object Storage, Google Cloud Storage, and Azure Blob Storage. CyVerse extended SFTPGo's capabilities by implementing a new backend module specifically for iRODS, enabling SFTP access to the Data Store. We extend our gratitude to Nicola Murino and the SFTPGo project for making this integration possible.</p>"},{"location":"ds/sftp/cli/","title":"SFTP Access using Command-line Tools","text":"<p>Most operating systems include built-in SFTP clients, enabling command-line access to the Data Store. This guide outlines the basics of using SFTP tools on Linux, macOS, and Windows.</p> <p>Windows Users</p> <p>Windows 10 and later versions include an SFTP client. For earlier versions, you may need to use a third-party command-line tool like <code>WinSCP</code> or a GUI tool like <code>FileZilla</code>.</p>"},{"location":"ds/sftp/cli/#sftp-access-information","title":"SFTP Access Information","text":"<p>Use the following credentials to connect to the Data Store:</p> Key Value <code>hostname</code> <code>data.cyverse.org</code> <code>port</code> <code>22</code> <code>username</code> <code>&lt;CyVerse Username&gt;</code> <code>password</code> <code>&lt;CyVerse Password&gt;</code> <p>Use these credentials for anonymous access to the Data Store:</p> Key Value <code>username</code> <code>anonymous</code> <code>password</code> (leave empty)"},{"location":"ds/sftp/cli/#connect-to-the-data-store","title":"Connect to the Data Store","text":"<p>To connect using SFTP, open a terminal and run:</p> <pre><code>sftp &lt;username&gt;@data.cyverse.org\n</code></pre> <p>Upon successful connection, you'll see a prompt like this:</p> <pre><code>$ sftp &lt;username&gt;@data.cyverse.org\nConnected to data.cyverse.org.\nsftp&gt;\n</code></pre> <p>Note: Output may vary depending on the operating system. The example above is from Linux.</p>"},{"location":"ds/sftp/cli/#basic-sftp-commands","title":"Basic SFTP Commands","text":"<p>Once connected, you can use these common SFTP commands:</p> <ul> <li><code>ls</code>: List files and directories</li> <li><code>cd</code>: Change directory</li> <li><code>pwd</code>: Display current directory</li> <li><code>get</code>: Download a file from the Data Store</li> <li><code>put</code>: Upload a file to the Data Store</li> <li><code>mkdir</code>: Create a directory</li> <li><code>rmdir</code>: Remove an empty directory</li> <li><code>rm</code>: Delete a file</li> </ul> <p>To close the SFTP connection, use the <code>exit</code> or <code>bye</code> command.</p> <p>Use the <code>help</code> or <code>?</code> command to see a list of available SFTP commands.</p>"},{"location":"ds/sftp/cli/#top-level-directories","title":"Top-level Directories","text":"<p>Once connected, you will see two directories in the root:</p> <ul> <li><code>&lt;username&gt;</code>: Your home directory (<code>/iplant/home/&lt;username&gt;</code> in the Data Store). You have read and write permissions. Note that anonymous users do not have a home directory.</li> <li><code>shared</code>: Community-shared data directory (<code>/iplant/home/shared</code> in the Data Store). You have only read permission.</li> </ul> <p>Note: A <code>.ssh</code> directory may appear in the root, but it is not writable. This directory is distinct from the <code>/&lt;username&gt;/.ssh</code> directory and should be ignored.</p>"},{"location":"ds/sftp/cli/#examples","title":"Examples","text":"<ol> <li> <p>List files in your home directory: <pre><code>ls /myUser\n</code></pre></p> </li> <li> <p>Download a file: <pre><code>get /myUser/myfile.txt\n</code></pre></p> </li> <li> <p>Upload a file: <pre><code>put localfile.txt /myUser/\n</code></pre></p> </li> <li> <p>Create a new directory: <pre><code>mkdir /myUser/newdir\n</code></pre></p> </li> </ol>"},{"location":"ds/sftp/cyberduck/","title":"SFTP Access using Cyberduck","text":"<p>Cyberduck is a free, open-source GUI FTP client available for both Windows and macOS. It supports various protocols such as FTP, SFTP, and WebDAV, allowing you to access the Data Store and other cloud storage services like Amazon S3, Google Drive, and Dropbox.</p> <p>This guide demonstrates how to use Cyberduck for SFTP access to the Data Store.</p>"},{"location":"ds/sftp/cyberduck/#installation","title":"Installation","text":"<p>To install Cyberduck, follow these steps:</p> <ol> <li> <p>Download Cyberduck:     Visit the Cyberduck website and download the appropriate version for your operating system (Windows or macOS).</p> </li> <li> <p>Install Cyberduck:</p> <ul> <li>Windows: Double-click the downloaded <code>.exe</code> file and follow the installation wizard.</li> <li>macOS: Double-click the downloaded <code>.zip</code> file to extract the contents. Open the extracted folder and find the <code>Cyberduck.app</code> icon. Drag and drop this icon into your Applications folder.</li> </ul> </li> <li> <p>Launch Cyberduck:     After installation, launch the Cyberduck to start using it.</p> </li> </ol>"},{"location":"ds/sftp/cyberduck/#connect-to-the-data-store","title":"Connect to the Data Store","text":"<p>In the Cyberduck window, click Open Connection button to create a new profile.</p> <p></p> <p>In the popup window, fill in the following fields:</p> <ul> <li>Protocol: <code>SFTP (SSH File Transfer Protocol)</code></li> <li>Server: <code>data.cyverse.org</code></li> <li>Port: <code>22</code></li> <li>Username: <code>&lt;CyVerse username&gt;</code></li> <li>Password: <code>&lt;CyVerse password&gt;</code></li> </ul> <p>Use these credentials for anonymous access to the Data Store:</p> <ul> <li>Username: <code>anonymous</code></li> <li>Password: (leave empty)</li> </ul> <p>Click the Connect button to establish the connection.</p>"},{"location":"ds/sftp/cyberduck/#basic-usage","title":"Basic Usage","text":"<p>To navigate:</p> <p></p> <ul> <li>Click on directory names to move into folders</li> <li>Click the top drop-down box and click directory name to move out of folders</li> </ul> <p>To transfer files:</p> <p></p> <ol> <li>Select the desired files or directories</li> <li>Right-click on the selected items and choose <code>Download To...</code> from the context menu</li> </ol> <p>Note: Additionally, you can utilize the drag-and-drop feature to easily upload files and directories from your local system to the Data Store, and vice versa.</p>"},{"location":"ds/sftp/cyberduck/#top-level-directories","title":"Top-level Directories","text":"<p>Once connected, you will see two directories in the root:</p> <ul> <li><code>&lt;username&gt;</code>: Your home directory (<code>/iplant/home/&lt;username&gt;</code> in the Data Store). You have read and write permissions. Note that anonymous users do not have a home directory.</li> <li><code>shared</code>: Community-shared data directory (<code>/iplant/home/shared</code> in the Data Store). You have only read permission.</li> </ul> <p>Note: A <code>.ssh</code> directory may appear in the root, but it is not writable. This directory is distinct from the <code>/&lt;username&gt;/.ssh</code> directory and should be ignored.</p>"},{"location":"ds/sftp/filezilla/","title":"SFTP Access using FileZilla","text":"<p>FileZilla is a free and open-source, cross-platform GUI FTP software, consisting of FileZilla Client and FileZilla Server. The FileZilla Client is available for Windows, Linux, and macOS, allowing you to access the Data Store.</p>"},{"location":"ds/sftp/filezilla/#installation","title":"Installation","text":"<p>To install the FileZilla Client, follow these steps:</p> <ol> <li> <p>Download FileZilla Client:     Visit the FileZilla website and download the client version suitable for your operating system (Windows, Linux, or macOS).</p> </li> <li> <p>Install FileZilla:</p> <ul> <li>Windows: Double-click the downloaded <code>.exe</code> file and follow the installation wizard.</li> <li>macOS: Open the downloaded package and drag the FileZilla application to your Applications folder.</li> <li>Linux: Use your distribution's package manager to install FileZilla. Alternatively, you can compile it from source if necessary.</li> </ul> </li> <li> <p>Launch FileZilla:     After installation, launch the FileZilla Client to start using it.</p> </li> </ol>"},{"location":"ds/sftp/filezilla/#connect-to-the-data-store","title":"Connect to the Data Store","text":"<p>In the FileZilla window, fill in the following fields:</p> <ul> <li>Host: <code>data.cyverse.org</code></li> <li>Username: <code>&lt;CyVerse username&gt;</code></li> <li>Password: <code>&lt;CyVerse password&gt;</code></li> <li>Port: <code>22</code></li> </ul> <p>Use these credentials for anonymous access to the Data Store:</p> <ul> <li>Username: <code>anonymous</code></li> <li>Password: (leave empty)</li> </ul> <p></p> <p>Click the Quickconnect button to establish the connection.</p>"},{"location":"ds/sftp/filezilla/#basic-usage","title":"Basic Usage","text":"<p>The FileZilla interface is divided into two main sections:</p> <ul> <li>Left pannel: Show data on your local machine</li> <li>Right pannel: Display data in the Data Store</li> </ul> <p>To navigate:</p> <ul> <li>Click on directory names to move in and out of folders</li> </ul> <p>To transfer files:</p> <ol> <li>Select the desired files or directories</li> <li>Drag them to the target directory in the opposite panel</li> <li>Drop to initiate the transfer</li> </ol> <p>This drag-and-drop functionality allows for easy file movement between your local system and the Data Store.</p>"},{"location":"ds/sftp/filezilla/#top-level-directories","title":"Top-level Directories","text":"<p>Once connected, you will see two directories in the root:</p> <ul> <li><code>&lt;username&gt;</code>: Your home directory (<code>/iplant/home/&lt;username&gt;</code> in the Data Store). You have read and write permissions. Note that anonymous users do not have a home directory.</li> <li><code>shared</code>: Community-shared data directory (<code>/iplant/home/shared</code> in the Data Store). You have only read permission.</li> </ul> <p>Note: A <code>.ssh</code> directory may appear in the root, but it is not writable. This directory is distinct from the <code>/&lt;username&gt;/.ssh</code> directory and should be ignored.</p>"},{"location":"ds/sftp/public_key_auth/","title":"SFTP Public-key Authentication Configuration","text":"<p>Set up password-less authentication for SFTP access by uploading your SSH public key to the Data Store.</p>"},{"location":"ds/sftp/public_key_auth/#setting-up-public-key-authentication","title":"Setting Up Public-key Authentication","text":"<ol> <li> <p>Generate an SSH key (if needed): <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n</code></pre></p> <p>This creates a private key <code>id_rsa</code> and a public key <code>id_rsa.pub</code> in the <code>~/.ssh</code> directory.</p> </li> <li> <p>Connect to the Data Store via SFTP: <pre><code>sftp myUser@data.cyverse.org\n</code></pre></p> </li> <li> <p>Create the <code>.ssh</code> directory in your Data Store home:     In the SFTP prompt, run:     <pre><code>mkdir /myUser/.ssh\n</code></pre></p> <p>This creates the <code>.ssh</code> directory at <code>/iplant/home/&lt;username&gt;/.ssh</code> in the Data Store.</p> <p>Note: A <code>.ssh</code> directory may appear in the root (<code>/.ssh</code>), but it is not writable. This directory is distinct from the <code>/&lt;username&gt;/.ssh</code> directory and should be ignored.</p> </li> <li> <p>Copy your SSH public key to the Data Store:     Still in the SFTP prompt, copy your local <code>~/.ssh/id_rsa.pub</code> file to the Data Store:     <pre><code>put ~/.ssh/id_rsa.pub /myUser/.ssh/authorized_keys\n</code></pre>     This registers your public key for password-less authentication.</p> </li> <li> <p>Exit and reconnect to verify: <pre><code>quit\nsftp myUser@data.cyverse.org\n</code></pre></p> <p>It should not ask for a password this time.</p> </li> </ol>"},{"location":"ds/sftp/public_key_auth/#advanced-configuration","title":"Advanced Configuration","text":"<p>For advanced usage, you can control public-key access by manually editing the <code>/iplant/home/&lt;username&gt;/.ssh/authorized_keys</code> file in the Data Store. This process involves downloading the file, making changes, and then uploading it back. Here's how to do it:</p> <ol> <li> <p>Download the <code>authorized_keys</code> File:     Connect to the Data Store via SFTP and download the file:     <pre><code>sftp myUser@data.cyverse.org\nget /myUser/.ssh/authorized_keys\nquit\n</code></pre></p> </li> <li> <p>Edit the file locally with a editor:     Open it with a text editor (e.g., <code>vi</code>, <code>nano</code>):     <pre><code>vi authorized_keys\n</code></pre></p> <p>Add parameters in <code>key=value</code> format before each SSH key. Example: <pre><code>expiry-time=\"20250320\" from=\"10.11.12.13\" ssh-rsa AAAAB3Nza... myUser\n</code></pre></p> </li> <li> <p>Upload the modified file back to the Data Store:     Reconnect via SFTP and upload:     <pre><code>sftp myUser@data.cyverse.org\nput authorized_keys /myUser/.ssh/\nquit\n</code></pre></p> <p>Note: Configuration changes are only applied during user authentication. Therefore, modifications do not affect users or clients that are already logged in.</p> </li> </ol>"},{"location":"ds/sftp/public_key_auth/#available-parameters","title":"Available Parameters","text":"Parameter Description Example <code>expiry-time</code> Sets expiration date-time in <code>YYYYMMDD</code>, <code>YYYYMMDDhhmm</code>, or <code>YYYYMMDDhhmmss</code> format <code>expiry-time=\"20250320\"</code> <code>from</code> Allows access from specific IP addresses. Use IP address, CIDR, or <code>!</code> prefix to negate. Separate multiple entries with commas <code>from=\"10.11.12.13,!10.11.12.14\"</code> <code>home</code> Sets a specific home collection path for SFTP access within the Data Store. Use absolute path of the collection in the Data Store <code>home=/iplant/home/myUser/sftp_home</code>"},{"location":"ds/sftp/structure/","title":"SFTP Directory Structure","text":"<p>When accessing the Data Store via SFTP, you'll encounter a different directory structure compared to other tools like GoCommands and iCommands. SFTP users have access to following directories:</p>"},{"location":"ds/sftp/structure/#home-directory","title":"Home Directory","text":"<p><code>/&lt;username&gt;</code></p> <ul> <li>Maps to your iRODS home directory <code>/iplant/home/&lt;username&gt;</code></li> <li>Read and write access for the owner</li> <li>Not provided to anonymous users</li> </ul>"},{"location":"ds/sftp/structure/#community-shared-data-directory","title":"Community-shared Data Directory","text":"<p><code>/shared</code></p> <ul> <li>Maps to the iRODS community-shared data directory: <code>/iplant/home/shared</code></li> <li>Read-only access</li> </ul>"},{"location":"ds/sftp/structure/#ssh-directory","title":"<code>.ssh</code> Directory","text":"<p><code>/.ssh</code></p> <ul> <li>Automatically generated by the SFTP service</li> <li>Not used and should be ignored</li> <li>Distinct from <code>/&lt;username&gt;/.ssh</code></li> </ul> <p>For password-less public-key authentication, use <code>/&lt;username&gt;/.ssh</code> instead.</p>"},{"location":"ds/webdav/","title":"Manage Your Data Using WebDAV","text":"<p>WebDAV (Web Distributed Authoring and Versioning) is a network protocol built on top of HTTP/HTTPS, enabling users to manage data on web servers. It operates over HTTP/HTTPS, ensuring secure data exchange between the client and server, with broad compatibility across various environments. WebDAV provides a flexible and reliable solution for managing data.</p> <p>This guide covers how to use WebDAV to efficiently manage your data in the Data Store.</p>"},{"location":"ds/webdav/#limitations","title":"Limitations","text":"<p>Using WebDAV for File Transfers</p> <p>WebDAV is ideal for transferring small files or small collections of files. While there is no strict size limit, it is not recommended for files larger than 10 GiB due to performance issues.</p> <p>Alternatives for Large Files</p> <p>For large files or extensive datasets, consider using GoCommands or iCommands instead. These tools offer better performance and efficiency for handling large data transfers.</p> <p>For more details on GoCommands and iCommands, visit their respective documentation pages: - GoCommands - iCommands</p>"},{"location":"ds/webdav/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Command-line Tools</li> <li>Web Browsers</li> <li>File Managers</li> <li>Data Locations</li> </ol>"},{"location":"ds/webdav/#command-line-tools","title":"Command-line Tools","text":"<p>Use command-line tools to manage and transfer files directly from your terminal, providing a flexible and efficient way to interact with the Data Store.</p>"},{"location":"ds/webdav/#web-browsers","title":"Web Browsers","text":"<p>Access the Data Store using web browsers for straightforward and convenient file downloads.</p>"},{"location":"ds/webdav/#file-managers","title":"File Managers","text":"<p>Access and manage Data Store files using your operating system's built-in file manager as if they were local.</p>"},{"location":"ds/webdav/#data-locations","title":"Data Locations","text":"<p>Discover how to locate your data with WebDAV.</p>"},{"location":"ds/webdav/browser/","title":"WebDAV Access using Web Browsers","text":"<p>WebDAV, an extension of HTTP, allows browsing and downloading data directly through any web browser.</p>"},{"location":"ds/webdav/browser/#connect-to-the-data-store","title":"Connect to the Data Store","text":"<p>In your web browser, enter the URL of the data location.</p> <p></p> <p>If the data requires authentication, you will be prompted to log in:</p> <ul> <li>Username: <code>&lt;CyVerse username&gt;</code></li> <li>Password: <code>&lt;CyVerse password&gt;</code></li> </ul> <p>For anonymous access:</p> <ul> <li>Username: <code>anonymous</code></li> <li>Password: (leave empty)</li> </ul> <p></p> <p>Web browsers allow you to list directories, view text file contents, and download files. To manage data fully (e.g., upload, move, or delete files), use GoCommands, iCommands, SFTP, or WebDAV Command-line Tools instead.</p>"},{"location":"ds/webdav/browser/#data-locations","title":"Data Locations","text":"<ol> <li> <p>User Data     Users can access their data at:</p> <pre><code>https://data.cyverse.org/dav/iplant/home/&lt;username&gt;/\n</code></pre> </li> <li> <p>Public Data (Read-Only Access)     Anonymous users can access public data at: <pre><code>https://data.cyverse.org/dav-anon/\n</code></pre></p> </li> <li> <p>Community/Project Data     To access project-specific data stored in iRODS at <code>/iplant/home/shared/&lt;project&gt;/</code>, use:     <pre><code>https://data.cyverse.org/dav/iplant/projects/&lt;project&gt;/\n</code></pre></p> </li> <li> <p>CyVerse Curated Data (DOI-Backed Datasets)     Access curated datasets with DOIs in the Data Commons at:     <pre><code>https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/\n</code></pre></p> </li> </ol>"},{"location":"ds/webdav/cli/","title":"WebDAV Access using Command-line Tools","text":"<p>You can access the Data Store via command-line tools using WebDAV, which is especially useful for integrating data into analysis pipelines or scripts. This guide covers using <code>curl</code>, a widely used command-line tool, for efficient WebDAV access and data management.</p>"},{"location":"ds/webdav/cli/#webdav-access-information","title":"WebDAV Access Information","text":"<p>Use the following credentials to connect to the Data Store:</p> Key Value <code>URL</code> <code>https://data.cyverse.org/dav</code> <code>username</code> <code>&lt;CyVerse Username&gt;</code> <code>password</code> <code>&lt;CyVerse Password&gt;</code> <p>Use these credentials for anonymous access to the Data Store:</p> Key Value <code>username</code> <code>anonymous</code> <code>password</code> (leave empty)"},{"location":"ds/webdav/cli/#connect-to-the-data-store","title":"Connect to the Data Store","text":"<p>To list the contents of your home directory in the Data Store using WebDAV, open a terminal and run the following command:</p> <pre><code>curl --user '&lt;username&gt;:&lt;password&gt;' https://data.cyverse.org/dav/iplant/home/&lt;username&gt;\n</code></pre> <ul> <li>Use your CyVerse username and password with <code>--user</code> flag to login</li> <li> <p><code>https://data.cyverse.org/dav</code> is the URL of the WebDAV root. Add Data Store path after for URL</p> </li> <li> <p><code>--user '&lt;username&gt;:&lt;password&gt;'</code>: This option provides your CyVerse username and password for authentication. Replace  and  with your actual credentials. <li><code>https://data.cyverse.org/dav/iplant/home/&lt;username&gt;</code>: This is the URL of your home directory within the Data Store's WebDAV server. <code>https://data.cyverse.org/dav</code> is the root WebDAV URL, and <code>/iplant/home/&lt;username&gt;</code> specifies the path to your home directory in the Data Store.</li> <p>The output will be an HTML-formatted text displaying files and directories in a table layout.</p>"},{"location":"ds/webdav/cli/#data-locations","title":"Data Locations","text":"<ol> <li> <p>User Data     Users can access their data at:</p> <pre><code>https://data.cyverse.org/dav/iplant/home/&lt;username&gt;/\n</code></pre> </li> <li> <p>Public Data (Read-Only Access)     Anonymous users can access public data at: <pre><code>https://data.cyverse.org/dav-anon/\n</code></pre></p> </li> <li> <p>Community/Project Data     To access project-specific data stored in iRODS at <code>/iplant/home/shared/&lt;project&gt;/</code>, use:     <pre><code>https://data.cyverse.org/dav/iplant/projects/&lt;project&gt;/\n</code></pre></p> </li> <li> <p>CyVerse Curated Data (DOI-Backed Datasets)     Access curated datasets with DOIs in the Data Commons at:     <pre><code>https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/\n</code></pre></p> </li> </ol>"},{"location":"ds/webdav/cli/#examples","title":"Examples","text":"<ol> <li> <p>List files in your home directory: <pre><code>curl https://data.cyverse.org/dav/iplant/home/myUser\n</code></pre></p> <p>This prints files and directories in HTML format.</p> </li> <li> <p>Read a file: <pre><code>curl https://data.cyverse.org/dav/iplant/home/myUser/myfile.txt\n</code></pre></p> <p>This displays the content of <code>myfile.txt</code> in the terminal.</p> </li> <li> <p>Download a file: <pre><code>curl -O https://data.cyverse.org/dav/iplant/home/myUser/myfile.txt\n</code></pre></p> <p>This saves <code>myfile.txt</code> to the current directory.</p> <pre><code>curl -o newfile.txt https://data.cyverse.org/dav/iplant/home/myUser/myfile.txt\n</code></pre> <p>This saves <code>myfile.txt</code> as <code>newfile.txt</code> in the current directory.</p> </li> <li> <p>Upload a file: <pre><code>curl -T localfile.txt https://data.cyverse.org/dav/iplant/home/myUser\n</code></pre></p> </li> <li> <p>Creat a new directory: <pre><code>curl -X MKCOL https://data.cyverse.org/dav/iplant/home/myUser/newdir\n</code></pre></p> </li> <li> <p>Renaming a File:     <pre><code>curl -X MOVE --header \"Destination: https://data.cyverse.org/dav/iplant/home/myUser/new_name.txt\" https://data.cyverse.org/dav/iplant/home/myUser/old_name.txt\n</code></pre></p> <p>This renames <code>old_name.txt</code> to <code>new_name.txt</code>.</p> </li> <li> <p>Deleting Files/Folders:     <pre><code>curl -X DELETE https://data.cyverse.org/dav/iplant/home/myUser/file_to_delete.txt\n</code></pre></p> </li> </ol>"},{"location":"ds/webdav/data_location/","title":"WebDAV Data Locations","text":"<p>When accessing the Data Store via WebDAV, use the following base URLs to locate your data.</p>"},{"location":"ds/webdav/data_location/#user-data","title":"User Data","text":"<p><code>https://data.cyverse.org/dav/iplant/home/&lt;username&gt;</code></p> <ul> <li>Maps to your iRODS home directory <code>/iplant/home/&lt;username&gt;</code></li> <li>Read and write access for the owner</li> <li>Not accessible to anonymous users</li> </ul>"},{"location":"ds/webdav/data_location/#public-data-read-only","title":"Public Data (Read-Only)","text":"<p><code>https://data.cyverse.org/dav-anon</code></p> <ul> <li>Read-only access</li> <li>Available to anonymous users</li> </ul>"},{"location":"ds/webdav/data_location/#communityproject-data","title":"Community/Project Data","text":"<p><code>https://data.cyverse.org/dav/iplant/projects/&lt;project&gt;</code></p> <ul> <li>Maps to the iRODS community-shared data directory: <code>/iplant/home/shared/&lt;project&gt;</code></li> </ul>"},{"location":"ds/webdav/data_location/#cyverse-curated-data-doi-backed-datasets","title":"CyVerse Curated Data (DOI-Backed Datasets)","text":"<p><code>https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated</code></p> <ul> <li>Maps to the iRODS CyVerse curated data directory: <code>/iplant/home/shared/commons_repo/curated</code></li> <li>Read-only access</li> </ul>"},{"location":"ds/webdav/file_manager/","title":"WebDAV Access using File Managers","text":"<p>Most operating systems include a file manager that supports WebDAV, allowing you to mount a WebDAV directory as part of the filesystem. This enables other applications on the same computer to access data in the Data Store as if it were local.</p>"},{"location":"ds/webdav/file_manager/#macos-finder","title":"macOS Finder","text":"<p>Follow these steps to connect using macOS Finder:</p> <ol> <li>Open Finder.  </li> <li>In the menu bar, click Go \u2192 Connect to Server (Command + K).  </li> <li>Enter the WebDAV URL for the folder you want to access.  </li> <li>If prompted, enter your CyVerse username and password.  </li> </ol>"},{"location":"ds/webdav/file_manager/#windows-file-exploer","title":"Windows File Exploer","text":"<p>To connect using Windows File Explorer:  </p> <ol> <li>Open File Explorer.  </li> <li>Right-click This PC and select Map Network Drive.  </li> <li>Click Choose a custom network location, then Next.  </li> <li>Enter the WebDAV URL for the folder you want to access.  </li> <li>If prompted, enter your CyVerse username and password.  </li> </ol>"},{"location":"ds/webdav/file_manager/#gnome-files","title":"Gnome Files","text":"<p>To connect using GNOME Files on Linux:  </p> <ol> <li>Open Files.  </li> <li>In the sidebar, click Other Locations.  </li> <li>Under Connect to Server, enter the WebDAV URL for the folder you want to access. Note: TLS-encrypted WebDAV URLs use <code>davs://</code> instead of <code>https://</code>, so CyVerse URLs should be formatted as: <pre><code>davs://data.cyverse.org/dav/iplant/home/&lt;username&gt;\n</code></pre></li> <li>Click Connect.  </li> <li>If prompted, enter your CyVerse username and password.  </li> </ol>"},{"location":"ds/webdav/file_manager/#linux-terminal","title":"Linux Terminal","text":"<p>To mount a WebDAV folder via the Linux terminal, root or sudo access is required:</p> <ol> <li>Install <code>davfs2</code> (e.g., on Ubuntu: <code>sudo apt install davfs2</code>).</li> <li>Create a mount point:     <pre><code>mkdir /tmp/data\n</code></pre></li> <li>Mount the WebDAV directory:     <pre><code>sudo mount -o gid=&lt;your_user&gt;,uid=&lt;your_user&gt; -t davfs &lt;webdav_url&gt; /tmp/data\n</code></pre><ul> <li>Replace <code>&lt;your_user&gt;</code> with your Linux username.</li> <li>Replace <code>&lt;webdav_url&gt;</code> with the WebDAV folder URL.  </li> </ul> </li> <li>If prompted, enter your CyVerse username and password.  </li> </ol>"},{"location":"ds/webdav/file_manager/#webdav-access-information","title":"WebDAV Access Information","text":"<p>Use the following credentials to connect to the Data Store:</p> Key Value <code>username</code> <code>&lt;CyVerse Username&gt;</code> <code>password</code> <code>&lt;CyVerse Password&gt;</code> <p>Use these credentials for anonymous access to the Data Store:</p> Key Value <code>username</code> <code>anonymous</code> <code>password</code> (leave empty)"},{"location":"ds/webdav/file_manager/#data-locations","title":"Data Locations","text":"<ol> <li> <p>User Data     Users can access their data at:</p> <pre><code>https://data.cyverse.org/dav/iplant/home/&lt;username&gt;/\n</code></pre> </li> <li> <p>Public Data (Read-Only Access)     Anonymous users can access public data at: <pre><code>https://data.cyverse.org/dav-anon/\n</code></pre></p> </li> <li> <p>Community/Project Data     To access project-specific data stored in iRODS at <code>/iplant/home/shared/&lt;project&gt;/</code>, use:     <pre><code>https://data.cyverse.org/dav/iplant/projects/&lt;project&gt;/\n</code></pre></p> </li> <li> <p>CyVerse Curated Data (DOI-Backed Datasets)     Access curated datasets with DOIs in the Data Commons at:     <pre><code>https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/\n</code></pre></p> </li> </ol>"},{"location":"edu/","title":"Teach using CyVerse","text":"<p>The User Portal provides a mechanism for onboarding entire workshops or class courses, by granting your students immediate access to CyVerse platforms and services.</p>"},{"location":"edu/#for-instructors","title":"For Instructors","text":""},{"location":"edu/#step-1-request-a-workshop","title":"Step 1 Request a Workshop","text":"<p>Instructors start by completing the CyVerse Resources for Training Request Form. </p> <p>Avoid conflicts with Maintenance days!</p> <p>When scheduling your workshop or class, note that CyVerse conducts regular maintenance of its platforms typically on the first Tuesday of the month, with most services unavailabe during that time. </p>"},{"location":"edu/#step-2-select-your-services","title":"Step 2 Select your services","text":"<p>In the workshop form, choose which services you want to use for your teaching. Enrollees will then have access to those services without needing to request them.</p> <p>Common platforms are: Data Store (data management), Discovery Environment (analyses), VICE (integrated environments and visualization), and Jetstream2(cloud computing).</p>"},{"location":"edu/#step-3-select-your-host-instructors-organizers","title":"Step 3 Select your Host, Instructor(s) / Organizer(s)","text":"<p>You can make other CyVerse users Instructors or Organizers of your workshop; these users will have administrative rights to modify the workshop template and to add and approve student/attendee accounts.</p>"},{"location":"edu/#step-4-enroll-your-participants","title":"Step 4 Enroll your participants","text":"<p>In the workshop builder, you can enroll existing CyVerse users by using their first/lastname or email address or username. </p> <p>You can pre-enroll new email addresses as well. We recommend using .edu, .gov, or .org email addresses. </p> <p>Students can also use the URL for the workshop/class to enroll themselves. Anyone who self-enrolls subsequently must be approved by the Workshop/Class Admin or Instructor.</p>"},{"location":"edu/#step-5-create-documentation","title":"Step 5 Create documentation","text":"<p>The CyVerse Learning Center provides templates for creating documentation for your class, e.g., Quick Starts, Guides, Tutorials, and Manuals on its GitHub Organization.</p>"},{"location":"edu/#for-students","title":"For Students","text":"<p>In order to view the User Portal Workshops page the students must first create their own CyVerse account.</p> <p>Set Up an Account</p> <p>Students MUST use their institutional email addresses</p> <p>Students must use their official email addresses (.edu, .org, .gov) so that their identities can be verified by CyVerse staff.</p> <p><code>@gmail.com</code>, <code>@yahoo.com</code>, etc., email accounts will not be approved for access to the Discovery Environment Interactive Apps.</p> <p>For graduate students or professionals, additional verification can be accomplished by creating and importing an ORCID</p>"},{"location":"edu/tutorials/","title":"Science Tutorials with CyVerse","text":""},{"location":"edu/tutorials/#bioinformatics-tutorials-using-cyverse","title":"Bioinformatics Tutorials Using CyVerse","text":"Tutorial Date Notes Plant Bioinformatics Vol 3 RNA-Seq Tutorial Oct 21, 2022 An end-to-end RNA-seq analysis using the Kallisto and Sleuth, emphasizing reproducibility features of the CyVerse platforms RNASeq using VICE Dec 06, 2019 Perform RNAseq differential expression analysis using Read Mapping and Transcript Assembly (RMTA) and Rstudio-DESEq2 apps Assemble a Genome Using SOAPdenovo Dec 19, 2019 Commonly used procedure for de novo whole genome assembly of Illumina reads using the DE: Assemble reads, Assess assembly Cluster Orthologs and Paralogs and Assemble Custom Gene Sets Dec 11, 2019 Input entire protein-encoding gene or transcript repertoires from genomes of interest, and cluster homologs (orthologs and paralogs), then query clusters to assemble gene sets based on presence/absence and copy number. RNA-Seq with Kallisto and Sleuth Nov 04, 2019 Kallisto is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Sleuth is designed to analyze and visualize the Kallisto results in R. Kallisto-0.42.3-INDEX-QUANT-PE Oct 25, 2019 Kallisto is a program for quantifying abundances of transcripts from RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets, without the need for alignment. Genome Annotation with MAKER Oct 09, 2019 This tutorial is a step-by-step guide for using SciApps to perform MAKER based annotation Evaluate and Pre-Process Sequencing Reads Jan 05, 2018 Clean and filter Illumina reads using DE apps. Taxonomic Name Resolution Service (TNRS) Dec 05, 2017 Become familiar with TNRS to identify, correct, and update scientific names of plants. Submit High-throughput Sequencing Reads to NCBI Sequence Read Archive (SRA) Dec 04, 2017 The SRA is a canonical repository for sequencing data generated by high-throughput instruments. The CyVerse submission pipeline allows you to directly submit your data into an SRA-linked BioProject. Evaluate High-throughput Sequencing Reads with FastQC Aug 01, 2017 FastQC is a popular tool for evaluating the quality of high-throughput sequencing reads such as from Illumina and PacBio. HTSeqQC Aug 01, 2017 An automated quality control analysis tool for a single and paired-end high-throughput sequencing data (HTS) generated from Illumina sequencing platforms Import data from NCBI SRA using the Discovery Environment Apr 04, 2017 The NCBI Sequence Read Archive (SRA) is a repository for high-throughput sequencing reads. These are valuable data for novel analysis and reuse. You can directly import data from SRA into your Data Store using a Discovery Environment app. Discover Variants Using SAM Tools Oct 11, 2016 Detect and call variants from sequence reads using Bowtie and SAM Tools. Filter, Trim, and Process High-throughput Sequencing Reads with Trimmomatic Sep 15, 2016 Trimmomatic is a popular application for filtering and trimming high- throughput sequencing reads. Several functions can remove populations of low quality reads, remove sequencing adaptors, and trim low-quality regions of individual reads. Characterizing Differential Expression With RNA-Seq (Without Reference Genome) Jul 21, 2015 Identify changes in gene expression levels between at least two sequenced transcriptome samples (18 separate tutorials) BLAST a Transcriptome May 11, 2016 Reduce number of transcripts and level of redundancy in an assembled transcriptome, and identify coding sequences that can be submitted to BLASTP searches. QIIME-1.9.1 for the DE Apr 12, 2016 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. mini SOAPdenovo Jan 04, 2016 Gain familiarity with a commonly used procedure for de novo whole genome assembly of Illumina reads using the DE. Genome-wide Association Study (GWAS) Using a Genotyping-by-sequencing Approach Sep 27, 2012 Learn to identify genetic variants that are associated with a trait."},{"location":"edu/tutorials/#sciapps","title":"SciApps","text":"Tutorial Date Notes Association analysis with mixed models Sep 18, 2013 A genome-wide association study (or GWAS) workflow using TASSEL, EMMAX, and MLMM for mixed model analysis."},{"location":"edu/tutorials/#atmosphere","title":"Atmosphere","text":"Tutorial Date Notes Basic Stacks Nov 06, 2017 Use next generation sequence data produced from Reduced Representation Libraries (RRL) such as Restriction site associated (RAD) tags. fastStructure Oct 01, 2017 fastStructure is a fast algorithm for inferring population structure from large SNP genotype data. It is based on a variational Bayesian framework for posterior inference and is written in Python2.x. Installing R packages on Atmosphere Jun 23, 2016 Install R packages on Atmosphere: Launch instance, transfer files to instance, install R package, request imaging. QIIME-1.9.1 for Atmosphere Jun 12, 2017 QIIME is an open-source bioinformatics pipeline for performing microbiome analysis from raw DNA rnaQUAST 1.2.0 May 19, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). QUAST 4.0 May 19, 2016 QUAST is a tool for evaluating genome assemblies by computing various metrics. rnaQUAST 1.1.0 May 11, 2016 rnaQUAST is a tool for evaluating RNA-Seq assemblies using reference genome and gene data database. In addition, rnaQUAST is also capable of estimating gene database coverage by raw reads and de novo quality assessment using third-party software (STAR, TopHat, GMAP etc.). Evolinc May 03, 2016 Evolinc is a two-part pipeline to identify lincRNAs from an assembled transcriptome file (.gtf output from cufflinks) and then determine the extent to which those lincRNAs are conserved in the genome and transcriptome of other species. FaST-LMM.Py v2.02 Apr 19, 2016 Introduce new users to the FaST-LMM software for GWAS analysis. KOBAS 2.0-09052014 Apr 19, 2016 Learn how to annotate and identify using KOBAS 2.0. Validate Workflow v0.9 Apr 19, 2016 Learn to navigate the Validate Workflow. BATools 0.0.1 Apr 10, 2016 Introduce new users to BATools and the BATools Wrapper Script."},{"location":"edu/tutorials/#geoinformatics-tutorials-using-cyverse","title":"Geoinformatics Tutorials Using CyVerse","text":"Tutorial Date Notes NEON AOP Workshop Nov 11, 2021 Second virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON AOP Workshop Nov 05-07, 2020 First virtual NEON AOP Workshop in collaboration with USDA-ARS and UArizona RISE Conference NEON-CyVerse Workshop Jan 09, 2019 CyVerse Workshop taught at Battelle Inc. NEON Headquarters, Boulder CO NEON Data Science Institute July 12, 2018 NEON summer workshop taught at Battelle Inc. NEON Headquarters, Boulder CO"},{"location":"edu/tutorials/#astronomy-tutorials-using-cyverse","title":"Astronomy Tutorials Using CyVerse","text":"Workshop Date Description Cloud Computing Busy Week Feb 2-7, 2020 a five-day busy week was conducted at the University of Arizona in order for PIRE members to work on large-scale synthetic data generation for the Event Horizon Telescope (EHT) project AstroContainers Workshop May 7-8, 2018 designed for astronomers and astrophysicists at Steward, LSST, NOAO, and LPL MiniHackathon PIRE Apr 11, 2018 Docker and Jupyter for Reproducible Astronomy"},{"location":"edu/tutorials/dna_subway_guide/","title":"DNA Subway","text":""},{"location":"edu/tutorials/dna_subway_guide/#goal","title":"Goal","text":"<p>DNA Subway is an educational bioinformatics platform developed by CyVerse. </p> <p>It bundles research-grade bioinformatics tools, high-performance computing, and databases into workflows with an easy-to-use interface. </p> <p>\"Riding\" DNA Subway lines, students can predict and annotate genes in up to 150kb of DNA (Red Line), identify homologs in sequenced genomes (Yellow Line), identify species using DNA barcodes and phylogenetic trees (Blue Line), examine RNA-Seq datasets for differential transcript abundance (Green Line), and analyze metabarcoding and eDNA samples using QIIME (Purple Line).</p>"},{"location":"edu/tutorials/dna_subway_guide/#prerequisites","title":"Prerequisites","text":"<p>In order to complete this tutorial you will need access to the following services/software</p> Prerequisite Preparation/Notes Link/Download CyVerse account You will need a CyVerse account to complete this exercise Register DNA Subway Access DNA Subway access is by request access Check or request access: CyVerse User Portal"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-basics-and-logging-in-to-subway","title":"DNA Subway Basics and Logging in to Subway","text":"<p>DNA Subway is designed to be a classroom-friendly approach to bioinformatics. Unlike most CyVerse platforms, you can even use Subway without registering for a CyVerse account. We do encourage you to register however, only work from registered users can be saved. DNA Subway uses the same open-source bioinformatics tools used by researchers. See a complete list of the tools provided in the Subway pipelines.</p> <p>Some things to remember about the platform</p> <p>Registered user and Guest user account types</p> <ul> <li>DNA Subway access must be requested through the CyVerse user portal.     You can check if you already have access, or request access by     logging into the portal and visiting the My     Services page. If DNA     Subway is not listed, click on     Available services to     request access.</li> <li>Guest users will not have their worked saved beyond a single DNA     Subway session. They are also disallowed from using one of the gene     predictors (FGenesH) in the genomic annotation pipeline (Red Line).</li> <li>We suggest that every student using DNA Subway obtain their own     account.</li> </ul> <p>Sample Datasets and reference data</p> <p>All Subway lines accept user data and also have sample data that can be immediately used to create a project.</p> <ul> <li>Red Line - Genome Annotation: Samples of plant and animal     genomes that can be used in annotation projects</li> <li>Yellow Line - TARGeT Search for transposons and other DNA     Sequences: Several model plant genomes</li> <li>Blue Line - DNA Barcoding and Phylogenetics: Sample sequence     from plant, animal, fungal, and bacterial barcoding regions; human     mitochondrial DNA sequence</li> <li>Green Line - RNA-Seq for differential expression: Sample     high-throughput reads from RNA-Seq experiments</li> </ul> <p>If there is a reference data set or sample sequence you would like added, you can contact CyVerse using the DNA Subway Contact page</p> <p>Public and private projects - DNA Subway projects are private by default, but can be shared by making them public. Public projects are searchable and are a great way to share data or present analysis for grading in a classroom project.</p>"},{"location":"edu/tutorials/dna_subway_guide/#logging-into-dna-subway-as-a-registered-user","title":"Logging into DNA Subway as a registered user","text":"<ol> <li>Access the DNA Subway website at https://dnasubway.cyverse.org/</li> <li> <p>If you wish to use DNA Subway as a guest click 'Enter As Guest'</p> <p>Note</p> <pre><code>When using DNA Subway as a guest, you will be able to work only on\nthe Red, Yellow, and Blue lines. Additionally, some Red Line\nfunctionalities will be disabled. Finally, after logging out, or a\nperiod of inactivity (\\&gt;\\~ 30 min) you work will be discarded.\n</code></pre> </li> <li> <p>Enter your CyVerse username and CyVerse password.</p> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#logging-into-dna-subway-as-a-guest-user","title":"Logging into DNA Subway as a guest user","text":"<ol> <li>Access the DNA Subway website at https://dnasubway.cyverse.org/; click 'Enter as Guest'</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#accessing-saved-private-and-public-dna-subway-projects","title":"Accessing Saved Private and Public DNA Subway Projects","text":"<p>DNA Subway projects are automatically saved for registered users. By default, Subway projects are private upon creation and visible only to you. You may make project public, in which case users will have the ability to view those projects, but may not edit those projects.</p>"},{"location":"edu/tutorials/dna_subway_guide/#accessing-private-projects","title":"Accessing Private Projects","text":"<ol> <li> <p>Access the DNA Subway website at https://dnasubway.cyverse.org/</p> </li> <li> <p>Upon login, you will see a listing of your private projects. Access the project by clicking the project title.</p> </li> <li> <p>From any DNA Subway page, you may access private projects by clicking the 'My Projects' button on the navigation menu on the left side of the page.</p> </li> </ol> Distinguishing Lines <p>All projects in DNA Subway are associated with the color of their respective DNA Subway lines, and with a project ID number. </p> <p>You may see the comments and species associated with the project</p> <p></p> Deleting a project <p>To delete a project, click the 'trash can' icon. Once deleted, all data related to that project will be lost and unrecoverable.</p>"},{"location":"edu/tutorials/dna_subway_guide/#accessing-public-projects","title":"Accessing Public Projects","text":"<ol> <li> <p>Access the DNA Subway website at https://dnasubway.cyverse.org/; login to Subway or enter as a guest user.</p> </li> <li> <p>On the navigation menu on the left side of the screen, click 'Public Projects'</p> </li> </ol> Sorting and Search <p>You can sort by project date or type, and you can search for a project by title, organism, or the name of the project owner. When searching, click the double arrow `` to search by your selected term.</p>"},{"location":"edu/tutorials/dna_subway_guide/#make-a-dna-subway-project-private-or-public","title":"Make a DNA Subway Project Private or Public","text":"<ol> <li>Access the DNA Subway website at https://dnasubway.cyverse.org/; login to Subway.</li> <li>Access your selected project by clicking the project title.</li> <li>Under the 'Project Information' tab, toggle the project setting to 'Public' or 'Private' as desired.      </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#walkthrough-of-dna-subway-red-line-genome-annotation","title":"Walkthrough of DNA Subway Red Line - Genome Annotation","text":"<p>Annotation adds features and information to a DNA sequence -- such as genes and their locations, structures, and functions. A good introduction to annotation can be found in the paper A beginner's guide to eukaryotic genome annotation. We'll also suggest the DNA Subway's primer on annotation evidence.  This guide contains an explanation of basic functions for this line, as wellas exercises that might be used in the classroom. Some things to remember about the platform     @@ -205,156 +164,115 @@ as exercises that might be used in the classroom.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-create-an-annotation-project-with-apollo","title":"DNA Subway Red Line - Create an Annotation Project with Apollo","text":"transition away from Java <p>DNA Subway is transitioning away from the original Java-based Apollo software as most popular web browsers will no longer support Java. The new Apollo is Java-free.</p> <ol> <li>Log-in to DNA Subway -     unregistered users may 'Enter as Guest'</li> <li>Click 'Annotate a genomic sequence.' (Red Square); select the     'Web Apollo' version</li> <li> <p>For 'Select Organism type' choose 'Animal' or 'Plant' and     then select the appropriate subtype.     The 'Select Organism' step will load appropriate sample     sequences and will also adjust the models used in the de novo gene     finding process.</p> </li> <li> <p>For 'Select Sequence Source' select a sample sequence.</p> </li> </ol> Apollo support <p>Currently, the Java-free Apollo version of Subway does not support upload of a custom DNA Sequence. </p> <p>This feature is coming soon, but we will help you upload custom genomes/regions for your use in the classroom</p> <ol> <li>(Optional) If you have a GFF file of annotated features, you may load these import these annotations from the Green Line, or from a     custom GFF file.</li> <li>Name your project and organism (required) and give a description if desired. Click 'Continue' to proceed.</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-project-creation-arabidopsis-chri","title":"Example Exercise - Project Creation: Arabidopsis ChrI","text":"<p>In this and subsequent steps, we will annotate a 75KB section of Arabidopsis chromosome I. 1.  Log-in to DNA Subway - unregistered users may 'Enter as Guest'. 2.  Click 'Annotate a genomic sequence.' (Red Square); select the 'Web Apollo' version. 3.  For 'Select Organism type' choose 'Plant' and then 'Dicotyledon'. 4.  from 'Select a sample sequence' chose 'Arabidopsis thaliana (mouse-ear cress) chr1, 75.00 kb'. 5.  Provide your project with a title, then Click 'Continue.'</p> Sequence <p>You can view your DNA sequence by clicking the 'Sequence' link in the 'Project Information' tab at the bottom of the page.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-find-and-mask-repetitive-dna","title":"DNA Subway Red Line - Find and Mask Repetitive DNA","text":"<p>One you have created a Red Line Project, you may begin the process of generating and assembling predictions and evidence that can be used to annotate genes. 1.  Click 'RepeatMasker' 2.  When 'RepeatMasker' turns 'green' and the icon displays a 'V' (view); click 'RepeatMasker' again to view results.</p> <pre><code>![repeat_results](./assets/dna_subway/repeat_results.png){width=\"300px\" height=\"200px\"}\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-repeat-masking-arabodopsis-chri","title":"Example Exercise - Repeat Masking: Arabodopsis ChrI","text":"<ul> <li>Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI, 75 kb</li> <li>Tool(s): RepeatMasker</li> <li>Concept(s): Non-coding DNA, sequence repeats, mobile genetic     elements (transposons)</li> </ul> <p>Following the RepeatMasking steps for the Arabidopsis ChrI sample above, answer the following discussion questions: 1.  How many hits were detected in your sample? 2.  RepeatMasker reports the length of the repetitive sequences     (Length) as well as the class (Attributes). -   What is the average length of sequences identified as \"simple     repeats\"? -   What is the average length of sequences identified as \"low     complexity\"? 3.  What is the total percentage of repetitive DNA in your sequence?     (Sum of the length of all repetitive sequence / sequence length     (75 kb)</p> Some Useful Definitions for Repetitive Sequences <ul> <li> <p>Simple repeats: 1-5bp repeats (e.g. repetitive dinucleotides 'AT' etc.)</p> </li> <li> <p>Low Complexity DNA: Poly-purine/ poly-pyrimidine stretches, or regions of extremely high AT or GC\u00a0content.</p> </li> <li> <p>Processed Pseudogenes, SINES, Retrotranscripts: Non-functional RNAs present within genomic sequence.</p> </li> <li> <p>Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome.</p> </li> </ul> <p>Additional Investigation: In the results table under 'Attributes' each repeat sequence is labeled \"RepeatMasker#-XXX\" The '#' is the ordinal number of the hit, the XXX is the class of DNA element (e.g. \"Simple_repeat\" or \"Low_complexity\"). There are other types of repetitive elements such as transposons and pseudogenes (e.g. Helitron and COPIA) Use online resources to learn more: (http://gydb.org/index.php/Main_Page).</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-making-gene-predictions","title":"DNA Subway Red Line - Making Gene Predictions","text":"<p>De novo gene predictors can be run on a sample sequence to generate predictions of gene structure and location based solely on the sequence nucleotides.</p> <ol> <li>Click on one or more gene prediction tools under the 'Gene     Prediction' stop. to view the results table, click the gene     predictor again once the indicator displays 'V' (view).</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-predict-genes-arabidopsis-chri","title":"Example Exercise - Predict Genes: Arabidopsis ChrI","text":"<ul> <li>Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI,     75 kb</li> <li>Tool(s): Augustus, FGenesH, Snap, tRNA Scan</li> <li>Concept(s): Genomic DNA, Gene Structure, Canonical sequences</li> </ul> <p>Following the gene prediction steps for the Arabidopsis ChrI sample above, answer the following discussion questions:</p> <ol> <li> <p>Look at the 'Type' column in the gene prediction report.     Considering the Augustus results, find the 6<sup>th</sup> gene prediction     (hint: AUGUSTUS006;ID=g6) and then locate the first mention of the     term 'gene' and copy down the gene's 'start' (i.e. the starting     basepair). Note the number of times you see the term 'exon' (i.e.     number of exons predicted).</p> Gene Predictor Exon Start (bp) Exon Stop (bp) Augustus 23456 23684 Augustus Augustus Augustus Augustus </li> <li> <p>Based on the chart, did all the gene predictors yield genes     starting at the same location? Did all the gene predictions have     the same number of exons?</p> </li> <li>Looking at the number of results returned by tRNA Scan, why are     they so different from results made by other predictors? Are their     places in the genome where tRNAs are more or less densely     concentrated?</li> </ol> <p>Additional Investigation: Look for the background link at the bottom of the DNA Subway home page and review the section entitled 'Gene Finding'.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-visualize-predicted-genes-in-a-genome-browser","title":"DNA Subway Red Line - Visualize predicted genes in a Genome Browser","text":"<p>A genome browser is an essential tool for visualization genomic data in context. The integrated JBrowse genome browser will allow you to see the visualized gene predictions generated so far.</p> <ol> <li>Click 'JBrowse' and allow browser to load.</li> <li> <p>Zoom into a region (for example, paste the region     1:3740638..3749063 into the location window.</p> <p>Tip</p> <pre><code>- JBrowse will load multiple tracks of data. Since the entire genome is loaded, we recommend using the 'highlight a region' feature to help keep your place. You may also wish to record the\ncoordinates you are viewing as shown in the coordinates window.\n- You may also adjust the settings for a particular track by clicking on the track name.\n- Right-click on any gene to view additional details about that gene.\n![jbrowse](./assets/dna_subway/jbrowse.png){width=\"400px\" height=\"250px\"}\n</code></pre> </li> <li> <p>Examine gene details by double-clicking on a gene to select; then     right-click to open the 'View Details' menu.</p> </li> <li>To view more tracks, click on 'Full-Screen View' in the     upper-left of the JBrowse window to see any additional tracks     available.</li> </ol> Useful Definitions <p>Genome Browser: A GUI (Graphical User Interface) for viewing biological information. GBrowse (DNA Subway's Browser) is \"designed to view genomes. It displays a graphical representation of a section of a genome, and shows the positions of genes and other functional elements. It can be configured to show both qualitative data such as the splicing structure of a gene, and quantitative data such as microarray expression levels.\" [citation]</p> <p>Track: The individual regions of the display where information imported into the browser. For each type (or source) of information, there is usually an associated track.</p>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-visualize-predicted-genes-arabidopsis-chri","title":"Example Exercise - Visualize predicted genes: Arabidopsis ChrI","text":"<ul> <li>Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI,     75 kb</li> <li>Tool(s): Local Browser (JBrowse)</li> <li>Concept(s): Gene orientation/structure, transposons, chromosome     organization</li> </ul> <p>Following the gene browser steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser):</p> <p>Considering the following genes:</p> <ul> <li>BFN1-201 (1:3748591..3753070)</li> <li>SCAMP5-201 (1:3744556..3749035)</li> <li>STP1-201 (1:3776366..3780845)</li> <li> <p>At1G11270.2 (1:3780041..3789000)</p> </li> <li> <p>Do all the gene predictors agree with each other?</p> </li> <li>Which gene predictions seem to match the Ensemble genes most closely?</li> </ul>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-search-databases-using-blast","title":"DNA Subway Red Line - Search Databases using BLAST","text":"<p>DNA Subway searches customized versions of UniGene and UniProt that contain only validated plant proteins, and are free of predicted or hypothetical proteins.</p> <ol> <li>Click 'BLASTN'; wait until the flashing icon displays 'V' (view)</li> <li>Click 'BLASTN' again to view the results.</li> <li>Click 'BLASTX'; wait until the flashing icon displays 'V' (view).</li> <li>Click 'BLASTX' again to view the results.</li> <li>Click on 'JBrowse' and then click 'Full-screen View' in the     upper-left.</li> <li>In the 'Available Tracks' menu, add the Blastn and Blastx     tracks.</li> </ol> Useful Definitions <pre><code>**Some Useful Definitions**\n</code></pre> <ul> <li>BLAST: Basic Local Alignment Search Tool (BLAST) is an     algorithm that search databases of biological sequence information     (e.g. DNA, RNA, or Protein sequence) and return matches. The     BLASTN program is specific to nucleotide data, and the BLASTX     algorithm works with sequence data translated into amino acid     sequences.</li> <li>UniGene: A database of transcript data, \"each UniGene entry is     a set of transcript sequences that appear to come from the same     transcription locus (gene or expressed pseudogene), together with     information on protein similarities, gene expression, cDNA clone     reagents, and genomic location.\"     [citation]</li> <li>cDNA: DNA produced by reverse transcribing mRNA using reverse     transcriptase. cDNAs are used to investigate mRNA within a     biological sample.</li> <li>ESTs: \"Small pieces of DNA sequence (usually 200 to 500     nucleotides long) that are generated by sequencing either one or     both ends of an expressed gene. The idea is to sequence bits of     DNA that represent genes expressed in certain cells, tissues, or     organs from different organisms.\"     [citation]</li> </ul>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-search-databases-using-blast-arabidopsis-chri","title":"Example Exercise - Search Databases using BLAST: Arabidopsis ChrI","text":"<ul> <li>Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI,     75 kb</li> <li>Tool(s): BLASTN, BLASTX, Upload Data</li> <li>Concept(s): RNA, cDNAs, ESTs, Biological Databases</li> </ul> <p>Following the BLAST steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser):</p> <ol> <li>Both BLASTN and BLASTX returns the 'Length' of your resulting     matches. Do you notice differences in the average lengths of     BLASTN and BLASTX matches? Explain.</li> <li>Under 'Type' both BLASTN and BLASTX returns 'match' and     'match_part.' 'Match' is describing the overall length of a single     match, but individual significant matches may be fragmented, i.e.     'match_part.' Do BLASTN and BLASTX return 'match' and 'match_part'     results in different frequencies? Explain.</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-red-line-build-gene-models-using-apollo","title":"DNA Subway Red Line - Build Gene Models using Apollo","text":"<p>Apollo is an extension of JBrowse which allows the user to build and edit gene models. Apollo has a number of features but in this tutorial, we will give brief intro covering the conceptual steps.</p> <p>A. Import Blastn model to match for transcript length Blast searches are matched against UniGene(blastn) and UniProt(blasts). UniGen models are derived from cDNA and ESTs (transcriptome evidence) produced by experiment.</p> <ol> <li>Open Apollo and zoom into a region of interest (e.g. 1:3793981..3802033)</li> <li>Ensure at least the following tracks are selected (on):<ul> <li>Augustus (and other gene predictors: FGenesH, SNAP, etc.)</li> <li>Blastn</li> </ul> </li> <li>Double-click on the Blastn result, and drag this transcript into     the yellow 'User-created Annotations' section.     {width=\"400px\"     height=\"250px\"}</li> </ol> <p>B. Select a scaffold model Use transcriptome evidence (UniGene - BLASTN) to select the best possible gene model for a scaffold. If no gene model exists or significantly reflects the UniGene model, use the UniGene model itself as a scaffold.</p> <ol> <li>Drag a plausible model into the yellow 'User-created     Annotations' - in this case we will choose the Augustus model;     double-click the Augustus model to select the entire model and     drag into 'User-created Annotations'.</li> <li>Adjust the Augustus model to match the 5' and 3' configuration     of the blastn model<ul> <li>Delete the extraneous 5' exon (single-click to select;     right-click to delete)</li> <li>Adjust the new 5' end to match the length of the blastn-derived     transcript</li> <li>Adjust the 3' end of the Augustus-derived model (single-click     to select; use your cursor/mouse to adjust the model length) </li> </ul> </li> </ol> <p>C. Edit model for splice sites and variants Protein and EST data can be used to examine possible alternative transcripts. Proteins give clues to the actual length of the translated protein at that locus and its reading frame. Like full length cDNAs, ESTs give valuable information on transcript diversity. ESTs are generated by high throughput methods, and although the data may be fragmentary, it may capture biologically relevant information about splice variants.</p> <ol> <li> <p>Turn on the blastx track</p> </li> <li> <p>Examine the additional evidence to consider making adjustments to     your Augustus-derived model. If you wish to make additional     isoforms of your gene:</p> <ul> <li>Double-click to select the entire Augustus-derived model</li> <li>Right-click on the model to duplicate</li> <li>Make adjustments to the model as desired  </li> </ul> </li> </ol> <p>You also have the option of adding additional EST evidence. For the Arabodopsis 75KB section, we have prepared a selection of EST data. You will need to close Apollo to load this data.</p> <ol> <li>Download the Arabidopsis ESTs for this region to your computer     from this link</li> <li>Click on 'Upload Data'; under \"Add DNA data in FASTA format\"     upload the EST file from the link in step 1.</li> <li>Click on 'User BLASTN' to align the ESTs to this section of the     Arabidopsis genome</li> <li>Open 'Web Apollo'. The \"Blastn User\" track should be loaded.     You may move this track to a convenient position on the browser     </li> </ol> <p>While EST evidence is always incomplete, these sequences can help you determine features of the gene model.</p> Learn More about Gene Evidence <ul> <li>J.Craig Venter on ESTs</li> <li>\"Dynamic Gene\" Evidence animation (requires Flash)</li> </ul> <p>D. Determine translation start/stop sites After making your adjustments, you can confirm that your gene model(s) represents the longest possible transcripts:</p> <ol> <li>Double-click the model; right-click and select 'Set longest ORF'</li> </ol> <p>E. Compare gene model(s) with existing annotations After making your gene models you can compare them with existing annotations by turning on the 'Ensemble genes' track. In this case, our work confirms the first gene model made, but a potential isoform supported by blastx data is likely incorrect.</p> <p></p>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-build-gene-models-using-apollo-arabodopsis-chri","title":"Example Exercise - Build Gene Models using Apollo: Arabodopsis ChrI","text":"<ul> <li>Example Sequence: Arabidopsis thaliana (mouse-ear cress) ChrI,     75 kb</li> <li>Tool(s): Apollo</li> <li>Concept(s): Synthesizing multiple lines of evidence</li> </ul> <p>Following the Apollo steps for the Arabidopsis ChrI sample above, answer the following discussion questions (the locations of the genes are given in parentheses and can be pasted into the browser):</p> <ol> <li>Try annotation of the following genes and take notes on your     annotation ( right-click on the gene model, open the 'Information     Editor' and scroll down to the comments section to enter     comments). How do your annotations compare with the Ensembl     annotations?     Genes to try:<ul> <li>AT1G11270.2 (1:3781511..3790520)</li> <li>STP1-201 (1:3776261..3785270)</li> <li>T28P6.11-201 (1:3762877..3764678)</li> </ul> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#walkthrough-of-dna-subway-yellow-line-sequence-detection","title":"Walkthrough of DNA Subway Yellow Line - Sequence Detection","text":"<p>Genome prospecting uses a query sequence (DNA or protein of up to 10,000 base pairs/amino acids) to find related sequences in specific genomes or in a database. A major purpose of genome prospecting is to identify members of gene or transposon families. DNA Subway uses the TARGeT workflow, which integrates BLAST searches, multiple sequence alignments, and tree-drawing utilities. Yellow line uses TARGeT (Tree Analysis of Related Genes and Transposons) uses either a DNA or amino acid 'seed' query to: (i) automatically identify and retrieve gene family homologs from a genomic database, (ii) characterize gene structure and (iii) perform phylogenetic analysis. Due to its high speed, TARGeT is also able to characterize very large gene families, including transposable elements (TEs). [citation]</p> <p>Some things to remember about the platform</p> <ul> <li>Yellow Line will return sequences that would normally be excluded     from a BLAST search of a genome (e.g. repetitive sequences,     transposons).</li> <li>Yellow Line is implemented only for plant genomes</li> </ul>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-yellow-line-create-a-yellow-line-project","title":"DNA Subway Yellow Line - Create a Yellow Line Project","text":"<ol> <li>Log-in to DNA Subway -     unregistered users may 'Enter as Guest'</li> <li>Click 'Prospect Genomes using TARGeT' (Yellow Square)</li> <li> <p>Select a sample sequence, or paste in a sequence to search for.</p> <p>Note</p> <p>DNA Subway Yellow Line is only implemented to search a limited set of plant genomes.</p> </li> <li> <p>Provide your project with a title, then Click 'Continue'</p> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-project-creation-mping-mite-element-to-search-plant-genomes-for-an-active-transposon","title":"Example Exercise - Project Creation: mPing Mite element to search plant genomes for an active transposon","text":"<p>The mPing MITE element is an example of an active transposon in rice. Transposons are a major class of DNA elements that impact the function of the genome.</p> <ol> <li>Create a Yellow Line project following the steps above and using the mPing Mite Element (Oryza sativa/Rice)</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-yellow-line-search-plant-genomes-with-target","title":"DNA Subway Yellow Line - Search Plant Genomes with TARGeT","text":"<ol> <li>Click and select the genome(s) you wish to search and the click;     'Run' to search those genomes.</li> <li>Click the 'Alignment Viewer' button to view the results of the     search as a multiple alignment.</li> <li>Click the 'Tree Viewer' button to view a tree that will group     results by similarity.</li> </ol> Viewer Tips <p>Alignment Viewer Generates an alignment of all search results  Tree Viewer Displays the results of sequence matches as a tree, grouped by sequence similarity yellow_tree</p> Useful Definitions <ul> <li>Transposons (DNA, Retroviral, LINES): Genetic elements which have the ability to be amplified and redistributed within a genome. </li> <li>Non-autonomous transposons: Transposons which lack an active transposase gene, thus requiring help from another transposon to move. </li> <li>Autonomous transposons: Transposons which have a functional transposase and can move within the genome.</li> </ul>"},{"location":"edu/tutorials/dna_subway_guide/#example-exercise-search-plant-genomes-mping-mite-element","title":"Example Exercise - Search Plant Genomes: mPing Mite element","text":"<ol> <li>After loading the mPing Mite Element as the query, search the     Oryza Sativa genome, and examine the results in the Alignment and     Tree Viewers.</li> <li>Repeat this analysis with a new project using the Ping transposase     gene and the Ping Transposase protein.</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#walkthrough-of-dna-subway-blue-line-dna-barcoding-and-phylogenetics","title":"Walkthrough of DNA Subway Blue Line - DNA Barcoding and Phylogenetics","text":"<p>You can analyze relationships between DNA sequences by comparing them to a set of sequences you have compiled yourself, or by comparing your sequences to other that have been published in database such as GenBank (National Center for Biotechnology Information). Generating a phylogenetic tree from DNA sequences derived from related species can also allow you to draw inferences about how these species may be related. By sequencing variable sections of DNA (barcode regions) you can also use the Blue Line to help you identify an unknown species, or publish a DNA barcode for a species you have identified, but which is not represented in published databases like GenBank.</p> <p>Some things to remember about the platform</p> <ul> <li>Wet lab protocols and other resources are available at     http://dnabarcoding101.org/</li> <li>The DNA Barcoding 101 site also contains information on low-cost     sequencing for U.S.-based educators.</li> </ul> <p>Sample Data</p> <pre><code>**How to use provided sample data**\n\nIn this guide, we will use a mosquito dataset that includes DNA\nsequences isolated from mosquito larvae collected from Virginia's\nShenandoah Valley (*\"Mosquito dataset\"*). There is a complete\ntwo-hour classroom bioinformatics lab with detailed instructions for\ninstructors and students on QUBES hub\n[here](https://qubeshub.org/qubesresources/publications/165/2). Where\nappropriate, a note (in this orange colored background) in the\ninstructions will indicate which options to select to make use of this\nprovided dataset.\n\n**Sample data citation**: Williams, J., Enke, R. A., Hyman, O.,\nLescak, E., Donovan, S. S., Tapprich, W., Ryder, E. F. (2018). Using\nDNA Subway to Analyze Sequence Relationships. (Version 2.0). QUBES\nEducational Resources.\n[doi:10.25334/Q4J111](http://dx.doi.org/10.25334/Q4J111)\n\n**Video Course**\n\nHere is a video series on analyzing data with DNA Subway using the\nabove mosquito dataset and lesson:\n\n&lt;iframe width=\"560\" height=\"315\" align=\"center\" src=\"https://www.youtube.com/embed/videoseries?list=PLRosqf3DDcTFqyPDG04Ed9EjrjaC_UTQo\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n</code></pre> <p>Tip</p> <pre><code>See a Course Source paper with protocols and recommendations for\nimplementing a Barcoding CURE (course-based undergraduate research\nexperience): [CURE-all: Large Scale Implementation of Authentic DNA Barcoding Research into First-Year Biology Curriculum](https://www.coursesource.org/courses/cure-all-large-scale-implementation-of-authentic-dna-barcoding-research-into-first-year).\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-blue-line-create-a-barcoding-project","title":"DNA Subway Blue Line - Create a Barcoding Project","text":"<ol> <li>Log-in to DNA Subway - unregistered users may 'Enter as Guest'.     !!! Note         Only registered users submitting novel, high-quality sequences         will be able to submit sequence to GenBank</li> <li> <p>Choose a project type:  - Phylogenetics: build phylogenetic trees from any DNA, protein, or mtDNA sequence)  - Barcoding: DNA Barcoding for plants (rbcL), animals (COI), bacteria (16S), and fungi (ITS).</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: Select **COI**.\n</code></pre> <p>3. Under 'Select Sequence Source' select a sequence by uploading either a FASTA file or AB1 Sanger sequencing tracefile; pasting in a sequence in FASTA format, or selecting and importing a trace file from DNALC. If you do not have a file, you may select any of the available sample sequences.</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset:\nFrom **Select a set of sample sequences** select **Intro to Barcoding Bioinformatics: Mosquitoes**.\n</code></pre> <p>4.  Name your project, and give a description if desired; click 'Continue.'</p> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-blue-line-view-and-clean-barcoding-sequence-data","title":"DNA Subway Blue Line - View and Clean Barcoding Sequence Data","text":"<p>A. View Sequencing Trace File</p> <p>If you provided AB1 trace files, or imported files from DNALC, you will be able to view the sequence electropherogram.</p> <ol> <li>Click 'Sequence Viewer' to show a list of your sequences.</li> <li>Click on a sequence name to show the sequences' trace file.</li> </ol> <p></p> <p>B. Trim sequence, reverse complement and pair</p> <p>By default, DNA Subway assumes that all reads are in the forward orientation, and displays an 'F' to the right of the sequence. If any sequence is not in that orientation, click the \"F\" to reverse compliment the sequence. The sequence will display an \"R\" to indicate the change.</p> <ol> <li>Click 'Sequence Trimmer.'</li> <li>Click 'Sequence Trimmer' again to examine to changes made in the sequence</li> <li>Click 'Pair Builder.'</li> <li> <p>Select the check boxes next to the sequences that represent bidirectional reads of the same sequence set. Alternatively Select the 'Auto Pair' function and verify the pairs generated.</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset:\nClick **Try Auto Pairing**. One pair of horsefly sequences and 4\npairs of mosquito sequences will be created. Finally, click\n`Save`{.interpreted-text role=\"guilabel\"}.\n</code></pre> </li> <li> <p>As necessary, Reverse Compliment sequences that were sequenced in     the reverse orientation by clicking the 'F' next to the sequence     name. The 'F' will become an 'R' to indicate the sequence has been     reverse complimented.</p> </li> <li>Click <code>Save</code> to save the created pairs.</li> </ol> <p>C. Build a consensus sequence This step remove poor quality areas at the 5' and/or 3' ends of the consensus sequence.</p> <ol> <li>Click on \"Trim Consensus.\" Once the job is ready to view, click     \"Trim Consensus\" again to view the results. Scroll left and     right in the consensus editor window to identify what string of     nucleotides from the consensus sequence you want to trim.</li> <li>Click on the last consensus sequence nucleotide that you want to     trim. A red line will indicate what nucleotides will be removed     from the consensus sequences.</li> <li> <p>Click <code>Trim</code>. A new \"Consensus     Editor\" window will pop up displaying the trimmed sequences.</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: All of the sequences in this dataset benefit from trimming. Follow the steps above to trim sequences. We recommending trimming at the first and last \"grey\" (lower quality) nucleotide on the right and left ends.\n</code></pre> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-blue-line-find-matches-with-blast","title":"DNA Subway Blue Line - Find Matches with BLAST","text":"<p>DNA Subway Blue Line will search a local copy of a BLAST databases to check for published matches in GenBank.</p> <p>Tip</p> <pre><code>At the end of the BLAST results page, you can see the latest update to the DNA Subway BLAST database.\n</code></pre> <ol> <li>Click 'BLASTN' then click the 'BLAST' link to BLAST the     sequence of interest. When the search is completed a 'View' link     will appear.</li> <li>Examine the BLAST matches for candidate identification. Clicking     the species name given in the BLAST hit will also give additional     information/photos of the listed species.</li> <li> <p>If desired, select the check box next to any hit, and click     <code>&amp;Add BLAST hits to project</code> to     add selected sequences to your project.  </p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: We recommend performing a BLASTN search for all samples and saving the top 2 matches to your project for additional analysis (as in Step 3).\n</code></pre> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-blue-line-add-reference-data","title":"DNA Subway Blue Line - Add Reference Data","text":"<p>Depending on the project type you have created, you will have access to additional sequence data that may be of interest. For example, if you are doing a DNA barcoding project using the rbcL gene, samples of rbcL sequence from major plant groups (Angiosperms, Gymnosperms, etc.) will be provided. Choose any data set to add it to your analysis; you will be able to include or exclude individual sequences within the set in the next step.</p> <ol> <li>Click 'Reference Data.'</li> <li>Select sequences of your choice.</li> <li> <p>Click <code>Add ref data</code> to add     the data to your project.</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: Select **Common insects** and then click `&amp;Add ref data`{.interpreted-text role=\"guilabel\"}.\n</code></pre> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-blue-line-build-a-multiple-sequence-alignment-and-phylogenetic-tree","title":"DNA Subway Blue Line - Build a Multiple Sequence Alignment and Phylogenetic Tree","text":"<p>A. Build a multiple sequence alignment and phylogenetic tree</p> <ol> <li>Click 'Select Data.'</li> <li> <p>Select any and all sequences you wish to add to your tree.</p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: We suggest first adding your \\\"user data\\\" and building an alignment and tree. You can return to this step later to build additional trees. Once Selected, click `Save Selections`{.interpreted-text role=\"guilabel\"}. Follow the rest of the steps in this section and section B to create your tree.\n</code></pre> </li> <li> <p>Click <code>Save Selections</code> to select data</p> </li> <li>Click 'MUSCLE.' to run the MUSCLE program.</li> <li>Click 'MUSCLE' again to open the sequence alignment window.     </li> <li>Examine the alignment and then select the <code>Trim Alignment</code> button in the upper-left of the Alignment viewer'.</li> </ol> <p>B. Build phylogenetic tree</p> <ol> <li> <p>Click 'PHYLIP NJ' and then click again to examine a     neighbor-joining tree     </p> </li> <li> <p>Click 'PHYLIP ML' and then click again to examine a     maximum-likelihood tree     </p> <p>Sample Data</p> <pre><code>*\"Mosquito\"* dataset: We suggest setting \"horsefly\" as outgroup for both trees.\n</code></pre> </li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#walkthrough-of-dna-subway-green-line-kallistosleuth-rna-seq","title":"Walkthrough of DNA Subway Green Line: Kallisto/Sleuth RNA-Seq","text":"<p>The Green Line runs within CyVerse DNA Subway and leverages powerful computing and data storage infrastructure and uses the supercomputer cluster to provide a high performance analytical platform with a simple user interface suitable for both teaching and research. is a quick, highly-efficient software for quantifying transcript abundances in an RNA-Seq experiment. Even on a typical laptop, Kallisto can quantify 30 million reads in less than 3 minutes. Integrated into CyVerse, you can take advantage of CyVerse DNA Subway to process your reads, do the Kallisto quantification, and analyze reads with the Kallisto companion software in an R-Shiny app.</p> <p>Some things to remember about the platform</p> <ul> <li>You must be a registered CyVerse user to use Green Line.</li> <li>The Green Line was designed to make RNA-Seq data analysis     \"simple\". However, we ask that users thoughtfully decide what     \"jobs\" they want to submit. Each user is limited to a maximum of     4 concurrent jobs running on Green Line.</li> <li>A single Green Line project may take a week to process since HPC     computing is subject to queues which hundreds of other jobs may be     staging for. Additionally these systems undergo regular maintenance     and are subject to periodic disruption.</li> </ul> <p>Note</p> <p>New, faster Green Line</p> <p>Green Line is now running on Jestream Cloud. This should greatly reduce queue times (The entire running time for this tutorial is about 60 minutes). We have designed Green Line for a lower number of concurrent users (&lt;50), and still recommend teaching using jobs you have made public, and only running the entire workflow when you are working with novel data. Please let us know about your experience: send feedback.</p> <p></p> <p>Important: Discontinued Support for Tuxedo Workflow</p> <p>The Tuxedo workflow previously implemented for the Green Line will has been removed in June 2019. Data and previously analyzed results will still be available on the CyVerse Data Store, however it is not possible to execute new analyses which include Tuxuedo.</p> <p>Sample Data</p> <pre><code>**How to use provided sample data**\n\nIn this guide, we will use an RNA-Seq dataset (*\"Zika infected\nhNPCs\"*). This experiment compared human neuroprogenetor cells\n(hNPCs) infected with the Zika virus to non-infected hNPCs. You can\nread more about the experimental conditions and methods in this [reference](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0175744).\nWhere appropriate, a note (in this orange colored background) in the\ninstructions will indicate which options to select to make use of this\nprovided dataset.\n\n**Sample data citation**: Yi L, Pimentel H, Pachter L (2017) Zika\ninfection of neural progenitor cells perturbs transcription in\nneurodevelopmental pathways. PLOS ONE 12(4): e0175744. [reference](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0175744).\n\n**Video Course**\n\nHere is a video series on analyzing data with DNA Subway using the above Zika dataset and lesson:\n\n&lt;iframe width=\"560\" height=\"315\" align=\"center\" src=\"https://www.youtube.com/embed/videoseries?list=PLRosqf3DDcTHLTsiCTT8tnA2ZAfMM5AWb\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-create-an-rna-seq-project-to-examine-differential-abundance","title":"DNA Subway Green Line: Kallisto/Sleuth - Create an RNA-Seq Project to Examine Differential Abundance","text":"<p>A. Create a project in Subway</p> <ol> <li>Log-in to - unregistered users may NOT use Green Line.</li> <li>Click on the Green \"Next Generation Sequencing\" square to start     a Green Line project.</li> <li> <p>For 'Select Project Type' select either \"Single End Reads\" or     \"Paired End Reads\".</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: Select **Paired End Reads**\n</code></pre> </li> </ol> <p>4.  For 'Select an Organism' select a species and genome build.</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: Select **Homo sapiens - Ensembl 78 GrCh38**\n</code></pre> <p>5.  Enter a project title, and description; click 'Continue'.</p> <p>Tip</p> <pre><code>If you don't see a desired species/genome [contact us](https://dnasubway.cyverse.org/feedback.html) to have it added.\n</code></pre> <p>B. Upload Read Data to CyVerse Data Store The sequence read files used in these experiments are too large to upload using the Subway internet interface. You must upload your files (either .fastq or .fastq.gz) directly to the CyVerse Data Store.</p> <ol> <li>Upload your reads to the CyVerse Data Store using Cyberduck. See instructions: Data Store Guide.</li> </ol> <p>Note</p> <pre><code>This step is not directly connected with DNA Subway. You can use any data uploaded to the CyVerse Data Store.\n</code></pre> <p>Data Limit</p> <pre><code>There is a limit of 6GB per file for samples on Green Line. For larger file sizes, you may wish to use the Kallisto tools in the CyVerse Discovery Environment. See the for more information.\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-manage-data-and-check-quality-with-fastqc","title":"DNA Subway Green Line: Kallisto/Sleuth - Manage Data and Check Quality with FASTQC","text":"<p>A. Select and pair files</p> <ol> <li>Click on the \"Manage Data\" step: this opens a Data store window     that says \"Select your FASTQ files from the Data Store\" (if you     are not logged in to CyVerse, it will ask you to do so).</li> <li> <p>Click on the folder that matches your CyVerse username and     Navigate to the folder where your sequencing files are located.</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: Select **Sample Data**.\n</code></pre> </li> <li> <p>Select the sequencing files you want to analyze (either .fastq or .fastq.gz format).</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: You will be presented with the following 8 files; **check-select all of the files** and click the `+ Add files`{.interpreted-text role=\"guilabel\"} button:\n</code></pre> <ul> <li>SRR3191542_1.fastq.gz</li> <li>SRR3191542_2.fastq.gz</li> <li>SRR3191543_1.fastq.gz</li> <li>SRR3191543_2.fastq.gz</li> <li>SRR3191544_1.fastq.gz</li> <li>SRR3191544_2.fastq.gz</li> <li>SRR3191545_1.fastq.gz</li> <li>SRR3191545_2.fastq.gz</li> </ul> <p>The SRR3191542 and SRR3191543 files are 2 replicates (paired-end) of the uninfected cells and the SRR3191544 and SRR3191545 file are from the Zika infected cells.</p> </li> <li> <p>If working with paired-end reads, click the <code>Pair Mode OFF</code> button to toggle to on; check each pair of sequencing files to pair them.</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: Right reads end in \"_1\" and left reads end in \"_2\". **Click the** `Pair Mode OFF`{.interpreted-text role=\"guilabel\"} **button** to turn pairing on, and **check-select each of the paired samples** (e.g. SRR3191543_1.fastq.gz and SRR3191543_2.fastq.gz).\n</code></pre> </li> </ol> <p>B. Check sequencing quality with FastQC</p> <p>It is important to only work with high quality data. is a popular tool for determining sequencing quality.</p> <p>Tip</p> <pre><code>This step takes place in the same **Manage data** window as the steps above.\n</code></pre> <ol> <li> <p>Once files have been loaded, in the 'Manage Data' window, click the 'Run' link in the 'QC' column to run FastQC.</p> <p>Note</p> <pre><code>There is a limit of 4 concurrent jobs. These jobs should take less\nthan 20 minutes to complete (depending on file size) and you may need\nto let several jobs finish before proceeding. If you have previously\nprocessed reads for quality, you can skip the FastQC step.\n</code></pre> </li> </ol> <p>2.  One the jobs are complete, click the 'View' link to view the results.</p> <p>Tip</p> <p>You can see a description and explanation of the FastQC report on the CyVerse Learning Center and a more detailed set of explanations on the website.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-trim-and-filter-reads-with-fastx-toolkit","title":"DNA Subway Green Line: Kallisto/Sleuth - Trim and Filter Reads with FastX Toolkit","text":"<p>Raw reads are first \"quality trimmed\" (remove poor quality bases off the end(s) of a read) and then are \"quality filtered\" (filter out entire poor quality reads) prior to aligning to the transcriptome. After trimming and filtering, FastQC is run on the trimmed/filtered files.</p> <ol> <li> <p>Click \"FastX ToolKit\" to open the FastX Toolkit panel for all your data.</p> </li> <li> <p>For each file, under 'Basic', Click 'Run' to filter the reads using default parameters or click 'Advanced' to run with desired parameters; repeat this process for all the FASTQ files in your dataset.</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: The quality of the reads in this dataset is relatively good. You can **skip the FastX Toolkit step for this dataset**.\n</code></pre> <p>Tip</p> <pre><code>The 'Basic' setting for FastX Toolkit uses the same settings as\nthe defaults in the 'Advanced' run:\n</code></pre> <ul> <li>quality_trimmer: minimum quality: 20</li> <li>quality_trimmer: minimum trimmed read length: 20</li> <li>quality_filter: minimum quality: 20</li> <li>quality_filter: minimum quality: 50</li> </ul> </li> <li> <p>Once the job completes, click the 'View' link to view a generated FastQC report.</p> </li> <li>Since you may trim reads multiple times to achieve the desired quality of data record the job IDs (e.g. fx####) that you wish to use in the subsequent steps.</li> </ol>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-quantify-reads-with-kallisto","title":"DNA Subway Green Line: Kallisto/Sleuth - Quantify reads with Kallisto","text":"<p>Kallisto uses a 'hash-based' pseudo alignment to deliver extremely fast matching of RNA-Seq reads against the transcriptome index (which was selected when you created your Green Line project). A Kallisto analysis must be run for each mapping of RNA-Seq reads to the index. In this tutorial, we have 12 fastQ files (6 pairs), so you will need to launch 6 Kallisto analyses.</p> The Science Behind Kallisto <pre><code>You can find a detailed video series on the science behind the Kallisto software and pseudoalignment: [YouTube](https://www.youtube.com/playlist?list=PL-0S9LiUi0vhjynujVZw34RKmUo6vPmVd).\n</code></pre> <ol> <li> <p>Click the \"Quantification\" step and enter a sample and condition name for each of your samples. You will typically have several replicates (at least 3 minimum) for each sample. For your condition, our implementation of the Kallisto/Sleuth workflow supports two conditions.</p> <p>Warning</p> <pre><code>When naming your samples and conditions, avoid spaces and special\ncharacters (e.g. !#\\$%\\^&amp;/, etc.). Also be sure to be consistent with spelling.\n</code></pre> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: &lt;br&gt;\nWe suggest the following names for this dataset:\n\n| Left/Right Pair | Sample name | Condition |\n| --- | --- | --- |\n| SRR3191542_1.fastq.gz &lt;br&gt; SRR3191542_2.fastq.gz | Mock1-1 | Mock |\n| SRR3191543_1.fastq.gz &lt;br&gt; SRR3191543_1.fastq.gz | Mock2-1 | Mock |\n| SRR3191544_1.fastq.gz &lt;br&gt; SRR3191544_2.fastq.gz | ZIKV1-1 | Zika |\n| SRR3191545_1.fastq.gz &lt;br&gt; SRR3191545_2.fastq.gz | ZIKV2-1 | Zika |\n</code></pre> </li> <li> <p>After naming the samples and conditions, click the <code>Submit</code> button to submit a job. Typically, within ~1 minute you will be provided with a job number. The job will be entered into the queue at the TACC Stampede supercomputing system. You can come back and click the Quantification stop to see the status of the job. The indication for the quantification stop will show \"R\" (running) while the job is running.</p> <p>Sample Data</p> <pre><code>*\"Zika infected hNPCs\"* dataset: Under parameters **uncheck** the *Build pseudo-bam files* option.\n</code></pre> </li> </ol> <p>Tip</p> <pre><code>You can select some of the advanced options for your Kallisto job by clicking the \"Parameters\" link in the Quantification stop. See more about these advanced parameters in the [Kallisto manual](https://pachterlab.github.io/kallisto/manual).\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-visualize-data-using-igv","title":"DNA Subway Green Line: Kallisto/Sleuth- Visualize data using IGV","text":"<p>In the \"View Results\" steps you have access to alignment visualizations, data download, and interactive visualization of your differential expression results.</p> <ol> <li>Click the \"View results\" step and choose one of the following     options:</li> </ol> <p>IVG - Integrated Genome Viewer</p> <p>Tip</p> <pre><code>IGV visualization will only be possible if you have built pseudo-bam\nfiles in the Kallisto step.\n</code></pre> <p>Click the icon in the \"IGV\" column to view a visualization of your reads pseudoaligned to the reference transcriptome. You will need to click the <code>Make it public</code> button (and possibly be re-directed to the CyVerse Discovery Environment). After making the data \"public\" which allows DNA Subway to access your files on the CyVerse Data Store, you must also select a memory size to launch this Java application. If you are not sure of which value to select, use the default 750MB option.</p> <p>Warning</p> <pre><code>Using IGV requires Java software. Java is increasingly unsupported for\nsecurity reasons on the internet.\n</code></pre> <p>Java Help</p> <pre><code>Java must be available and enabled in your Internet browser to use the\nIGV function. Java frequently is the source of security\nvulnerabilities and so its not uncommon to experience configuration\nissues due to safety. Follow the tips below to configure Java for your\ncomputer. Alternatively, you can use the Download link (see\ninstructions in the section below) to download your data (you will\nneed the .bam and .bam.bai files) and download and install yourself.\n\n*Internet Browser*\n\nWe highly recommend using Firefox as your browser for DNA Subway. &lt;br&gt;\n-   Verify your Java availability for your browser: [Java test](https://www.java.com/en/download/installed.jsp) &lt;br&gt;\n-   Java must be [enabled](https://java.com/en/download/help/enable_browser.xml) in your browser\n\n*Java Configuration*\n\n-   Open the Java control panel on your computer. (On Mac, open System\n    Preferences &gt; Java. On PC, open Control Panel &gt; Programs &gt;\n    Java.) &lt;br&gt;\n-   Click the Security tab and check \"Enable Java in the browser\"\n    and set the security level for applications to \"high\". Add\n    \"&lt;http://dnasubway.cyverse.org&gt;\" and \"&lt;http://gfx.dnalc.org&gt;\"\n    to the \"Exception Site List\" in the Java Security tab.\n</code></pre> <p>Download Data - Abundance</p> <p>Click the folder icon to be redirected to the CyVerse Discovery Environment (you may be required to log in). You will be directed to all outputs from you Kallisto analysis. You may preview them in the Discovery Environment or use the path listed to download the files using Cyberduck (see Data Store Guide). A tab-separated file of abundances for each sequence pair is available at the download link.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-green-line-kallistosleuth-visualize-data-using-sleuth","title":"DNA Subway Green Line: Kallisto/Sleuth- Visualize data using Sleuth","text":"<p>Differential analysis - Shiny App</p> <p>Click the \"Sleuth R Shiny\" link to launch an interactive window which contains data and graphics from your analysis.</p> <p>R Shiny App Walkthrough</p> <p>The R Shiny App allows you to explore your differential expression results as generated by the . We will cover highlights to for each menu in the app.</p> Data Transfer Timings <p>It can take a few minutes for data to be transferred to the R Shiny server after the quantification step completes. If R Shiny does not load, try again in a few minutes. If you still have an issue, use the link and include your project number in the feedback form.</p> <p>Results Menu</p> <p></p> <p>This menu is an interactive table of your results. You can choose which columns to display in the table using the checkboxes on the left of the screen. Several important values selected by default include:</p> <ul> <li>Target_id: This is the name of the transcript (gene) from the selected reference transcriptome.</li> <li>qval: This is a corrected (for multiple testing) p-value indicating the significance test of differential abundance. Lower numbers indicate greater significance.</li> <li>b: This is an estimate of the fold change between the conditions</li> <li>ext_gene: If available, these are gene names pulled from Ensemble</li> </ul> <p>Tip</p> <pre><code>Click the `Download`{.interpreted-text role=\"guilabel\"} button to download these results.\n</code></pre> <p>Bootstrap</p> <p></p> <p>This menu will display a box plot that indicates the difference in expression between conditions. The box plots themselves indicate variation between replicates as estimated by bootstrap sampling of the reads. A dropbox enables you to select any transcript. Clicking the \"Show genes\" will load alternative gene names if available.</p> <p>Tip</p> <pre><code>Right-click a graph to download this and other images.\n</code></pre> <p>PCA</p> <p></p> <p>This graph displays principle components of each of the conditions/replicates. In general replicates of the same condition should cluster closely together.</p> <p>Volcano Plot</p> <p></p> <p>This scatter plot displays all transcripts colored by significance of differential abundance. You may also use menu on the left of the screen to highlight specific genes/transcripts or previously set filters from the results menu.</p> <p>Loadings</p> <p></p> <p>This barplot indicates which genes/transcripts explain most of the variance computed in the principle components analysis.</p> <p>Heatmap</p> <p></p> <p>This heatmap gives a measure of the similarity between the possible comparison of the samples and their replicates.</p> <p>Summary: Together, Kallisto and Sleuth are quick, powerful ways to analyze RNA-Seq data.</p>"},{"location":"edu/tutorials/dna_subway_guide/#walkthrough-of-dna-subway-purple-line-beta-testing-documentation","title":"Walkthrough of DNA Subway Purple Line (beta testing documentation)","text":"<p>BETA RELEASE</p> <pre><code>The Purple line is in beta release. Please send feedback to [DNALC Admin](mailto:dnalcadmin@cshl.edu).\n</code></pre> <p>The Purple Line provides the capability for analysis of microbiome and eDNA (environmental DNA) by implementing a simplified version of the QIIME 2 (pronounced \"chime two\") workflow. Using the Purple Line, you can analyze uploaded high throughput sequencing reads to identify species in microbial or environmental DNA samples.</p> <p>Metabarcoding uses high-throughput sequencing to analyze hundreds of thousands of DNA barcodes from complex mixtures of DNA. In a typical experiment, DNA is isolated from sterile swabs or material taken from different environmental locations or conditions. PCR is used to amplify a variable region, such as COI, or 12S or 16S ribosomal RNA genes, and sequence reads identify the variety and abundance of species from different samples. The analysis requires specialized software, such as QIIME 2.</p> <p>The Purple Line integrates sequence data and metadata imported from CyVerse's Data Store, demultiplexing of samples, quality control, and taxonomic identification and quantitation. Once sequences are analyzed, the results can be visualized to allow comparisons between samples and different conditions summarized in the metadata.</p> <p>Some things to remember about the platform</p> <ul> <li>You must be a registered CyVerse user to use Purple Line (register     for a CyVerse account at user.cyverse.org).</li> <li>The Purple line was designed to make microbiome/eDNA data analysis     \"simple\". However, we ask that users very carefully and     thoughtfully decide what \"jobs\" they want to submit.</li> <li>A single Purple Line project may take hours to process since HPC     computing is subject to queues which may support hundreds of other     jobs. These systems also undergo regular maintenance and are subject     to periodic disruption.</li> <li>DNA Subway implements the QIIME 2 software. This software is in continual     development. Our version may not be the most current, and our     documentation and explanation is not meant to replace the full QIIME 2 documentation.</li> <li>We have made design decisions to create a straightforward     classroom-friendly workflow. While this Subway Line does not have     all possible features of QIIME 2, we purpose to cover important     concepts behind microbiome and eDNA analysis.</li> <li>You may work with up to 96 samples (e.g. 192 paired files or 96 single read files) in a Purple line project. </li> </ul> <p>Sample Data: How to use provided sample data</p> <pre><code>In this guide, we will use a microbiome dataset (*\"ubiome-test-data\"*) collected from various\nwater sources in Montana (down-sampled and de-identified).Where\nappropriate, a note (in this orange colored background) in the\ninstructions will indicate which options to select to make use of this\nprovided dataset.\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-metadata-file-and-sequencing-prerequisites","title":"DNA Subway Purple Line - Metadata file and Sequencing Prerequisites","text":"<p>If you are generating data for a project (i.e. sequencing samples), you will need to provide the sequencing data (fastq files) as well as a metadata file that describes the data contained in these sequencing files. This metadata must conform to strict guidelines, or analyses will fail. QIIME 2 metadata is stored in a TSV (tab-separated values) file. These files typically have a .tsv or .txt file extension, though it doesn't matter to QIIME 2 what file extension is used. TSV files are simple text files used to store tabular data, and the format is supported by many types of software, such as editing, importing, and exporting from spreadsheet programs and databases. Thus, it's usually straightforward to manipulate QIIME 2 metadata using the software of your choosing. If in doubt, we recommend using a spreadsheet program such as Microsoft Excel or Google Sheets to edit and export your metadata files.</p> <p>Handling Project Metadata</p> <p>Before you create your project, you will have generated metadata (as described above) for your project. You have two options for preparing this metadata to ensure that it conforms to the required QIIME2 parameters. The file must be validated (which you can do on your own or using Subway). If there are errors in your file (this is common), they must be fixed.</p> <p>Formatting Your Metadata</p> <pre><code>**Leading and trailing whitespace characters**\n\nIf any cell in the metadata contains leading or trailing whitespace\ncharacters (e.g. spaces, tabs), those characters will be ignored when\nthe file is loaded. Thus, leading and trailing whitespace characters\nare not significant, so cells containing the values 'gut' and ' gut' are equivalent. This rule is applied before any other rules\ndescribed below\n\n**ID column**\n\nThe first column MUST be the ID column name (i.e. ID header) and the\nfirst line of this column should be #SampleID or one of a few\nalternative.\n-   Case-insensitive: id; sampleid; sample id; sample-id; featureid;\n    feature id; feature-id.\n-   Case-sensitive: #SampleID; #Sample ID; #OTUID; #OTU ID;\n    sample_name\n\n**Sample IDs**\n\nFor the sample IDs, there are some simple rules to comply with QIIME 2\nrequirements:\n\n-   IDs may consist of any Unicode characters, with the exception\n    that IDs must not start with the pound sign (#), as those rows\n    would be interpreted as comments and ignored. IDs cannot be\n    empty (i.e. they must consist of at least one character).\n-   IDs must be unique (exact string matching is performed to detect\n    duplicates).\n-   At least one ID must be present in the file.\n-   IDs cannot use any of the reserved ID column names (the sample\n    ID names, above).\n-   The ID column can optionally be followed by additional columns\n    defining metadata associated with each sample or feature ID.\n    Metadata files are not required to have additional metadata\n    columns, so a file containing only an ID column is a valid QIIME\n    2 metadata file.\n\n**Column names**\n\n-   May consist of any Unicode characters.\n-   Cannot be empty (i.e. column names must consist of at least one\n    character).\n-   Must be unique (exact string matching is performed to detect\n    duplicates).\n-   Column names cannot use any of the reserved ID column names.\n\n**Column values**\n\n-   May consist of any Unicode characters.\n-   Empty cells represent missing data. Note that cells consisting\n    solely of whitespace characters are also interpreted as missing\n    data.\n\nQIIME 2 currently supports categorical and numeric metadata columns.\nBy default, QIIME 2 will attempt to infer the type of each metadata\ncolumn: if the column consists only of numbers or missing data, the\ncolumn is inferred to be numeric. Otherwise, if the column contains\nany non-numeric values, the column is inferred to be categorical.\nMissing data (i.e. empty cells) are supported in categorical columns\nas well as numeric columns. For more details, and for how to define\nthe nature of the data when needed, see the [QIIME 2 metadata documentation](https://docs.qiime2.org/2019.10/tutorials/metadata/).\n</code></pre> <p>Working with an existing metadata file</p> <p>Tip</p> <p>If you have your own metadata file, it will still need to be validated once uploaded to DNA Subway.</p> <p>Using a spreadsheet editor, create a metadata sheet that provides descriptions of the sequencing files used in your experiment. Export this file as a tab-delimited .txt or .tsv file. following the QIIME 2 metadata documentation](https://docs.qiime2.org/2019.10/tutorials/metadata/) recommendations. (Optional: if you using your own metadata file you can validate it using DNA Subway and or online QIIME2 validator Keemei).</p> <p>Tip</p> <p>See an example metadata file used for our sample data here: metadata file. Click the <code>Download</code> button on the linked page to download and examine the file. (Note: This is an Excel version of the metadata file, you must save Excel files as .TSV (tab-separated) to be compatible with the QIIME 2 workflow.)</p> <p>Creating a metadata file using DNA Subway</p> <p>See DNA Subway Purple Line - Metadata and QC section C.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-create-a-microbiome-analysis-project","title":"DNA Subway Purple Line - Create a Microbiome Analysis Project","text":"<p>A. Create a project in Subway</p> <ol> <li>Log-in to DNA Subway (unregistered users may NOT use Purple Line,     register for a CyVerse account at user.cyverse.org.</li> <li>Click the purple square (\"Microbiome Analysis\") to begin a     project.</li> <li> <p>For 'Select Project Type' select either Single End Reads or     Paired End Reads</p> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: Select **Single End Reads**\n</code></pre> <ol> <li>For 'Select File Format' select the format the corresponds to  your sequence metadata.</li> </ol> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: Select **Illumina Casava 1.8**\n</code></pre> <p>Tip</p> <pre><code>Typically, microbiome/eDNA will be in the form of multiplexed FastQ sequences. We support the following formats:\n\n- [Illumina Casava 1.8](http://illumina.bioinfo.ucr.edu/ht/documentation/data-analysis-docs/CASAVA-FASTQ.pdf/at_download/file)\n</code></pre> <ol> <li>Enter a project title, and description; click <code>Continue</code>.</li> </ol> </li> </ol> <p>B. Upload read data to CyVerse Data Store</p> <p>The sequence read files used in these experiments are too large to upload using the Subway interface. You must upload your files (Note: Only <code>.fastq.gz</code> files are accepted) directly to the CyVerse Data Store:</p> <ol> <li>Upload your<ul> <li>FASTQ sequence reads; Note: Only <code>.fastq.gz</code> files are accepted. </li> <li>Sample metadata file (.tsv or .txt formatted according to QIIME 2 Metadata documentation) to     the CyVerse Data Store using Cyberduck. See instructions: CyVerse Data Store Guide.</li> </ul> </li> </ol> <p>(Optional: You can edit and change metadata using the Subway interface in the [Manage data]step once the project is created.)</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-metadata-and-qc","title":"DNA Subway Purple Line - Metadata and QC","text":"<p>A. Select files using Manage Data</p> <ol> <li> <p>Click on the 'Manage data stop: this opens a window where you can     add your FASTQ (up to 192 paired files or 96 single read files) and metadata files. Click     <code>+Add from CyVerse</code> to add the     FASTQ files uploaded to the CyVerse Data Store. Select your files     and then click <code>Add selected files</code>{.interpreted-text     role=\"guilabel\"} or <code>Add all FASTQ files in this directory</code>{.interpreted-text     role=\"guilabel\"} as appropriate. Note: Only <code>.fastq.gz</code> files are accepted. </p> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: Navigate to: Shared Data &gt; SEPA_microbiome_2016 &gt; **ubiome-test-data** and click `Add all FASTQ files in this directory`{.interpreted-text role=\"guilabel\"}\n</code></pre> </li> </ol> <p>2.  To add your metadata file you may use one of three options: -   Add from CyVerse: Add a metadata file you have uploaded to CyVerse Data store -   Upload locally: Directly upload a metadata file from your local computer -   Create New: Create a new metadata file using DNA Subway</p> <p>Creating a metadata file using DNA Subway</p> <pre><code>You can create a metadata file using DNA Subway. Creating the file\nstep-by-step will help you to avoid metadata errors. Be sure you\nhave consulted the [QIIME 2 documentation](https://docs.qiime2.org/2019.10/tutorials/metadata/) so you can anticipate what the required fields\nare. To use this feature under in the 'Manage data' step under\n'Metadata Files' click `Create new`{.interpreted-text role=\"guilabel\"}\n\n**Sample IDs and adding/removing samples**\n\nThese are unique IDs for each of your samples.\nAll metadata files must have a column called **#SampleID**. Click\n`+Add samples`{.interpreted-text role=\"guilabel\"} to add additional\nrows. In the Subway form, these will be unique, arbitrary names\n(roughly corresponding to well-positions on a 96-well microplate).\nYou can change these (including pasting in sample names from an\nexisting spreadsheet).\n\n![metadata_add_samples](./assets/dna_subway/metadata_add_samples.gif){width=\"450px\" height=\"250px\"}\n\nRight-clicking on a row number allows you to remove or insert rows.\n\n![metadata_rows](./assets/dna_subway/metadata_rows.gif){width=\"450px\" height=\"250px\"}\n\n**Adding columns, managing sample descriptions and data types**\n\nThe very **last** column must be a sample description. You can click\nthe arrow on the right of this column to add a new column (which\nwill be added to the left). Column names must be unique, must not be\nempty, cannot contain whitespace, can contain a maximum of 32\ncharacters, cannot match a reserved column name. Notice that when\nyou click on a column name it is colored -pink for columns that have\nnumeric data (e.g. measurements) and cyan for everything else (e.g.\ncategorical descriptions in the form of words (i.e. strings)).\nClicking a column name will allow you to change its type.\n\n![metadata_add_column](./assets/dna_subway/metadata_add_column.gif){width=\"450px\" height=\"250px\"}\n\n**Handling errors**\n\nIf you violate one of the rules for metadata formatting, the entry\nwill turn red. Consult the help and or the [QIIME 2 documentation](https://docs.qiime2.org/2019.10/tutorials/metadata/) to correct the error.\n\n![metadata_error](./assets/dna_subway/metadata_error.gif){width=\"450px\" height=\"250px\"}\n\nClick `Save`{.interpreted-text role=\"guilabel\"} to save your\nmetadata file, and close the window.\n</code></pre> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: &lt;br&gt;\nClick `Add from CyVerse`{.interpreted-text role=\"guilabel\"}Navigate to: Shared Data &gt; SEPA_microbiome_2016 &gt; **ubiome-test-data**\nSelect the **mappingfile_MT_corrected.tsv** and then click `Add selected files`{.interpreted-text role=\"guilabel\"}.\n</code></pre> <p>3.  As needed, you can edit or rename your metadata file. Before     proceeding, you must validate your metadata file. To validate,     click the \"validate\" link to the right of the metadata file you     wish to check. Once the validation completed, click <code>Run</code> to proceed. If you have     errors, you will be presented with an <code>Edit</code> button so that you can return to the file and     edit.</p> <p>B. Demultiplex reads</p> <p>At this step, reads will be grouped according to the sample metadata. This includes separating reads according to their index sequences if this was not done prior to running the Purple Line. For demultiplexing based on index sequences, the index sequences must be defined in the metadata file.</p> <p>Note</p> <pre><code>Even if your files were previously demultimplexed (as will generally\nbe the case with Illumina data) you must still complete this step to\nhave your sequence read files appropriately associated with metadata.\n</code></pre> <p>1. Click the 'Demultiplex reads' and choose a number of reads to sample. When the job has completed click Demultiplexing Summary to view your results. In 'Random sequences to sample for QC', enter a value (1000 is recommended),</p> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: Use the default of 1000 sequences\n</code></pre> <p>2. When demultiplexing is complete, you will generate a file (.qzv) click this link to view a visualization and statistics on the sequence and metadata for this project.</p> <p>Tip</p> <pre><code>Several jobs on Purple Line will take several minutes to an hour\nto complete. Each time you launch one of these steps you will get\na Job ID. You can click the `View job info`{.interpreted-text\nrole=\"guilabel\"} button to see a detailed status and\ndiagnostic/error messages. If needed There is a [stop this job]{.title-ref} link at the bottom of the info page to cancel a\njob.\n\n!!! Note\n\n        **QIIME2 Visualizations**\n\n        One of the features of QIIME 2 are the variety of visualizations\n        provided at several analysis steps. Although this guide will not\n        cover every feature of every visualization, here are some\n        important points to note.\n\n        **QIIME2 View**: DNA Subway uses the QIIME 2 View plugin to\n        display visualizations. Like the standalone QIIME 2\n        software, you can navigate menus, and interact with several\n        visualizations. Importantly, many files and visualizations\n        can be directly download for your use outside of DNA Subway,\n        including in report generation, or in your custom QIIME 2\n        analyses. You can view downloaded .qza or .qzv files at [view.qiime2.org](https://view.qiime2.org/).\n</code></pre> <p>Quality Graphs Explained</p> <pre><code>After demultiplexing, you will be presented with a visualization\nthat displays the following tables and graphs:\n\n**Overview Tab**\n\n-   *Demultiplexed sequence counts summary*: For each of the\n    fastq files (each of which may generally correspond to a\n    single sample), you are presented with comparative\n    statistics on the number of sequences present. This is\n    followed by a histogram that plots number of sequences by\n    the number of samples. &lt;br&gt;\n-   *Per-sample sequence counts*: These are the actual counts\n    of sequences per sample as indicated by the sample names\n    you provided in your metadata sheet.\n\n![overview_tab](./assets/dna_subway/overview_tab.gif){width=\"450px\" height=\"250px\"}\n\n**Interactive Quality Plot**\n\nThis is an interactive plot that gives you an average quality\n(y-axis) by the position along the read (x-axis). This box plot\nis derived from a random sampling of a subset of sequences. The\nnumber of sequences sampled will be indicated in the plot\ncaption. You can use your mouse drag and zoom in to regions on\nthe plot. Double-click your mouse to zoom out.\n\n![quality_plot](./assets/dna_subway/quality_plot.gif){width=\"450px\" height=\"250px\"}\n</code></pre> <p>3. Click the \"Interactive Quality Plot\" tab to view a histogram of sequence quality. Use this plot at the tip below to determine a location to trim.</p> <p>Tips on trimming for sequence quality</p> <pre><code>On the Interactive Quality Plot you are shown an histogram, plotting\nthe average quality (x axis) [Phred score](https://en.wikipedia.org/wiki/Phred_quality_score) vs. the position on the read (y axis) in base pairs for a **subsample** of reads.\n\n**Zooming to determine 3' trim location**\n\nClick and drag your mouse around a collection of base pair positions\nyou wish to examine. Clicking on a given histogram bar will also\ngenerate a text report and metrics in the table below the chart. Using\nthese metrics, you can choose a position to trim on the right side\n(e.g. 3' end of the sequence read). The 5' (left trim) is specific\nto your choice of primers and sequencing adaptors (e.g. the sum of the\nadaptor sequence you expect to be attached to the 5' end of the\nread). Poor quality metrics will generate a table colored in red, and\nthose base positions will also be colored red in the histogram.\nDouble-clicking will return the histogram to its original level of\nzoom.\n\n**Example plots**\nIt is important to maximize the length of the reads while minimizing\nthe use of low quality base calls. To this end, a good guideline is to\ntrim the right end of reads to a length where the 25th percentile is\nat a quality score of 25 or more. However, the length of trimming will\ndepend on the quality of the sequence, so you may have to use a lower\nquality threshold to retain enough sequence for informative sequence\nsearches and alignments. This may require multiple runs of the\nanalysis to find the optimal trim length for your data.\n\n*Quality drops significantly at base 35*\n\n![histogram_poor](./assets/dna_subway/histogram_poor.png){width=\"400px\" height=\"250px\"}\n\n*Improved quality sequence*\n\n![histogram_good](./assets/dna_subway/histogram_good.png){width=\"400px\" height=\"250px\"}\n</code></pre> <p>C. Use DADA2 for Trimming and Error-correction of Reads</p> <p>It is important to only work with high quality data. This step will generate a sequence quality histogram which can be used to determine parameter for trimming.</p> <ol> <li> <p>Click 'DADA2' and choose the metadata file corresponding to the     samples you wish to analyze. Then choose values for trimming of     the reads. For \"trimLeft\" (the position starting from the left     you wish to trim) and \"TruncLen\" (this is the position where     reads should be trimmed, truncating the 3' end of the read. Reads     shorter than this length will be discarded). Finally, click     <code>Trim reads</code>.</p> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: Based on the histogram for our sample, we recommend the following parameters:\n\n-   **trimLeft: 17** (this is specific to primers and adaptors in\n    this experiment)\n-   **TruncLen: 200** (this is where low quality sequence begins, in\n    this case because our sequence length is lower than the expected\n    read length)\n</code></pre> </li> </ol> <p>D. Check Results of Trimming Once trimming is complete, the following outputs are expected:</p> <ol> <li> <p>Click on DADA2 and then click on the links in the Results table     to examine results.</p> </li> <li> <p>Trim Table (Metric summary, Frequency per sample,     Frequency per feature): Summarizes the dataset post-trimming     including the number of samples and the number of features per     sample. The \"Interactive Sample Detail\" tab contains a sampling     depth tool that will be used in computation of the core matrix.</p> <p>Note</p> <pre><code>**You will use the maximum frequency value for the Alpha\nrarefaction step** So you may wish to record this value now for\nthe DNA Subway 'Clustering sequences' step.\n</code></pre> </li> <li> <p>Stats: Sequencing statistics for each of the sample IDs     described in the original metadata file.</p> </li> <li>Representative Sequences (Sequence Length Statistics,     Seven-Number Summary of Sequence Lengths, Sequence Table):     This table contains a listing of features observed in the sequence     data, as well as the DNA sequence that defines a feature. Clicking     on the DNA sequence will submit that sequence for BLAST at NCBI in     a separate browser tab.</li> </ol> <p>The feature table contains two columns output by DADA2. DADA2 (Divisive Amplicon Denoising Algorithm 2) determines what sequences are in the samples. DADA2 filters the sequences and identifies probable amplification or sequencing errors, filters out chimeric reads, and can pair forward and reverse reads to create the best representation of the sequences actually found in the samples and eliminating erroneous sequences.</p> <ul> <li>Feature ID: A unique identifier for sequences.</li> <li>Sequence: A DNA Sequence associated with each identifier.</li> </ul> <p>Clicking on any given sequence will initiate at BLAST search on the NCBI website. Click \"View report\" on the BLAST search that opens in a new web browser tab to obtain your results. Keep in mind that if your sequences are short (due to read length or trimming) many BLAST searches may not return significant results.</p> <p>Tip</p> <pre><code>Although the term \"feature\" can (unfortunately) [have many meanings](https://forum.qiime2.org/t/what-is-a-feature-exactly/2201) as used by the\nQIIME2 documentation, unless otherwise noted in this documentation\nit can be thought of as an OTU ([Operational Taxonomic Unit](https://en.wikipedia.org/wiki/Operational_taxonomic_unit)); another substitution for the word\nspecies. OTU is a convenient and common terminology for referring to\nan unclassified or undetermined species. Ultimately, we are\nattempting to identify an organism from a sample of DNA which may\nnot be informative enough to reach a definitive conclusion.\n</code></pre> <p>Tip</p> <pre><code>If you want to redo the DADA2 step with different parameters, click\nthe \"New Job\" tab on the upper left of a DADA2 window to submit a\nnew job. New jobs appear as tabs on Subway steps that are typically\nrun several times. You can go back an see these jobs which are\nlabeled with a job number.\n\n![dada_tabs](./assets/dna_subway/dada_tabs.gif){width=\"450px\" height=\"250px\"}\n</code></pre>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-alpha-rarefactionclustering-sequences","title":"DNA Subway Purple Line - Alpha Rarefaction/Clustering Sequences","text":"<p>A. Alpha rarefaction</p> <p>At this step, you can visualize summaries of the data. A feature table will generate summary statistics, including how many sequences are associated with each sample. Note that sample depth is limited to 100,000.</p> <ol> <li>Click on 'Alpha rarefaction'. Select \"run\" and designate the     minimum and maximum rarefaction depth. A minimum value should be     set at 1. The maximum value is specific to your data set. The     maximum value is specific to your data set. To determine what the     maximum value should be set to, open the \"Trim Table\" from the     \"DADA2\" step. You may not choose a value that is greater than     the maximum frequency per sample. In general, choosing a value     that is somewhere around the median frequency seems to work well,     but you may want to increase that value if the lines in the     resulting rarefaction plot don't appear to be leveling out, or     decrease that value if you seem to be losing many of your samples     due to low total frequencies closer to the minimum sampling depth     than the maximum sampling depth. Identify the maximum Sequence     Count value and enter that number as the maximum value. Click     <code>Submit Job</code>.</li> </ol> <p>Note</p> <pre><code>Since you may want to try Alpha rarefaction using different\ncombinations of results from DADA2 trimming and your choice of\nrarefaction depths, your trim (DADA2) jobs are displayed on the\nleft, and each new Alpha rarefaction setting will appear as a tab on\nthe top.\n\n![alpha_tabs](./assets/dna_subway/alpha_tabs.gif){width=\"450px\" height=\"250px\"}\n</code></pre> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset: \nWe recommend the following parameters:\n\n-   **Min. rarefaction depth**: 1\n\n-   **Max. rarefaction depth**: 2938\n</code></pre> <ol> <li>Under 'Results' click on Alpha Rarefaction Plot to view the results.</li> </ol> Navigating Alpha Rarefaction graphs <p>Alpha rarefaction generates an interactive plot of species diversity by sampling depth by the categorical samplings described in your sample metadata. You can use dropdown menus to change metrics/conditions displayed and also export data as a CSV file.</p> <p></p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-calculate-core-metricsalpha-and-beta-diversity","title":"DNA Subway Purple Line - Calculate Core Metrics/Alpha and Beta Diversity","text":"<p>At this stop, you will examine Alpha Diversity (the diversity of species/taxa present within a single sample) and Beta Diversity (a comparison of species/taxa diversity between two or more samples).</p> <ul> <li>Alpha diversity answers the question - \"How many species are in a     sample?\"</li> <li>Beta diversity answer the question - \"What are the differences in     species between samples?\"</li> </ul> <p>A. Calculate core metrics</p> <ol> <li>Click on 'Core metrics' and then click the \"run\" link. Choose     a sampling depth based upon the \"Sampling depth\" tool (described     in Section D Step 1, in the Trim Table output; Interactive     Sample Detail tab). Choose an appropriate classifier (see     comments in the tip below) and click <code>Submit job</code>.</li> </ol> <p>Choosing Core metrics parameters</p> <pre><code>*Sampling Depth*\n\nIn downstream steps, you will need to choose a sampling depth for\nyour sample comparisons. You can choose by examining the table\ngenerated at the **Trim reads** step. In the *Trim Table* output,\n*Interactive Sample Detail* tab, use the \"Sampling depth\" tool to\nexplore how many sequences can be sampled during the Core matrix\ncomputation. As you slide the bar to the right, more sequences are\nsampled, but samples that do not have this many sequences will be\nremoved during analysis. The sampling depth affects the number of\nsequences that will be analyzed for taxonomy in later steps: as the\nsampling depth increases, a greater representation of the sequences\nwill be analyzed. However, high sampling depth could exclude\nimportant samples, so a balance between depth and retaining samples\nin the analysis must be found.\n\n*Classifier*\n\nChoose a classifier pertaining to your experiment type.\n\n-   **Microbiome** choose **Greengenes (515F/806R)** or **Greengenes\n    (full sequences)** or **Sliva (16S rRNA)** classifier\n-   **eDNA** experiment with marine fishes you may elect to choose\n    the **Fish 12S/ecoPrimer** classifier\n</code></pre> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset:\nWe recommend the following parameters:\n\n-   **Sampling Depth**: 3000\n\n-   **Classifier**: Grenegenes (full sequences)\n</code></pre> <p>B. Examine alpha and beta diversity</p> <ol> <li> <p>When core metrics is complete, you should generate several     visualization results. Click each of the following to get access:</p> <ul> <li> <p>Alpha Diversity:</p> <ul> <li> <p>Pielou's Evenness</p> <ul> <li> <p>Alpha Correlation: Measure of community evenness using correlation tests</p> </li> <li> <p>Group Significance: Analysis of differences between features across group</p> </li> </ul> </li> <li> <p>Faith's Phylogenetic Diversity</p> <ul> <li> <p>Alpha Correlation: Faith Phylogenetic Diversity (a measure of community richness) with correlation tests</p> </li> <li> <p>Group Significance: Faith Phylogenetic Diversity ( a measure of community richness)</p> </li> </ul> </li> </ul> </li> <li> <p>Beta Diversity:</p> <ul> <li> <p>Bray-Curtis Distance</p> <p>Bray-Curtis is a metric for describing the dissimilarity of species in an ecological sampling. -   Bioenv: Bray-Curtis test metrics</p> <ul> <li>Emperor: Interactive PCoA plot of Bray-Curtis metrics</li> </ul> </li> <li> <p>Jaccard Distance</p> <ul> <li>Emperor: Interactive PCoA plot calculated by Jaccard similarity index.</li> </ul> </li> <li> <p>Unweighted UniFrac Distance</p> <p>UniFrac is a metric for describing the similarity of a biological community, taking into account the relatedness of community members.</p> <ul> <li> <p>Bioenv: UniFrac test metrics</p> </li> <li> <p>Emperor: Unweighted interactive PCoA plot</p> </li> </ul> </li> <li> <p>Weighted UniFrac Distance </p> <p>Unweighted UniFrac removes the effect of low-abundance features in the calculation of principal components.</p> <ul> <li>Emperor: Weighted interactive PCoA plot of UniFrac.</li> </ul> </li> </ul> </li> </ul> </li> </ol> <p>Tip</p> <pre><code>**Emperor Plots**\n\nThese plots are all interactive three-dimensional plots of an\nanalysis using [principal components](https://en.wikipedia.org/wiki/Principal_component_analysis).\n\n**Customization**\n\nYou can customize Emperor plots, including altering the color of\nand shape points, axes, and other parameters. You can also export\nimages from this visualization.\n\n![emperor_plots](./assets/dna_subway/emperor_plots.gif){width=\"550px\" height=\"300px\"}\n\n**Bioenv**\n\nThese plots are tables of tests and descriptive metrics.\n</code></pre> <p>C. Taxonomic Diversity:</p> <p>Taxonomic diversity is at the heart of many analyses. We suggest consulting the QIIME taxonomy overview for a detailed explanation of how QIIME2 calculates taxonomy and additional features of QIIME2 you may wish to explore beyond the functionalities DNA Subway has included.</p> <ul> <li> <p>Bar Plots</p> <ul> <li> <p>An interactive stacked bar plot of species diversity.     Dropdown menus allow you to color by seven taxonomic     levels 1) kingdom, 2) phylum,     3) class, 4) order, 5), family, 6) genus, 7) species. Plots      can be further arranged/filtered/sorted accoridng to      characteristics in the sample metadata. You may also      download images and data used to create the barpot      visualization.</p> <p></p> </li> </ul> </li> <li> <p>Taxonomy</p> <ul> <li>A table indicating the identified \"features\", their taxa,      and an indication of confidence.</li> </ul> </li> </ul> <p>You can download and interact with any of the available plots.</p> <p>D. Calculate differential abundance</p> <ol> <li>Click on the 'Differential abundance' stop. Then click on the     \"Submit new \"Differential abundance\" job\" link. Choose a     metadata category to group by, and a level of taxonomy to     summarize by. Then click <code>&amp;submit job</code>{.interpreted-text     role=\"guilabel\"}.</li> </ol> <p>Sample Data</p> <pre><code>*\"ubiome-test-data\"* dataset:\n\nWe recommend the following parameters:\n\n-   **Group data by**: CollectionMethod\n\n-   **Level of taxonomy to summarize**: 5\n</code></pre> <p>Tip</p> <p>Download the provided CSV files so that you can generate customized plots.</p>"},{"location":"edu/tutorials/dna_subway_guide/#dna-subway-purple-line-visualize-data-with-picrust-and-phyloseq","title":"DNA Subway Purple Line - Visualize data with PiCrust and PhyloSeq","text":"<p>Under Development</p>"},{"location":"edu/workshops/","title":"Current Offerings","text":"<p>CyVerse's popular in-person and virtual trainings are intensive, providing hands-on learning and application of cutting edge, open source technologies. Come with questions, leave with solutions.</p>"},{"location":"edu/workshops/#professional-education-series","title":"Professional Education Series","text":"Workshop Info &amp; Reg What's Covered Container Camp (Basic) Website Syllabus Cloud Native Camp (Advanced) Website Syllabus Foundational Open Science Skills workshops Website Syllabus"},{"location":"edu/workshops/#teach-your-workshops-on-our-resources","title":"Teach your Workshops on our resources","text":"<p>Cyverse also helps facilitate external workshops through the User Portal</p> <p>Request a Workshop sign-up form be here</p> <p>You can request a workshop that uses specific CyVerse platforms like the Data Store, the Discovery Environment, or CACAO and Jetstream-2.</p> <p>By using the form, your students will be automatically granted access to these platforms when they enroll.</p> <p>Read more detailed instructions on setting up a class or workshop.</p> <p>Questions? Email us!</p>"},{"location":"edu/workshops/container_camp/","title":"Container Camp","text":"<p>CyVerse teaches in-person and virtual workshops on the use of software containers for scientific research. </p> <p>Currently, we teach both a 'beginning' and 'advanced' format for new and advanced users. Introductory camps are offered prior to advanced camps to allow users to level up or refresh their container skills.</p> <p>View the schedule and sign up for the next camp here: Container Camp Announcements</p> Name Dates Description Container Camp 2023 Advanced Aug 16-18 2023 Virtual Container Camp 2023 Basics Mar 6-9, 2023 Virtual Container Camp 2022 May 12-19, 2022 in-person &amp; Virtual Container Camp 2021 Advanced Aug 2-4, 2021 Virtual Camp Container Camp 2021 Basics July 26-28, 2021 Virtual Camp Container Camp 2020 Mar 10-13, 2020 Third camp, in person at UArizona Container Camp 2019 Mar 6-8 2019 Second camp, in person at UArizona Container Camp 2018 Mar 7-9, 2018 First camp, in person at UArizona"},{"location":"edu/workshops/foss/","title":"Foundational Open Science Skills","text":"<p>Fall 2024 FOSS workshop will be virtual on Thursdays 11:00AM - 1:00PM US Arizona Mountain Standard Time starting Sept. 5, 2024</p> <p>CyVerse's 12-week virtual workshop teaches you the principles, practices, and how-tos for doing collaborative open science using cutting-edge, open source cyberinfrastructure. </p> <p>To see how our FOSS workshop can support your work, check out the workshop curriculum over the years: </p> Name Dates Description Fall FOSS 2024 Sept. 5 - Nov. 21, 2024 Eighth virtual workshop series Spring FOSS 2024 Jan. 25 - March 14, 2024 Seventh virtual workshop series Fall FOSS 2023 Sept. 7 - Nov. 2, 2023 Sixth virtual workshop series Spring FOSS 2023 Jan 19 - Mar 30, 2023 Fifth virtual workshop series Fall FOSS 2022 Sept 15 - Nov 18, 2022 Fourth virtual workshop series Fall FOSS 2021 Sept 7 - Nov 18, 2021 Third virtual workshop series Spring FOSS 2021 Feb 9 - Apr 21, 2021 Second virtual workshop series Summer FOSS 2020 July 28 - Nov 3, 2020 First virtual workshop series Spring FOSS 2020 Feb 17 - 21, 2020 Second in-person workshop at UArizona Spring FOSS 2019 Jun 3-7, 2019 First in-person workshop at UArizona"},{"location":"home/account/","title":"Setting Up your CyVerse Account","text":"<p>To use CyVerse's platforms, you will need to create an account.</p> <p>Here's how to do so:</p> <p> Go to the User Portal to begin the registration process. </p> <p>You will be asked to enter voluntary demographic information about yourself, your contact info, and what you want to use CyVerse for.</p> <p>Also, please add your ORCID https://orcid.org to your CyVerse User Profile. If you don't have an ORCID get one today!</p> <p>Entering demographic information is not a requirement.</p> <p>Avoid signing up with a personal <code>@gmail.com</code> <code>@hotmail.com</code> or private email server if possible</p> <p>CyVerse staff approve every user registration. We receive dozens of spam requests every day.  </p> <p>We strongly recommended that you use an institutional email address:<code>.edu</code>, <code>.org</code>, or <code>.gov</code> if possible. This will speed the approval process for access to certain CyVerse platforms.</p> <p>Email accounts that have computer generated user names, i.e. <code>student1234@qq.com</code>, are from foreign IP addresses, or use free email services, like <code>qq.com</code>, <code>hotmail.com</code>, or <code>gmail.com</code> will be scrutinized and may be rejected. </p> <p>Complete the registration process.</p> <p>Make sure to set your email address and user password before exiting the User Portal account creation wizard.</p> <p>In order to reset a password, you will need to have created one in the first place.</p> <p>In order to receive a password reset request, you will need to have access to the email account you signed up with.</p> <p> Check your email for an account confirmation link and follow the confirmation instructions.</p> <p>Once you have confirmed your email address, you can start using your CyVerse account immediately!</p> <p>Pop-up-blockers</p> <p>When signing up for an account, be sure that Java Script is enabled on your web browser and that any pop-up blockers are disabled.</p> <p></p> <p>Check-your-spam folder</p> <p>Check your SPAM folder for the confirmation email if it does not arrive within a few minutes.</p>"},{"location":"home/account/#request-other-services","title":"Request Other Services","text":"<p>New basic account holders will have immediate access to the Discovery Environment https://de.cyverse.org, and Data Store.</p> <p>To register for other services and platforms, login to the User Portal's dashboard. Under \"My Services\" click the 'Request Access' button next to the service(s) you would like to access. You will receive an email notification when the service is added; this may take up to 24 hours.</p>"},{"location":"home/account/#account-types","title":"Account Types","text":"<p>CyVerse financial sustainability model now includes a tiered subscription service where individuals can use free 'basic' tiered services for a limited amount of time.</p> <p>To leverage CyVerse for research or education, you must:</p> <p>(1) purchase an individual subscription (see table below), </p> <p>(2) connect with us to develop an Institutional agreement (see Professional Services or Powered By), </p> <p>(3) are part of a funded research project which has an existing Professional Services agreement with CyVerse. </p> <p>(4) are a current student or a faculty member at an Institution CyVerse is currently serving (specifically, the University of Arizona).</p>"},{"location":"home/account/#individual-subscriptions","title":"Individual Subscriptions","text":"<p>In order to purchase an individual CyVerse subscription, please see Subscribe</p> <p>Table: CyVerse Individual Subscription Tiers (Spring 2025)</p> Service Basic (Free) Regular Pro Commercial Discovery Environment Yes Yes Yes Yes Data Store Yes Yes Yes Yes Advanced Features &amp; APIs - - Yes Yes Data Storage Limit 5 GB 50 GB 4 TB 7 TB Compute Units / Year* 200 1,000 25,000 250,000 Access to GPU** - - contact us contact us Concurrent Jobs 1 2 4 8 Sharing Data &amp; Apps None 100 Unlimited Unlimited Community Released Data Folder Requests None Yes  Yes Yes DOI for Data None 5 10 20 Workshop Requests - - 4 8 Webinar Access Yes Yes Yes Yes Support Email In-App Chat Screen Share Support Screen Share Support Price / Year Free $200 $400 $2,400 <p>Teaching with CyVerse</p> <p>CyVerse was built as a free to use, open source cyberinfrastructure project for everyone to use. It is a privilege to offer access to the most cutting edge data science tools and computing environments in the world to students from the most under resourced and under served corners of our country with the worst internet connections.</p> <p>Free \"basic\" account holders are intended to be undergraduates or continuing education students. The \"basic\" account comes with enough computing hours in the Discovery Environment for a student to complete two semester's worth (one academic year) of a courses computational assignments.</p> <p>Students should be mindful of their allocation hours and use them conservatively. Analyses should not be left idle or running overnight when not in use, as they take away from the shared resource pool, and they rapidly deplete a student's free account.</p> <p>Teachers should purchase a \"Pro\" or \"Commericial\" subscription, so that they can share data with their students, and request a Community Release folder, if need be. </p>"},{"location":"home/account/#professional-services","title":"Professional Services","text":"<p>For over a decade CyVerse has partnered with other universities, private companies, and governmental and non-govermental organizations to provide services.</p>"},{"location":"home/account/#powered-by-cyverse","title":"Powered-by CyVerse","text":"<p>Organizations may be interested in leveraging parts of CyVerse software stack or cyberinfrastructure for their own clouds, gateways, or projects.</p> <p>Partnerships with CyVerse for Centers, Institutes, and Large Projects are managed through our Powered-by project documentation.</p>"},{"location":"home/faq/","title":"Frequently Asked Questions","text":""},{"location":"home/faq/#user-account","title":"User Account","text":"How do I update my account information? <p>CyVerse users should update their account information annually for continued access to services. To update, go to the CyVerse User Portal, log in, and click the account icon in the upper right corner.</p> <p>In addition to updating your email, institution, occupation, preferences and other information that may have changed, please add your ORCID ID, a unique identifier which can help you receive credit for your work. Get an ORCID here https://orcid.org/register.</p> <p>By keeping your account information current, our funders can see the value of CyVerse to our community and we learn which of our services and platforms are most helpful to you.</p>"},{"location":"home/faq/#data","title":"Data","text":"What if I need more space (storage) in the Data Store? <p>Every user has a 5GB allocation in the Data Store.  Please see information on storage allocations for CyVerse's subscription tiers .</p> How do I publish a large set of public data? <p>If you need assistance transferring a large dataset to CyVerse, please contact CyVerse Support (support@cyverse.org or use the blue chat icon at the bottom right). </p> <p>For more information on our policies, see CyVerse's Collaboration Policy  and Data Management Policy . </p> <p>For more information on using data at CyVerse, see the Learning Center documentation on working with data.</p> What public datasets are in CyVerse? <p>CyVerse provides web access to its public datasets via WebDav https://data.cyverse.org </p> <p>Public datasets in CyVerse may also be accessed through the Discovery Environment, Atmosphere, the Science APIs and iCommands. </p> <p>For more information on using public data at CyVerse, see the Learning Center documentation pages on HTTP Access with WebDAV.</p> How do I request a Community Released Data Folder? <p>Community Released Data folders are available for evolving datasets that individuals or communities want to make available as quickly as possible for research and reuse, especially within CyVerse analysis platforms. </p> <p>Community Released Data folders are intended for datasets that are growing or changing frequently or that may not need long-term preservation.</p> <p>Before requesting a folder, please read this wiki article on publishing data through the Data Commons, and this one on preparing community-released data folders.</p> <p>Then, if you meet the criteria, you can request a folder using this form.</p> How do I connect to a shared or public folder with CyberDuck? <p>See our using CyberDuck documentation.</p> How do I open a connection to a private folder that is shared with me? <p>See our using the Data Store documentation.</p> How do I make a folder public with iCommands? <p>Although you can share files and folders in the DE and create public links, you must use iCommands make them visible to everyone. Permissions are set in iCommands by using <code>ichmod</code> (https://docs.irods.org/4.2.1/icommands/user/#ichmod){target=_blank} .</p> <p>To make a folder public, you must give read permission to two users: 'public' (anyone signed in with a CyVerse account) and 'anonymous' (anyone on the web - no log in required). To recursively make a shared folder called 'myfolder' public, use the instructions below.</p> <pre><code>ichmod -r read public /iplant/home/shared/myfolder\nichmod -r read anonymous /iplant/home/shared/myfolder\n</code></pre> <p>To remove public access to the folder, use:</p> <pre><code>ichmod -r null public /iplant/home/shared/myfolder\nichmod -r null anonymous /iplant/home/shared/myfolder\n</code></pre> When sharing a file or folder, what permission should I give to my collaborator? <p>It depends on what you want to allow the collaborator to do with the file or folder. Options are:  read, write (ability to edit the file or folder), and own (in addition to edit, can also delete and move; use this permission with caution). Learn more here .</p> Why can't I rename or delete files in a folder that has been shared with me? <p>To rename a file or folder, you must have \"write\" permission, and to delete a file you must have \"own\" permission. To check the permission you have, click the checkbox for the item and look at the Permissions shown in the Details panel on the right. Contact the person who shared the file or folder with you if they did not give you the necessary level of permission. Learn more at Changing and Viewing Data Permission Levels in the DE.</p> How can I manage shared files and folders for my lab group or project? <p>See Setting Up a Shared Directory for a Lab or Project .</p> Why doesn't anything happen when I move a folder I own to the Trash? <p>If a folder has hundreds of files, it can take several hours for the deletion to complete in the DE. Please be patient and try refreshing your browser periodically. You cannot delete 1000 files or more in the DE. You must use iCommands  instead. Note that deleted files may still show up in the search for awhile, but eventually deleted files will be fully purged from the system.</p> Can I have spaces in file and folder names? <p>No. Do not use spaces or special characters in file or folder names as they can cause analyses to fail. Learn more here .</p> Can I view my files in a genome browser? <p>You can view bam, vcf, and gff genome files you own in the genome browsers at Ensembl, UCSC, IGV, GBrowse, and jbrowse, and view Fasta genome files in CoGe. Learn more about viewing genome files in a genome browser  or in CoGe .</p>"},{"location":"home/faq/#apps-and-analyses","title":"Apps and Analyses","text":"Why has my job failed or been running forever? <p>The following recommendations can help you determine what went wrong and collect information for CyVerse staff in case you cannot resolve the problem yourself.</p> <p>Common things to check when troubleshooting an analysis</p> <ul> <li>View the app's parameters to make sure you used the correct input     files and settings.</li> <li>Read through the app's documentation page.</li> <li>It also may be helpful to read through documentation about the     tool that was used to create the app. Check the app's     documentation page to see if a link was provided. If no link was     provided, you can find specifics about the tool that was used and     search for more information on the web.</li> <li>Avoid the use of special characters and spaces in analysis names,     file names, and folder names when submitting an analysis through     the DE (e.g., ~ ` ! @ # $ % ^ &amp; * ( ) + = { } [ ] |  : ;     \" ' &lt; , ? / and spaces).</li> </ul> <p>Getting Help with an analysis</p> <p>If you know that an analysis typically completes in 20 minutes but you have one that still shows Running status 24 hours after you submitted it, the app used for the analysis seems to have a problem, or you didn't get any output files or the output files were not what you expected, you can submit a request for help directly in the Analyses window. The status of the analysis determines the Help information that is displayed.</p> <ul> <li>In the Analyses window, find the analysis with the possible issue.</li> <li>Click the name of the failed analysis whose outputs you want to     view.</li> <li>Review the suggestions for review.</li> <li>If you still need assistance, click I still need help and complete     the form.</li> <li>Please go through all the troubleshooting steps yourself before     requesting help. The problem is often something that you can     diagnose yourself.</li> </ul> <p>Checking log files for error</p> <p>One of the main tools available for troubleshooting a failed analysis is the set of log files that are returned with each completed or failed analysis. These log files contain important information about the analysis, such as the settings that were used, files you used, and, in the case of a failed analysis, information to help explain why the analysis failed.</p> <p>Because different apps are based on different tools, there is no standard method used for error reporting, so the same type of error may land in different log files. For example, one app may return errors to the stdout files (usually the screen, although it can be redirected and is generally captured in a log file here), while another saves its errors to the stderr files (which usually writes to a file, but can also be redirected). This means you may have to look in more than one log file when troubleshooting a failed analysis. The log files that most commonly contain error information are (numerals in the filename correspond to the step number that was logged in your analysis):</p> <ul> <li><code>condor-stderr</code> and <code>condor-input-stdout</code> log files contain errors     and details about Condor, the batch manager program that handles     the execution of your analyses submission in the analyses queue.</li> <li><code>condor-input-stderr</code> and <code>condor-input-stdout</code> files contain     details about outputs from the tool upon which the app is based.</li> </ul> How do I get help with a tool (app) or workflow? <p>The steps to get Help depend on whether you're a novice or an expert with the tool (executable or binary) on which the app or workflow is based.</p> <p>If you are a novice:</p> <ol> <li>Learn more about the tools used:<ul> <li>Search the internet for the publication describing the tool and any related documentation.</li> <li>Make sure you understand what the tool is designed to do, what inputs it can accept and in which format, and how to set any parameters.</li> </ul> </li> <li>Search the internet for informative sites in your domain. For     example, SEQanswers is the go-to     online forum for the next-generation sequencing community.</li> <li>Talk with someone at your institution who is more experienced with     the tool.</li> <li>Try to use the app in the Discovery Environment. Click the info icon next to the app name to     view the app manual and its sample test input files and expected     outputs.</li> </ol> <p>If you are experienced with the tool or workflow:</p> <p>If you are experienced with the tool or workflow and need advice for how to work with very large-scale data or a complex workflow, you may request Extended Collaborative Support.</p> Why is my analysis sitting in the Submitted state for so long? <p>Analyses that use an app that runs on an HPC system can remain in the Submitted state for hours or even days. They may sit in the queue in Submitted state waiting to run, along with other possibly long-running jobs that were in the queue first. Therefore, it may take several days for your analysis to get its turn to run. Once your analysis runs, its results will be returned to the Data Store and you will get a notification that the analysis status is now Completed.</p> Is there a limit to how many analyses (jobs) I can run at the same time in the Discovery Environment? <p>The DE will run up to 8 of your analyses at the same time. You can launch more, but they will not run until some of your analyses have completed.</p> I'm trying to run an analysis, but when I enter an input I can't see my files. Why? I know they are there. <p>Because the app requires a folder as input, not a file, the files don't show since they aren't the appropriate inputs for the app. The files are indeed there but don't show. Check the app's input box; if it says \"Select a folder\", then it requires a folder input. Put the file(s) you want to input into a folder and then use that folder as input. Note: You can use Drag and Drop to input the folder by finding it in the Data window, making sure the folder name is shown in the center panel, and then dragging the folder into the app's input box.</p> How do I rerun a job, but with different parameters or with a different input? <p>You can easily relaunch the same analysis with different settings:</p> <p>In the Analyses window, click the app name in the App column for the analysis you want to rerun. This opens up an app window for that app, which is already configured with the inputs and settings you used for the previous analysis run. Change settings or inputs as needed. Click Launch Analysis to launch the new analysis.</p> <p>Learn more here.</p> How do I run the same analysis on a number of files most efficiently? <p>You can create a file that contains a list of up to 16 files to use as input for high-throughput and batch file execution. Such a file is called an HT Analysis Path List file. Learn more here, and if you still have questions, read here.</p> I want to analyze a series of files with the same app, but the output files all have the same name. How do I distinguish them so I can use them in a workflow? <p>You can avoid confusion by finding the output folder in your Data list and renaming each output file with a unique name. After renaming the output files, you can then use them together in a step of the analysis workflow.</p> Why can't I find an app in the Discovery Environment? <p>There are two common reasons why an app is not \"visible\" or doesn't come up in search in the Apps list:</p> <ul> <li>The app may be an HPC (high-performance computing) app, which is     only displayed after you have logged in to Tapis, where the HPC     apps are stored. To do so, click the HPC tab in the Apps     window and enter your CyVerse username and password.</li> <li>The app may not yet be public, or the app owner may not have     shared the unpublished app with you. Check with the owner to see     if it is indeed shared with you or is public.</li> </ul> <p>If you still can't find the app, it's possible it has been deprecated. If an app is no longer returned in a search query, search for an app with a similar name or one that uses the same tool, topic, or operation. If you are the app integrator and need the app returned to the catalog, contact Support (support@cyverse.org) for assistance. Learn more about deprecated apps.</p> What apps and workflows are in CyVerse? <p>CyVerse has hundreds of apps and workflows in the Discovery Environment (DE). You can view the list of applications available in the DE here. Most apps in the DE have user manuals to help you use the app. You also can browse the list of tutorials to find help to learn a complicated workflow or how to use an app in the DE or VICE.</p> How do I make my app available for others to use? <p>You can create a new app interface in the Discovery Environment and share it with other users and you also can install the app on VICE. In most cases, providing a Docker container (or a link to one) with the application of your choice is all you need to start. See the Develop section of the Learning Center.</p>"},{"location":"home/faq/#containers","title":"Containers","text":"Does CyVerse have resources for GPU and containers (e.g., to stabilize R modules using the nvidia cuda)? <p>Yes; please email Tyson at tswetnam@cyverse.org for details.</p> While container performance is greater than a VM, how much is container performance below that of native mode, in general? <p>Please see the Conclusion section bullet #2 in Evaluation of Docker Containers for Scientific Workloads in the Cloud.</p> Are there tools for scanning publicly available containers in Atmosphere VMs for malware? <p>Docker Hub and Quay, two of the most popular public container image registries, both provide security scanning for images that are uploaded to their sites. Details about how to enable or use these registries' security scanning features can be found here: https://developers.redhat.com/blog/2019/06/26/using-quay-io-to-find-vulnerabilities-in-your-container-images/ and https://docs.docker.com/docker-hub/vulnerability-scanning/.</p> <p>Other tools to scan your container images without using DockerHub and Quay include Anchore, Clair, and Trivy, with new container-based security scanning software being developed all the time. Each solution seems to take a different approach to security scanning, so you might need to experiment to find the tool that works for your workflow. The easier tools to use are Anchore, which can be used as a container itself, and Trivy, which can be installed by a package manager.</p> <p>When using Singularity, there is built-in integration with Clair using Singularity's tools. Information about Singularity tools can be found here: https://github.com/singularityhub/stools</p>"},{"location":"home/faq/#bring-your-own-byo","title":"Bring Your Own (BYO)","text":"How can I use CyVerse's tools and resources from within my program/app? <p>See information about our Science APIs; you can also contact Support using the blue chat icon at the bottom right of the platform. For projects requiring more extensive support, you can request community support or an external collaborative partnership (see Collaboration below).</p>"},{"location":"home/faq/#collaboration","title":"Collaboration","text":"How can I get a letter of collaboration for my grant proposal that uses CyVerse? <p>To request a letter of collaboration, email info@cyverse.org your request with the following information: - the CyVerse resources your project will use (e.g., storage, computing power, expertise for scaling, etc.) and indicate if any resulting datasets will be made publicly available; - the name of the PI, proposal title, funding agency, the date you need the letter  - if there is a template that must be used, please attach it to your email.</p> What is an external collaborative partnership and how do I apply? <p>External Collaborative Partnerships (ECP) pair member(s) of the CyVerse user community with expert CyVerse staff to address the computational needs of a scientific project. Requests are reviewed on an ongoing basis.</p> <p>The criteria CyVerse uses to review ECP requests are available here: ECP Criteria.</p> <p>To help you complete the ECP Application, the questions on the form are listed below.</p> <p>External Collaborative Partnership Application Questions</p> <ul> <li>Project Principal Investigator (PI)</li> <li>Institution</li> <li> <p>Collaborating personnel:   </p> <ul> <li>Provide a detailed list of students, technicians,         informaticians and/or developers who will be able to assist         with project design and implementation, their respective         computational science skill sets (e.g., web design, Python,         GWAS, etc.), and their specific time commitments during the         project (e.g., 1.5 hrs/day).</li> </ul> </li> <li> <p>Previous interactions with CyVerse</p> </li> <li>Funding sources</li> <li>Project title</li> <li>Project description</li> <li> <p>Please summarize your proposal's activities and desired outcomes     (500 chars or less)</p> </li> <li> <p>Scientific description:   </p> <ul> <li>Provide a scientific description of your project. Describe         how the proposed project is within the scope of CyVerse's         scientific Enablement Vision. Illustrate how any resulting         deliverables have the potential to enable science for         scientists beyond your immediate network of collaborators.</li> </ul> </li> <li> <p>Technical description:   </p> <ul> <li>Provide a technical description of your project. What is the         computational need that Will be addressed with assistance         from CyVerse? Identify specific potential deliverables to be         implemented using CyVerse technologies, such as the         Discovery Environment, Atmosphere, APIs, Data Store, Data         Commons, etc.</li> </ul> </li> <li> <p>Timeline and milestones for completing the project:   </p> <ul> <li>Provide a timeline of specific monthly milestones         (deliverables). Projects of short duration (~2 months)         should provide weekly milestones.</li> </ul> </li> <li> <p>Scientific and technical impact:   </p> <ul> <li>Describe how the success of this collaboration will benefit         your project and the broader community.</li> </ul> </li> <li> <p>Communication and sharing plan:   </p> <ul> <li>Will the data and/or workflows be made publicly available         through CyVerse?<ul> <li>Will you be blogging and/or tweeting about the work?</li> <li>Will you be giving a talk about your work at your     institution or at a professional conference?</li> <li>Will you be writing a news article for the CyVerse website     or newsletter?</li> <li>Will you be preparing a tutorial that uses the datasets or     workflows?</li> <li>Will you be leading a workshop(s) or webinar(s) to teach     others to use the data or workflow(s)?</li> </ul> </li> </ul> </li> </ul>"},{"location":"home/faq/#teaching-and-training","title":"Teaching and Training","text":"How can I use CyVerse in my course? <p>A great teaching resource is to use containerized workflows in DE/VICE for a class. By loading a container with the software tools, datasets, and analysis parameters necessary to run an analysis, educators use containers to help overcome many technological and logistical (i.e., devices with different OS) hurdles for  both learning and teaching informatics and computational skills. See Teaching with VICE for more information.</p> <p>Also, DNA Subway is especially useful for teaching the basics of computational genomics workflows: gene concepts, phylogenetics, DNA barcoding and RNA-Seq analysis. With a friendly user interface, DNA Subway uses the analogy of multiple subway  stops and lines to understand genomics workflows and has been used successfully by high school students and above.</p> Can CyVerse give a workshop at my institution? <p>Funding to support workshop requests is very limioted, with priority for trainings at underserved institutions (rural, HBCU/Tribal/Hispanic-serving, etc.). Contact CyVerse's Education, Outreach, and Training Lead Jason Williams (williams@cshl.edu).</p>"},{"location":"home/getting_help/","title":"Getting Help","text":"<p>First, check if your question is answered on the FAQ page. Next, try searching the Learning Center documentation using the search bar at the top of the page. If you still haven't found an answer, click the Intercom icon  on the lower right-hand side of the page to start messaging with the CyVerse support team.</p>"},{"location":"home/getting_help/#issues-with-documentation","title":"Issues with Documentation","text":"<p>To report an issue with the documentation itself, or to propose a change to the documentation, click on the GitHub icon in the top right of the page to navigate to the GitHub repository, where you can open an Issue. If you prefer not to use GitHub, you can email us at learning@cyverse.org.</p>"},{"location":"home/glossary/","title":"Glossary &amp; Acronyms","text":"<p>This glossary is to help you become more familiar with terms used in the CyVerse ecosystem as well as more broadly in Open Science and beyond.</p>"},{"location":"home/glossary/#a","title":"A","text":"<ul> <li>action: automate a workflow in the context of CI/CD, see GitHub Actions https://github.com/features/actions</li> <li>agile: development methodology https://en.wikipedia.org/wiki/Agile_software_development for organizing a team to complete tasks organized over short periods called 'sprints'</li> <li>allocation: portion of a resource assigned to a particular recipient, typical unit is a core or node hour</li> <li>Anaconda: open source data science platform. https://www.anaconda.com/</li> <li>application: also called an 'app', a software designed to help the user to perform specific task</li> <li>ARM: Advanced RISC Machines, a family of central processor units  </li> <li>awesome: a curated set of lists that provide insight into awesome software projects on GitHub https://github.com/topics/awesome-list</li> <li>AVU: Attribute-Value-Unit a components for iRODS metadata https://docs.irods.org/4.1.9/icommands/metadata/</li> <li>AWS: Amazon Web Services a commercial cloud</li> <li>Azure: Microsoft's Azure a commercial cloud</li> </ul>"},{"location":"home/glossary/#b","title":"B","text":"<ul> <li>beta: :math:<code>\\beta</code>, a software version which is not yet ready for publication but is being tested</li> <li>bash: Bash is the GNU Project's shell, the Bourne-Again Shell https://www.gnu.org/software/bash/</li> <li>biocontainer: a community-driven project that provides the infrastructure and basic guidelines to create, manage and distribute bioinformatics packages (e.g conda) and containers (e.g docker, singularity)</li> <li>bioconda: a channel for the conda package manager specializing in bioinformatics software</li> </ul>"},{"location":"home/glossary/#c","title":"C","text":"<ul> <li>CLI: (1) the UNIX shell `command line interface https://en.wikipedia.org/wiki/Command-line_interface, most typically  BASH (2) the CyVerse Learning Institute https://learning.cyverse.org</li> <li>command: a set of instructions sent to the computer, typically in a typed interface</li> <li>conda: an installation type of the Anaconda data science platform. Command line application for managing packages and environments</li> <li>container: virtualization of an operating system run within an isolated user space</li> <li>Continuous Integration: (CI) is testing automation to check that the application is not broken whenever new commits are integrated into the main branch</li> <li>Continuous Delivery: (CD) is an extension of 'continuous integration' to make sure that you can release new changes in a sustainable way</li> <li>Continuous Deployment: a step further than 'continuous delivery', every change that passes all stages of your production pipeline is released</li> <li>Continuous Development: a process for iterative software development and is an umbrella over several other processes including 'continuous integration', 'continuous testing', 'continuous delivery' and 'continuous deployment'</li> <li>Continuous Testing: a process of testing and automating software development</li> <li>CPU: central processor unit</li> <li>CRAN: The Comprehensive R Archive Network https://cran.r-project.org/</li> <li>CyVerse tool: Software program that is integrated into the back end of the DE for use in DE apps</li> <li>CyVerse app: graphic interface of a tool made available for use in the DE</li> </ul>"},{"location":"home/glossary/#d","title":"D","text":"<ul> <li>Debian: a free OS https://www.debian.org/, base of other Linux distributions such as Ubuntu</li> <li>Development: the environment on your computer where you write code</li> <li>DevOps Software *Dev*elopment and information techology *Op*erations techniques for shortening the time to change software in relation to CI/CD</li> <li>Discovery Environment (DE): a data science workbench for running executable, interactive, and high throughput applications in `CyVerse DE https://de.cyverse.org</li> <li>distribution: abbreviated as 'distro', an operating system made from a software collection based upon the Linux kernel</li> <li>Docker: https://www.docker.com/ is an open source software platform to create, deploy and manage virtualized application containers on a common operating system (OS), with an ecosystem of allied tools. A program that runs and handles life-cycle of containers and images</li> <li>DockerHub: an official registry of docker containers, operated by Docker. https://hub.docker.com/</li> <li>DOI: a digital object identifier. A persistant identifier number, managed by the doi.org https://www.doi.org/</li> <li>Dockerfile: a text document that contains all the commands you would normally execute manually in order to build a Docker image. Docker can build images automatically by reading the instructions from a Dockerfile</li> </ul>"},{"location":"home/glossary/#e","title":"E","text":"<ul> <li>elastic: (disambiguation) the ability of a cloud service provider to swiftly scale the usage of resources such as storage</li> <li>Elastic Container Registry</li> <li>Elastic Container Service </li> <li>environment: software that includes operating system, database system, specific tools for analysis</li> <li>entrypoint: In a Dockerfile, an ENTRYPOINT is an optional definition for the first part of the command to be run</li> </ul>"},{"location":"home/glossary/#f","title":"F","text":"<ul> <li>FOSS:  (1) Free and Open Source Software https://en.wikipedia.org/wiki/Free_and_open-source_software, (2) Foundational Open Science Skills https://cyverse.org/foss</li> <li>function: a named section of a program that performs a specific task</li> </ul>"},{"location":"home/glossary/#g","title":"G","text":"<ul> <li>git: a version control system software</li> <li>GitHub: a website for hosting <code>git</code> repositories -- owned by Microsoft https://github.com</li> <li>GitLab: a website for hosting <code>git</code> repositories https://gitlab.com</li> <li>GitOps: using <code>git</code> framework as a means of deploying infrastructure on cloud using Kubernetes</li> <li>GPU: graphic processing unit</li> <li>GUI: graphical user interface</li> </ul>"},{"location":"home/glossary/#h","title":"H","text":"<ul> <li>hack: a quick job that produces what is needed, but not well</li> <li>HPC: high performance computer, for large syncronous computation</li> <li>HTC: high throughput computer, for many parallel tasks</li> </ul>"},{"location":"home/glossary/#i","title":"I","text":"<ul> <li>IaaS: Infrastructure as a Service https://en.wikipedia.org/wiki/Infrastructure_as_a_service. online services that provide APIs</li> <li>iCommands: command line application https://docs.irods.org/master/icommands/user/ for accessing iRODS Data Store</li> <li>IDE: integrated development environment, typically a graphical interface for working with code language or packages</li> <li>instance: a single virtul machine</li> <li>image: self-contained, read-only \u2018snapshot\u2019 of your applications and packages, with all their dependencies</li> <li>iRODS: an open source integrated Rule-Oriented Data Management System https://irods.org/</li> </ul>"},{"location":"home/glossary/#j","title":"J","text":"<ul> <li>Java: programming language, class-based, object-oriented</li> <li>JavaScript: programming language</li> <li>JSON: Java Script Object Notation, data interchange format that uses human-readable text</li> <li>Jupyter(Hub,Lab,Notebooks): an IDE, originally the iPythonNotebook, operates in the browser https://jupyter.org/</li> </ul>"},{"location":"home/glossary/#k","title":"K","text":"<ul> <li>kernel:  central component of most operating systems (OS)</li> <li>Kubernetes: an open source container orchestration platform created by Google Kubernetes https://kubernetes.io/ is often referred to as \"K8s\"</li> </ul>"},{"location":"home/glossary/#l","title":"L","text":"<ul> <li>lib: a UNIX library</li> <li>linux: open source Unix-like operating system</li> </ul>"},{"location":"home/glossary/#m","title":"M","text":"<ul> <li>makefile: a file containing a set of directives used by a make build automation tool https://www.gnu.org/software/make/</li> <li>markdown: a lightweight markup language with plain text formatting syntax</li> <li>master: a racist word used by computer engineers to describe the <code>main</code> or `primary`` computer or branch</li> <li>metadata:: data about data, useful for searching and querying</li> <li>multi-thread: a process which runs on more than one CPU or GPU core at the same time</li> <li>Mac OS X: Apple's popular desktop OS</li> </ul>"},{"location":"home/glossary/#n","title":"N","text":"<ul> <li>node: a computer, typically 1 or 2 core (with many threads) server in a cloud or HPC center</li> </ul>"},{"location":"home/glossary/#o","title":"O","text":"<ul> <li>ontology: formal naming and structural hierarchy used to describe data, also called a knowledge graph https://en.wikipedia.org/wiki/Ontology_(information_science)</li> <li>organization: a group, in the context of GitHub a place where developers contribute code to repositories</li> <li>Operating System (OS): software that manages computer hardware, software resources, and provides common services for computer programs</li> <li>Open Science Grid (OSG): national, distributed computing partnership for data-intensive research https://opensciencegrid.org/</li> <li>ORCID: Open Researcher and Contributor ID https://orcid.org/, a persistent digital identifier that distinguishes you from every other researcher</li> </ul>"},{"location":"home/glossary/#p","title":"P","text":"<ul> <li>PaaS: Platform as a Service https://en.wikipedia.org/wiki/Platform_as_a_service run and manage applications in cloud without complexity of developing it yourself</li> <li>package: an app designed for a particular langauge</li> <li>package manager: a collection of software tools that automates the process of installing, upgrading, configuring, and removing computer programs for a computer's operating system in a consistent manner</li> <li>Production: environment where users access the final code after all of the updates and testing</li> <li>Python:  interpreted, high-level, general-purpose programming language https://www.python.org/</li> </ul>"},{"location":"home/glossary/#q","title":"Q","text":"<ul> <li>QUAY.io: private Docker registry https://quay.io</li> </ul>"},{"location":"home/glossary/#r","title":"R","text":"<ul> <li>R: data science programming language R Project https://cran.r-project.org/</li> <li>recipe file: a file with installation scripts used for building software such as containers, e.g. Dockerfile</li> <li>registry: a storage and content delivery system, such as that used by Docker</li> <li>remote desktop: a VM with a graphic user interface accessed via a browser</li> <li>repo(sitory): a directory structure for hosting code and data</li> <li>RST: ReStructuredText, a markdown type file</li> <li>ReadTheDocs: a web service for rendering documentation (that this website uses) https://readthedocs.org and readthedocs.com https://readthedocs.com/</li> <li>root: the administrative user on a linux kernel - use your powers wisely</li> </ul>"},{"location":"home/glossary/#s","title":"S","text":"<ul> <li>SaaS: Software as a Service https://en.wikipedia.org/wiki/Software_as_a_service web based platform for using software</li> <li>schema: a metadata standard for labeling, tagging or coding for recording &amp; cataloging information or structuring descriptive records. see https://schema.org/</li> <li>scrum: daily set of tasks and evalautions as part of a sprint.</li> <li>shell: is a command line interface program that runs other programs (may be complex, technical programs or very simple programs such as making a directory). These simple, stand-alone programs are called commands</li> <li>Singularity: a container software, used widely on HPC, created by SyLabs https://sylabs.io/</li> <li>SLACK: Searchable Log of All Conversation and Knowledge, a team communication tool https://slack.com/</li> <li>slave: a racist word used to describe worker or secondary computers</li> <li>sprint: set period of time during which specific work has to be completed and made ready for review</li> <li>Singularity def file: (definition file) recipe for building a Singualrity container</li> <li>Stage:  environment that is as similar to the production environment as can be for final testing</li> </ul>"},{"location":"home/glossary/#t","title":"T","text":"<ul> <li>tar:  software utility for collecting many files into one archive file, often referred to as a tarball</li> <li>tensor: algebraic object that describes a linear mapping from one set of algebraic objects to another</li> <li>terminal: a windowed emulator for directly enterinc commands to a computer</li> <li>thread: a CPU process or a series of linked messages in a discussion board</li> <li>tool: In the context of CyVerse Discovery Environment, a Docker Container</li> <li>TPU: tensor processing unit</li> <li>Travis: Travis-CI https://travis-ci.org/, a continuous integration software</li> </ul>"},{"location":"home/glossary/#u","title":"U","text":"<ul> <li>Ubuntu: most popular Linux OS distribution https://ubuntu.com/, based on Debian</li> <li>UNIX: operating system</li> <li>user: the profile under which applications are started and run, <code>root</code> is the most powerful system administrator</li> </ul>"},{"location":"home/glossary/#v","title":"V","text":"<ul> <li>VICE: Visual Interactive Computing Environment https://learning.cyverse.org/projects/vice/en/latest</li> <li>virtual machine: is a software computer that, like a physical computer, runs an operating system and applications</li> </ul>"},{"location":"home/glossary/#w","title":"W","text":"<ul> <li>waterfall: software development broken into linear sequential phases, similar to a Gantt chart</li> <li>W3C: World Wide Web Consortium</li> <li>webGL: JavaScript API for rendering interactive 2D and 3D graphics within any compatible web browser without the use of plug-ins</li> <li>Windows: Microsoft's most popular desktop OS</li> <li>workspace: (vs. repo)</li> <li>worker node: A cluster typically has one or more nodes, which are the worker machines that run your containerized applications and other workloads. Each node is managed from the master, which receives updates on each node's self-reported status.</li> </ul>"},{"location":"home/glossary/#x","title":"X","text":"<ul> <li>XML: Extensible Markup Language, data interchange format that uses human-readable text</li> </ul>"},{"location":"home/glossary/#y","title":"Y","text":"<ul> <li>YAML: YAML Ain't Markup Language, data interchange format that uses human-readable text</li> </ul>"},{"location":"home/glossary/#z","title":"Z","text":"<ul> <li>ZenHub: team collaboration solution built directly into GitHub that uses kanban style boards</li> <li>Zenodo: general-purpose open-access repository developed under the European OpenAIRE program and operated by CERN</li> <li>zip: a compressed file format</li> <li>zsh: Z-Shell https://www.zsh.org/ now the default shell on new Mac OS X</li> </ul> <p>Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy.</p> <p>Fix or improve this documentation</p> <p>We make regular contributions to these materials, and you can suggest new materials or create and share your own.  If you have ideas or suggestions please email learning@cyverse.org. You can also view, edit, and submit contributions on GitHub.</p> <p>On Github: GitHub Send feedback: learning@cyverse.org</p>"},{"location":"home/mooc/","title":"Self-Guided Courses","text":"<p>CyVerse Self-Guided Course (USA version) </p> <p>Created: 2022-02-14 </p> <p>In collaboration with CyVerse Austria and CyVerse UK, we have created a massive open online course (MOOC) for self-guided students, covering the basics of data management and analysis in CyVerse. This is a perfect starting point for new CyVerse users to get a basic understanding of how their computational workflows and data lifecycles can work in CyVerse.</p>"},{"location":"home/powered_by/","title":"Powered by CyVerse","text":""},{"location":"home/powered_by/#leveraging-cyverse-services","title":"Leveraging CyVerse Services","text":"<p>CyVerse public platform provides a nominal quantity of compute and data storage to all of our users. </p> <p>For researchers who need more, we also provide mechanisms for extending and powering your research.</p> <p></p>"},{"location":"home/powered_by/#professional-services","title":"Professional Services","text":"<p>CyVerse offers a suite of services for institutions seeking to deploy CyVerse's cyberinfrastructure locally. With a secure, shared data management and computing environment with increased speed and performance, a local installation can better support your members' research and teaching needs for:</p> <ul> <li>Security compliance (e.g., HIPAA, ITAR, ISO, etc.)</li> <li>Federation with local and commercial cloud and high-performance computing</li> <li>Integration with local user identity management systems</li> </ul> <p>Our professional services include installation, maintenance, and training for local installations of CyVerse.</p> <p>Because CyVerse fully supports open source practices, you can access all of our open source infrastructure code and architecture diagrams on Github.</p> <p>Contact Us if you're interested in knowing more.</p>"},{"location":"home/powered_by/#powered-by-cyverse","title":"Powered by CyVerse","text":"<p>Through our unique Powered by CyVerse program, third-party projects can leverage CyVerse cyberinfrastructure to provide their users with robust services such as secure single sign-on with authentication, easy and fast data transfers, access to large-scale, High-Performance Compute resources such as Jetstream or XSEDE, as well as expertise from developers and domain scientists.</p>"},{"location":"home/powered_by/#external-collaborative-partnership","title":"External Collaborative Partnership","text":"<p>External Collaborative Partnerships (ECP) pair you with an expert staff member to address the computational needs of your specific scientific project.</p> <p>To be considered for a partnership, review the below criteria and complete the ECP Request Form. CyVerse does not provide funding support for external projects.</p>"},{"location":"home/subscriptions/","title":"Individual Subscriptions","text":"<p>In order to purchase an individual CyVerse subscription, please see Subscribe</p> <p>Table: CyVerse Individual Subscription Tiers (Spring 2025)</p> Service Basic (Free) Regular Pro Commercial Discovery Environment Yes Yes Yes Yes Data Store Yes Yes Yes Yes Advanced Features &amp; APIs - - Yes Yes Data Storage Limit 5 GB 50 GB 4 TB 7 TB Compute Units / Year* 200 1,000 25,000 250,000 Access to GPU** - - contact us contact us Concurrent Jobs 1 2 4 8 Sharing Data &amp; Apps None 100 Unlimited Unlimited Community Released Data Folder Requests None Yes  Yes Yes DOI for Data None 5 10 20 Workshop Requests - - 4 8 Webinar Access Yes Yes Yes Yes Support Email In-App Chat Screen Share Support Screen Share Support Price / Year Free $200 $400 $2,400 <p>Teaching with CyVerse</p> <p>CyVerse was built as a free to use, open source cyberinfrastructure project for everyone to use. It is a privilege to offer access to the most cutting edge data science tools and computing environments in the world to students from the most under resourced and under served corners of our country with the worst internet connections.</p> <p>Free \"basic\" account holders are intended to be undergraduates or continuing education students. The \"basic\" account comes with enough computing hours in the Discovery Environment for a student to complete two semester's worth (one academic year) of a courses computational assignments.</p> <p>Students should be mindful of their allocation hours and use them conservatively. Analyses should not be left idle or running overnight when not in use, as they take away from the shared resource pool, and they rapidly deplete a student's free account.</p> <p>Teachers should purchase a \"Pro\" or \"Commericial\" subscription, so that they can share data with their students, and request a Community Release folder, if need be. </p>"},{"location":"home/what_is_cyverse/","title":"What is CyVerse?","text":"<p>CyVerse is a powerful cloud infrastructure, custom open source software, and the people who support its operations. </p> <p>CyVerse is owned by The Arizona Board of Regents and is operated primarily at The University of Arizona, with partners Texas Advanced Computing Center (TACC) at University of Texas, Austin, Cold Spring Harbor Labs (CSHL)  in Long Island, New York, and Indiana University (Jetstream 2 Cloud) in Bloomington, Indiana. </p> <p>CyVerse leverages public computing resources across the United States through partnerships with the National Science Foundation's ACCESS-CI program, connected over the Internet2 </p> <p>CyVerse was originally funded by the USA National Science Foundation in 2008 to handle huge datasets and complex analyses for the USA Plant Sciences community. Today, we have 16 years of experience working with tens of thousands of scientific researchers across Astronomy, Life, Earth, Health, Defense, and Space Sciences from over 160 countries. </p> <p>To date, CyVerse has directly enabled over $280,000,000 in externally funded research projects in the United States, and has been cited in over 1,400 peer-reviewed research articles as the computational and data management platform which enabled the science. </p> <p>Our current cyberinfrastructure platform includes:</p> <ul> <li> <p> Data Management </p> <p> 5GB free data storage for all basic users,</p> <p> Multi-petabyte data hosting available for Powered By services, sponsored projects and proposed research (contact us).</p> <p> Managed File Transfers (MFT) move your data securely with end-to-end encryption</p> <p> Store data privately, share it with your collaborators, or make it public </p> <p> Publish your data with DataCite DOI from Lyrasis</p> </li> <li> <p> Discovery Environment </p> <p> An interactive browser-based Data Science Workbench</p> <p> Launch multi-core, large memory, and GPU based analyses</p> <p> Leverage major open source scientific research software applications</p> <p> Bring Your Own Software using Docker Containers</p> <p> Share your data and analyses privately and securely with collaborators</p> <p> Create and curate reproducible research objects</p> </li> <li> <p> Cloud Native Services </p> <p> Cloud Automation &amp; Continuous Analysis Orchestration CACAO enabling cloud automation &amp; continuous analysis orchestration on multi-cloud</p> <p> Uses templates to provision and launch scalable resources to commercial or public cloud resource providers</p> <p> Launch  Project Jupyter Hubs for tens to thousands of users in three clicks. </p> <p> Launch Open Source LLM frameworks (Ollama, OpenWebUI, DeepSeek, etc) with vector databases (Weaviate, Pinecone, etc) in secure environments and work with your data privately and securely</p> <p>  https://gitlab.com/cyverse/cacao</p> </li> </ul> <p> Powered by - Work with our experienced data scientists and software engineers to scale your algorithms and data onto cloud and high performance compute. Contact Us if you are interested in starting an external collaborative partnership.</p> <p> Education and Training - learn how to use containers, workflows, and public research cyberinfrastructure from our professional trainers.</p> <p> Cloud Resources for running your class or workshop in the cloud.</p> <p>Funding and Citations:</p> <p>CyVerse is funded entirely by the National Science Foundation  under Award Numbers:</p> <p> </p> <p>Please cite CyVerse appropriately when you make use of our resources, see CyVerse citation policy.</p>"}]}